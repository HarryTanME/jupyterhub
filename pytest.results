=========================================== test session starts ============================================
platform linux -- Python 3.6.2, pytest-3.2.1, py-1.4.34, pluggy-0.4.0
rootdir: /home/ec2-user/jupyterhub, inifile:
plugins: tornado-0.4.5, cov-2.5.1
collected 167 items

jupyterhub/tests/test_api.py EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE
jupyterhub/tests/test_app.py .F........
jupyterhub/tests/test_auth.py .........EEEFF.
jupyterhub/tests/test_crypto.py ............
jupyterhub/tests/test_db.py FF
jupyterhub/tests/test_named_servers.py EEEE
jupyterhub/tests/test_orm.py .........
jupyterhub/tests/test_pages.py EEEEEEEEEEEEEEEEEEEEEEEEEE
jupyterhub/tests/test_proxy.py FEEEEEEEEEEEEE
jupyterhub/tests/test_services.py EEE
jupyterhub/tests/test_services_auth.py ...EEEEE
jupyterhub/tests/test_singleuser.py EEFF
jupyterhub/tests/test_spawner.py .EFFF..FF..EEEE
jupyterhub/tests/test_traitlets.py ...

================================================== ERRORS ==================================================
_____________________________________ ERROR at setup of test_auth_api ______________________________________

self = <jupyterhub.tests.mocking.MockHub object at 0x7fdd742688d0>

    @gen.coroutine
    def start(self):
        """Start the whole thing"""
        self.io_loop = loop = IOLoop.current()
    
        if self.subapp:
            self.subapp.start()
            loop.stop()
            return
    
        if self.generate_config:
            self.write_config_file()
            loop.stop()
            return
    
        # start the webserver
        self.http_server = tornado.httpserver.HTTPServer(self.tornado_application, xheaders=True)
        try:
            self.http_server.listen(self.hub_port, address=self.hub_ip)
        except Exception:
            self.log.error("Failed to bind hub to %s", self.hub.bind_url)
            raise
        else:
            self.log.info("Hub API listening on %s", self.hub.bind_url)
    
        # start the proxy
        if self.proxy.should_start:
            try:
>               yield self.proxy.start()

jupyterhub/app.py:1550: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tornado.gen.Runner object at 0x7fdd73a301d0>

    def run(self):
        """Starts or resumes the generator, running until it reaches a
            yield point that is not ready.
            """
        if self.running or self.finished:
            return
        try:
            self.running = True
            while True:
                future = self.future
                if not future.done():
                    return
                self.future = None
                try:
                    orig_stack_contexts = stack_context._state.contexts
                    exc_info = None
    
                    try:
>                       value = future.result()

../anaconda3/lib/python3.6/site-packages/tornado/gen.py:1055: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = None, timeout = None

    def result(self, timeout=None):
        """If the operation succeeded, return its result.  If it failed,
            re-raise its exception.
    
            This method takes a ``timeout`` argument for compatibility with
            `concurrent.futures.Future` but it is an error to call it
            before the `Future` is done, so the ``timeout`` is never used.
            """
        self._clear_tb_log()
        if self._result is not None:
            return self._result
        if self._exc_info is not None:
            try:
>               raise_exc_info(self._exc_info)

../anaconda3/lib/python3.6/site-packages/tornado/concurrent.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

exc_info = None

>   ???

<string>:4: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<jupyterhub.proxy.ConfigurableHTTPProxy object at 0x7fdd742b47b8>,), kwargs = {}, future = None
result = <generator object start at 0x7fdd73a1a990>, orig_stack_contexts = ((), None), yielded = None

    @functools.wraps(wrapped)
    def wrapper(*args, **kwargs):
        future = TracebackFuture()
    
        if replace_callback and 'callback' in kwargs:
            callback = kwargs.pop('callback')
            IOLoop.current().add_future(
                future, lambda future: callback(future.result()))
    
        try:
            result = func(*args, **kwargs)
        except (Return, StopIteration) as e:
            result = _value_from_stopiteration(e)
        except Exception:
            future.set_exc_info(sys.exc_info())
            return future
        else:
            if isinstance(result, GeneratorType):
                # Inline the first iteration of Runner.run.  This lets us
                # avoid the cost of creating a Runner when the coroutine
                # never actually yields, which in turn allows us to
                # use "optional" coroutines in critical path code without
                # performance penalty for the synchronous case.
                try:
                    orig_stack_contexts = stack_context._state.contexts
>                   yielded = next(result)

../anaconda3/lib/python3.6/site-packages/tornado/gen.py:307: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <jupyterhub.proxy.ConfigurableHTTPProxy object at 0x7fdd742b47b8>

    @gen.coroutine
    def start(self):
        public_server = Server.from_url(self.public_url)
        api_server = Server.from_url(self.api_url)
        env = os.environ.copy()
        env['CONFIGPROXY_AUTH_TOKEN'] = self.auth_token
        cmd = self.command + [
            '--ip', public_server.ip,
            '--port', str(public_server.port),
            '--api-ip', api_server.ip,
            '--api-port', str(api_server.port),
            '--error-target', url_path_join(self.hub.url, 'error'),
        ]
        if self.app.subdomain_host:
            cmd.append('--host-routing')
        if self.debug:
            cmd.extend(['--log-level', 'debug'])
        if self.ssl_key:
            cmd.extend(['--ssl-key', self.ssl_key])
        if self.ssl_cert:
            cmd.extend(['--ssl-cert', self.ssl_cert])
        if self.app.statsd_host:
            cmd.extend([
                '--statsd-host', self.app.statsd_host,
                '--statsd-port', str(self.app.statsd_port),
                '--statsd-prefix', self.app.statsd_prefix + '.chp'
            ])
        # Warn if SSL is not used
        if ' --ssl' not in ' '.join(cmd):
            self.log.warning("Running JupyterHub without SSL."
                             "  I hope there is SSL termination happening somewhere else...")
        self.log.info("Starting proxy @ %s", public_server.bind_url)
        self.log.debug("Proxy cmd: %s", cmd)
        shell = os.name == 'nt'
        try:
>           self.proxy_process = Popen(cmd, env=env, start_new_session=True, shell=shell)

jupyterhub/proxy.py:462: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <subprocess.Popen object at 0x7fdd73a23e48>
args = ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '56525', '--api-ip', ...], bufsize = -1
executable = None, stdin = None, stdout = None, stderr = None, preexec_fn = None, close_fds = True
shell = False, cwd = None
env = {'COLUMNS': '108', 'CONFIGPROXY_AUTH_TOKEN': '40a30913f49d45b19d325dbc1e6bb46c', 'CVS_RSH': 'ssh', 'HISTCONTROL': 'ignoredups', ...}
universal_newlines = False, startupinfo = None, creationflags = 0, restore_signals = True
start_new_session = True, pass_fds = ()

    def __init__(self, args, bufsize=-1, executable=None,
                 stdin=None, stdout=None, stderr=None,
                 preexec_fn=None, close_fds=_PLATFORM_DEFAULT_CLOSE_FDS,
                 shell=False, cwd=None, env=None, universal_newlines=False,
                 startupinfo=None, creationflags=0,
                 restore_signals=True, start_new_session=False,
                 pass_fds=(), *, encoding=None, errors=None):
        """Create new Popen instance."""
        _cleanup()
        # Held while anything is calling waitpid before returncode has been
        # updated to prevent clobbering returncode if wait() or poll() are
        # called from multiple threads at once.  After acquiring the lock,
        # code must re-check self.returncode to see if another thread just
        # finished a waitpid() call.
        self._waitpid_lock = threading.Lock()
    
        self._input = None
        self._communication_started = False
        if bufsize is None:
            bufsize = -1  # Restore default
        if not isinstance(bufsize, int):
            raise TypeError("bufsize must be an integer")
    
        if _mswindows:
            if preexec_fn is not None:
                raise ValueError("preexec_fn is not supported on Windows "
                                 "platforms")
            any_stdio_set = (stdin is not None or stdout is not None or
                             stderr is not None)
            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:
                if any_stdio_set:
                    close_fds = False
                else:
                    close_fds = True
            elif close_fds and any_stdio_set:
                raise ValueError(
                        "close_fds is not supported on Windows platforms"
                        " if you redirect stdin/stdout/stderr")
        else:
            # POSIX
            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:
                close_fds = True
            if pass_fds and not close_fds:
                warnings.warn("pass_fds overriding close_fds.", RuntimeWarning)
                close_fds = True
            if startupinfo is not None:
                raise ValueError("startupinfo is only supported on Windows "
                                 "platforms")
            if creationflags != 0:
                raise ValueError("creationflags is only supported on Windows "
                                 "platforms")
    
        self.args = args
        self.stdin = None
        self.stdout = None
        self.stderr = None
        self.pid = None
        self.returncode = None
        self.universal_newlines = universal_newlines
        self.encoding = encoding
        self.errors = errors
    
        # Input and output objects. The general principle is like
        # this:
        #
        # Parent                   Child
        # ------                   -----
        # p2cwrite   ---stdin--->  p2cread
        # c2pread    <--stdout---  c2pwrite
        # errread    <--stderr---  errwrite
        #
        # On POSIX, the child objects are file descriptors.  On
        # Windows, these are Windows file handles.  The parent objects
        # are file descriptors on both platforms.  The parent objects
        # are -1 when not using PIPEs. The child objects are -1
        # when not redirecting.
    
        (p2cread, p2cwrite,
         c2pread, c2pwrite,
         errread, errwrite) = self._get_handles(stdin, stdout, stderr)
    
        # We wrap OS handles *before* launching the child, otherwise a
        # quickly terminating child could make our fds unwrappable
        # (see #8458).
    
        if _mswindows:
            if p2cwrite != -1:
                p2cwrite = msvcrt.open_osfhandle(p2cwrite.Detach(), 0)
            if c2pread != -1:
                c2pread = msvcrt.open_osfhandle(c2pread.Detach(), 0)
            if errread != -1:
                errread = msvcrt.open_osfhandle(errread.Detach(), 0)
    
        text_mode = encoding or errors or universal_newlines
    
        self._closed_child_pipe_fds = False
    
        try:
            if p2cwrite != -1:
                self.stdin = io.open(p2cwrite, 'wb', bufsize)
                if text_mode:
                    self.stdin = io.TextIOWrapper(self.stdin, write_through=True,
                            line_buffering=(bufsize == 1),
                            encoding=encoding, errors=errors)
            if c2pread != -1:
                self.stdout = io.open(c2pread, 'rb', bufsize)
                if text_mode:
                    self.stdout = io.TextIOWrapper(self.stdout,
                            encoding=encoding, errors=errors)
            if errread != -1:
                self.stderr = io.open(errread, 'rb', bufsize)
                if text_mode:
                    self.stderr = io.TextIOWrapper(self.stderr,
                            encoding=encoding, errors=errors)
    
            self._execute_child(args, executable, preexec_fn, close_fds,
                                pass_fds, cwd, env,
                                startupinfo, creationflags, shell,
                                p2cread, p2cwrite,
                                c2pread, c2pwrite,
                                errread, errwrite,
>                               restore_signals, start_new_session)

../anaconda3/lib/python3.6/subprocess.py:707: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <subprocess.Popen object at 0x7fdd73a23e48>
args = ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '56525', '--api-ip', ...]
executable = b'configurable-http-proxy', preexec_fn = None, close_fds = True, pass_fds = (), cwd = None
env = {'COLUMNS': '108', 'CONFIGPROXY_AUTH_TOKEN': '40a30913f49d45b19d325dbc1e6bb46c', 'CVS_RSH': 'ssh', 'HISTCONTROL': 'ignoredups', ...}
startupinfo = None, creationflags = 0, shell = False, p2cread = -1, p2cwrite = -1, c2pread = -1
c2pwrite = -1, errread = -1, errwrite = -1, restore_signals = True, start_new_session = True

    def _execute_child(self, args, executable, preexec_fn, close_fds,
                       pass_fds, cwd, env,
                       startupinfo, creationflags, shell,
                       p2cread, p2cwrite,
                       c2pread, c2pwrite,
                       errread, errwrite,
                       restore_signals, start_new_session):
        """Execute program (POSIX version)"""
    
        if isinstance(args, (str, bytes)):
            args = [args]
        else:
            args = list(args)
    
        if shell:
            args = ["/bin/sh", "-c"] + args
            if executable:
                args[0] = executable
    
        if executable is None:
            executable = args[0]
        orig_executable = executable
    
        # For transferring possible exec failure from child to parent.
        # Data format: "exception name:hex errno:description"
        # Pickle is not used; it is complex and involves memory allocation.
        errpipe_read, errpipe_write = os.pipe()
        # errpipe_write must not be in the standard io 0, 1, or 2 fd range.
        low_fds_to_close = []
        while errpipe_write < 3:
            low_fds_to_close.append(errpipe_write)
            errpipe_write = os.dup(errpipe_write)
        for low_fd in low_fds_to_close:
            os.close(low_fd)
        try:
            try:
                # We must avoid complex work that could involve
                # malloc or free in the child process to avoid
                # potential deadlocks, thus we do all this here.
                # and pass it to fork_exec()
    
                if env is not None:
                    env_list = []
                    for k, v in env.items():
                        k = os.fsencode(k)
                        if b'=' in k:
                            raise ValueError("illegal environment variable name")
                        env_list.append(k + b'=' + os.fsencode(v))
                else:
                    env_list = None  # Use execv instead of execve.
                executable = os.fsencode(executable)
                if os.path.dirname(executable):
                    executable_list = (executable,)
                else:
                    # This matches the behavior of os._execvpe().
                    executable_list = tuple(
                        os.path.join(os.fsencode(dir), executable)
                        for dir in os.get_exec_path(env))
                fds_to_keep = set(pass_fds)
                fds_to_keep.add(errpipe_write)
                self.pid = _posixsubprocess.fork_exec(
                        args, executable_list,
                        close_fds, tuple(sorted(map(int, fds_to_keep))),
                        cwd, env_list,
                        p2cread, p2cwrite, c2pread, c2pwrite,
                        errread, errwrite,
                        errpipe_read, errpipe_write,
                        restore_signals, start_new_session, preexec_fn)
                self._child_created = True
            finally:
                # be sure the FD is closed no matter what
                os.close(errpipe_write)
    
            # self._devnull is not always defined.
            devnull_fd = getattr(self, '_devnull', None)
            if p2cread != -1 and p2cwrite != -1 and p2cread != devnull_fd:
                os.close(p2cread)
            if c2pwrite != -1 and c2pread != -1 and c2pwrite != devnull_fd:
                os.close(c2pwrite)
            if errwrite != -1 and errread != -1 and errwrite != devnull_fd:
                os.close(errwrite)
            if devnull_fd is not None:
                os.close(devnull_fd)
            # Prevent a double close of these fds from __init__ on error.
            self._closed_child_pipe_fds = True
    
            # Wait for exec to fail or succeed; possibly raising an
            # exception (limited in size)
            errpipe_data = bytearray()
            while True:
                part = os.read(errpipe_read, 50000)
                errpipe_data += part
                if not part or len(errpipe_data) > 50000:
                    break
        finally:
            # be sure the FD is closed no matter what
            os.close(errpipe_read)
    
        if errpipe_data:
            try:
                pid, sts = os.waitpid(self.pid, 0)
                if pid == self.pid:
                    self._handle_exitstatus(sts)
                else:
                    self.returncode = sys.maxsize
            except ChildProcessError:
                pass
    
            try:
                exception_name, hex_errno, err_msg = (
                        errpipe_data.split(b':', 2))
            except ValueError:
                exception_name = b'SubprocessError'
                hex_errno = b'0'
                err_msg = (b'Bad exception data from child: ' +
                           repr(errpipe_data))
            child_exception_type = getattr(
                    builtins, exception_name.decode('ascii'),
                    SubprocessError)
            err_msg = err_msg.decode(errors="surrogatepass")
            if issubclass(child_exception_type, OSError) and hex_errno:
                errno_num = int(hex_errno, 16)
                child_exec_never_called = (err_msg == "noexec")
                if child_exec_never_called:
                    err_msg = ""
                if errno_num != 0:
                    err_msg = os.strerror(errno_num)
                    if errno_num == errno.ENOENT:
                        if child_exec_never_called:
                            # The error must be from chdir(cwd).
                            err_msg += ': ' + repr(cwd)
                        else:
                            err_msg += ': ' + repr(orig_executable)
>               raise child_exception_type(errno_num, err_msg)
E               FileNotFoundError: [Errno 2] No such file or directory: 'configurable-http-proxy'

../anaconda3/lib/python3.6/subprocess.py:1333: FileNotFoundError

During handling of the above exception, another exception occurred:

request = <SubRequest 'app' for <Function 'test_auth_api'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:832: in start
    self._run_callback(self._callbacks.popleft())
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:605: in _run_callback
    ret = callback()
../anaconda3/lib/python3.6/site-packages/tornado/stack_context.py:277: in null_wrapper
    return fn(*args, **kwargs)
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:436: in run
    result = func()
../anaconda3/lib/python3.6/site-packages/tornado/gen.py:319: in wrapper
    _futures_to_runners[future] = Runner(result, future, yielded)
../anaconda3/lib/python3.6/site-packages/tornado/gen.py:1003: in __init__
    self.run()
../anaconda3/lib/python3.6/site-packages/tornado/gen.py:1069: in run
    yielded = self.gen.send(value)
jupyterhub/tests/conftest.py:62: in make_app
    yield mocked_app.start()
../anaconda3/lib/python3.6/site-packages/tornado/gen.py:319: in wrapper
    _futures_to_runners[future] = Runner(result, future, yielded)
../anaconda3/lib/python3.6/site-packages/tornado/gen.py:1003: in __init__
    self.run()
../anaconda3/lib/python3.6/site-packages/tornado/gen.py:1063: in run
    yielded = self.gen.throw(*exc_info)
jupyterhub/app.py:1553: in start
    self.exit(1)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <jupyterhub.tests.mocking.MockHub object at 0x7fdd742688d0>, exit_status = 1

    def exit(self, exit_status=0):
        self.log.debug("Exiting application: %s" % self.name)
>       sys.exit(exit_status)
E       SystemExit: 1

../anaconda3/lib/python3.6/site-packages/traitlets/config/application.py:648: SystemExit
------------------------------------------ Captured stderr setup -------------------------------------------
[D 45:55.849 MockHub app:1365] Writing PID 27865 to /tmp/tmp9a9x64p_
[I 45:55.852 MockHub app:851] Loading cookie_secret from /home/ec2-user/jupyterhub/jupyterhub_cookie_secret
[D 45:55.852 MockHub app:903] Connecting to db: sqlite:////tmp/tmpws_qwwfd
[D 45:55.862 MockHub orm:475] Stamping empty database with alembic revision 3ec6993fe20c
[I 45:55.867 alembic.runtime.migration migration:117] Context impl SQLiteImpl.
[I 45:55.867 alembic.runtime.migration migration:122] Will assume non-transactional DDL.
[I 45:55.873 alembic.runtime.migration migration:327] Running stamp_revision  -> 3ec6993fe20c
[D 45:55.873 alembic.runtime.migration migration:516] new branch insert 3ec6993fe20c
[I 45:55.953 MockHub app:1000] Not using whitelist. Any authenticated user will be allowed.
[D 45:55.963 MockHub app:1228] Loading state for admin from db
[D 45:55.964 MockHub app:1258] Loaded users: 
       admin admin
[I 45:55.975 MockHub app:1545] Hub API listening on http://127.0.0.1:8081/@/space%20word/hub/
[W 45:55.976 MockHub proxy:415] 
    Generating CONFIGPROXY_AUTH_TOKEN. Restarting the Hub will require restarting the proxy.
    Set CONFIGPROXY_AUTH_TOKEN env or JupyterHub.proxy_auth_token config to avoid this message.
    
[W 45:55.976 MockHub proxy:456] Running JupyterHub without SSL.  I hope there is SSL termination happening somewhere else...
[I 45:55.976 MockHub proxy:458] Starting proxy @ http://127.0.0.1:56525/@/space%20word/
[D 45:55.976 MockHub proxy:459] Proxy cmd: ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '56525', '--api-ip', '127.0.0.1', '--api-port', '8001', '--error-target', 'http://127.0.0.1:8081/@/space%20word/hub/error']
[E 45:55.979 MockHub proxy:467] Failed to find proxy ['configurable-http-proxy']
    The proxy can be installed with `npm install -g configurable-http-proxy`
[C 45:55.980 MockHub app:1552] Failed to start proxy
    Traceback (most recent call last):
      File "/home/ec2-user/jupyterhub/jupyterhub/app.py", line 1550, in start
        yield self.proxy.start()
      File "/home/ec2-user/jupyterhub/jupyterhub/proxy.py", line 462, in start
        self.proxy_process = Popen(cmd, env=env, start_new_session=True, shell=shell)
      File "/home/ec2-user/anaconda3/lib/python3.6/subprocess.py", line 707, in __init__
        restore_signals, start_new_session)
      File "/home/ec2-user/anaconda3/lib/python3.6/subprocess.py", line 1333, in _execute_child
        raise child_exception_type(errno_num, err_msg)
    FileNotFoundError: [Errno 2] No such file or directory: 'configurable-http-proxy'
    
[D 45:55.981 MockHub application:647] Exiting application: jupyterhub
___________________________________ ERROR at setup of test_referer_check ___________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_____________________________________ ERROR at setup of test_get_users _____________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_____________________________________ ERROR at setup of test_add_user ______________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_____________________________________ ERROR at setup of test_get_user ______________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
________________________________ ERROR at setup of test_add_multi_user_bad _________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
______________________________ ERROR at setup of test_add_multi_user_invalid _______________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
__________________________________ ERROR at setup of test_add_multi_user ___________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_______________________________ ERROR at setup of test_add_multi_user_admin ________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
___________________________________ ERROR at setup of test_add_user_bad ____________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_____________________________________ ERROR at setup of test_add_admin _____________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
____________________________________ ERROR at setup of test_delete_user ____________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
____________________________________ ERROR at setup of test_make_admin _____________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_______________________________________ ERROR at setup of test_spawn _______________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
____________________________________ ERROR at setup of test_slow_spawn _____________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
____________________________________ ERROR at setup of test_never_spawn ____________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_____________________________________ ERROR at setup of test_bad_spawn _____________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
__________________________________ ERROR at setup of test_slow_bad_spawn ___________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
____________________________________ ERROR at setup of test_spawn_limit ____________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
________________________________ ERROR at setup of test_active_server_limit ________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
__________________________________ ERROR at setup of test_start_stop_race __________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_____________________________________ ERROR at setup of test_get_proxy _____________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
______________________________________ ERROR at setup of test_cookie _______________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_______________________________________ ERROR at setup of test_token _______________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
____________________________ ERROR at setup of test_get_new_token[headers0-200] ____________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
____________________________ ERROR at setup of test_get_new_token[headers1-403] ____________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
__________________________________ ERROR at setup of test_token_formdata ___________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
__________________________ ERROR at setup of test_token_as_user[admin-other-200] ___________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_________________________ ERROR at setup of test_token_as_user[admin-missing-400] __________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
___________________________ ERROR at setup of test_token_as_user[user-other-403] ___________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
___________________________ ERROR at setup of test_token_as_user[user-user-200] ____________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
____________________________________ ERROR at setup of test_groups_list ____________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_____________________________________ ERROR at setup of test_group_get _____________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
________________________________ ERROR at setup of test_group_create_delete ________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
__________________________________ ERROR at setup of test_group_add_users __________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
________________________________ ERROR at setup of test_group_delete_users _________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
___________________________________ ERROR at setup of test_get_services ____________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
____________________________________ ERROR at setup of test_get_service ____________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_____________________________________ ERROR at setup of test_root_api ______________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_______________________________________ ERROR at setup of test_info ________________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
______________________________________ ERROR at setup of test_options ______________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
___________________________________ ERROR at setup of test_bad_json_body ___________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_____________________________________ ERROR at setup of test_shutdown ______________________________________

request = <SubRequest 'app' for <Function 'test_referer_check'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd74268ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_____________________________________ ERROR at setup of test_handlers ______________________________________

self = <jupyterhub.tests.mocking.MockHub object at 0x7fdd742688d0>

    @gen.coroutine
    def start(self):
        """Start the whole thing"""
        self.io_loop = loop = IOLoop.current()
    
        if self.subapp:
            self.subapp.start()
            loop.stop()
            return
    
        if self.generate_config:
            self.write_config_file()
            loop.stop()
            return
    
        # start the webserver
        self.http_server = tornado.httpserver.HTTPServer(self.tornado_application, xheaders=True)
        try:
            self.http_server.listen(self.hub_port, address=self.hub_ip)
        except Exception:
            self.log.error("Failed to bind hub to %s", self.hub.bind_url)
            raise
        else:
            self.log.info("Hub API listening on %s", self.hub.bind_url)
    
        # start the proxy
        if self.proxy.should_start:
            try:
>               yield self.proxy.start()

jupyterhub/app.py:1550: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tornado.gen.Runner object at 0x7fdd73880748>

    def run(self):
        """Starts or resumes the generator, running until it reaches a
            yield point that is not ready.
            """
        if self.running or self.finished:
            return
        try:
            self.running = True
            while True:
                future = self.future
                if not future.done():
                    return
                self.future = None
                try:
                    orig_stack_contexts = stack_context._state.contexts
                    exc_info = None
    
                    try:
>                       value = future.result()

../anaconda3/lib/python3.6/site-packages/tornado/gen.py:1055: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = None, timeout = None

    def result(self, timeout=None):
        """If the operation succeeded, return its result.  If it failed,
            re-raise its exception.
    
            This method takes a ``timeout`` argument for compatibility with
            `concurrent.futures.Future` but it is an error to call it
            before the `Future` is done, so the ``timeout`` is never used.
            """
        self._clear_tb_log()
        if self._result is not None:
            return self._result
        if self._exc_info is not None:
            try:
>               raise_exc_info(self._exc_info)

../anaconda3/lib/python3.6/site-packages/tornado/concurrent.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

exc_info = None

>   ???

<string>:4: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<jupyterhub.proxy.ConfigurableHTTPProxy object at 0x7fdd735bfdd8>,), kwargs = {}, future = None
result = <generator object start at 0x7fdd73adde60>, orig_stack_contexts = ((), None), yielded = None

    @functools.wraps(wrapped)
    def wrapper(*args, **kwargs):
        future = TracebackFuture()
    
        if replace_callback and 'callback' in kwargs:
            callback = kwargs.pop('callback')
            IOLoop.current().add_future(
                future, lambda future: callback(future.result()))
    
        try:
            result = func(*args, **kwargs)
        except (Return, StopIteration) as e:
            result = _value_from_stopiteration(e)
        except Exception:
            future.set_exc_info(sys.exc_info())
            return future
        else:
            if isinstance(result, GeneratorType):
                # Inline the first iteration of Runner.run.  This lets us
                # avoid the cost of creating a Runner when the coroutine
                # never actually yields, which in turn allows us to
                # use "optional" coroutines in critical path code without
                # performance penalty for the synchronous case.
                try:
                    orig_stack_contexts = stack_context._state.contexts
>                   yielded = next(result)

../anaconda3/lib/python3.6/site-packages/tornado/gen.py:307: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <jupyterhub.proxy.ConfigurableHTTPProxy object at 0x7fdd735bfdd8>

    @gen.coroutine
    def start(self):
        public_server = Server.from_url(self.public_url)
        api_server = Server.from_url(self.api_url)
        env = os.environ.copy()
        env['CONFIGPROXY_AUTH_TOKEN'] = self.auth_token
        cmd = self.command + [
            '--ip', public_server.ip,
            '--port', str(public_server.port),
            '--api-ip', api_server.ip,
            '--api-port', str(api_server.port),
            '--error-target', url_path_join(self.hub.url, 'error'),
        ]
        if self.app.subdomain_host:
            cmd.append('--host-routing')
        if self.debug:
            cmd.extend(['--log-level', 'debug'])
        if self.ssl_key:
            cmd.extend(['--ssl-key', self.ssl_key])
        if self.ssl_cert:
            cmd.extend(['--ssl-cert', self.ssl_cert])
        if self.app.statsd_host:
            cmd.extend([
                '--statsd-host', self.app.statsd_host,
                '--statsd-port', str(self.app.statsd_port),
                '--statsd-prefix', self.app.statsd_prefix + '.chp'
            ])
        # Warn if SSL is not used
        if ' --ssl' not in ' '.join(cmd):
            self.log.warning("Running JupyterHub without SSL."
                             "  I hope there is SSL termination happening somewhere else...")
        self.log.info("Starting proxy @ %s", public_server.bind_url)
        self.log.debug("Proxy cmd: %s", cmd)
        shell = os.name == 'nt'
        try:
>           self.proxy_process = Popen(cmd, env=env, start_new_session=True, shell=shell)

jupyterhub/proxy.py:462: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <subprocess.Popen object at 0x7fdd73880588>
args = ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '56525', '--api-ip', ...], bufsize = -1
executable = None, stdin = None, stdout = None, stderr = None, preexec_fn = None, close_fds = True
shell = False, cwd = None
env = {'COLUMNS': '108', 'CONFIGPROXY_AUTH_TOKEN': 'd8210167d69c460bba61b79d6e25350a', 'CVS_RSH': 'ssh', 'HISTCONTROL': 'ignoredups', ...}
universal_newlines = False, startupinfo = None, creationflags = 0, restore_signals = True
start_new_session = True, pass_fds = ()

    def __init__(self, args, bufsize=-1, executable=None,
                 stdin=None, stdout=None, stderr=None,
                 preexec_fn=None, close_fds=_PLATFORM_DEFAULT_CLOSE_FDS,
                 shell=False, cwd=None, env=None, universal_newlines=False,
                 startupinfo=None, creationflags=0,
                 restore_signals=True, start_new_session=False,
                 pass_fds=(), *, encoding=None, errors=None):
        """Create new Popen instance."""
        _cleanup()
        # Held while anything is calling waitpid before returncode has been
        # updated to prevent clobbering returncode if wait() or poll() are
        # called from multiple threads at once.  After acquiring the lock,
        # code must re-check self.returncode to see if another thread just
        # finished a waitpid() call.
        self._waitpid_lock = threading.Lock()
    
        self._input = None
        self._communication_started = False
        if bufsize is None:
            bufsize = -1  # Restore default
        if not isinstance(bufsize, int):
            raise TypeError("bufsize must be an integer")
    
        if _mswindows:
            if preexec_fn is not None:
                raise ValueError("preexec_fn is not supported on Windows "
                                 "platforms")
            any_stdio_set = (stdin is not None or stdout is not None or
                             stderr is not None)
            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:
                if any_stdio_set:
                    close_fds = False
                else:
                    close_fds = True
            elif close_fds and any_stdio_set:
                raise ValueError(
                        "close_fds is not supported on Windows platforms"
                        " if you redirect stdin/stdout/stderr")
        else:
            # POSIX
            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:
                close_fds = True
            if pass_fds and not close_fds:
                warnings.warn("pass_fds overriding close_fds.", RuntimeWarning)
                close_fds = True
            if startupinfo is not None:
                raise ValueError("startupinfo is only supported on Windows "
                                 "platforms")
            if creationflags != 0:
                raise ValueError("creationflags is only supported on Windows "
                                 "platforms")
    
        self.args = args
        self.stdin = None
        self.stdout = None
        self.stderr = None
        self.pid = None
        self.returncode = None
        self.universal_newlines = universal_newlines
        self.encoding = encoding
        self.errors = errors
    
        # Input and output objects. The general principle is like
        # this:
        #
        # Parent                   Child
        # ------                   -----
        # p2cwrite   ---stdin--->  p2cread
        # c2pread    <--stdout---  c2pwrite
        # errread    <--stderr---  errwrite
        #
        # On POSIX, the child objects are file descriptors.  On
        # Windows, these are Windows file handles.  The parent objects
        # are file descriptors on both platforms.  The parent objects
        # are -1 when not using PIPEs. The child objects are -1
        # when not redirecting.
    
        (p2cread, p2cwrite,
         c2pread, c2pwrite,
         errread, errwrite) = self._get_handles(stdin, stdout, stderr)
    
        # We wrap OS handles *before* launching the child, otherwise a
        # quickly terminating child could make our fds unwrappable
        # (see #8458).
    
        if _mswindows:
            if p2cwrite != -1:
                p2cwrite = msvcrt.open_osfhandle(p2cwrite.Detach(), 0)
            if c2pread != -1:
                c2pread = msvcrt.open_osfhandle(c2pread.Detach(), 0)
            if errread != -1:
                errread = msvcrt.open_osfhandle(errread.Detach(), 0)
    
        text_mode = encoding or errors or universal_newlines
    
        self._closed_child_pipe_fds = False
    
        try:
            if p2cwrite != -1:
                self.stdin = io.open(p2cwrite, 'wb', bufsize)
                if text_mode:
                    self.stdin = io.TextIOWrapper(self.stdin, write_through=True,
                            line_buffering=(bufsize == 1),
                            encoding=encoding, errors=errors)
            if c2pread != -1:
                self.stdout = io.open(c2pread, 'rb', bufsize)
                if text_mode:
                    self.stdout = io.TextIOWrapper(self.stdout,
                            encoding=encoding, errors=errors)
            if errread != -1:
                self.stderr = io.open(errread, 'rb', bufsize)
                if text_mode:
                    self.stderr = io.TextIOWrapper(self.stderr,
                            encoding=encoding, errors=errors)
    
            self._execute_child(args, executable, preexec_fn, close_fds,
                                pass_fds, cwd, env,
                                startupinfo, creationflags, shell,
                                p2cread, p2cwrite,
                                c2pread, c2pwrite,
                                errread, errwrite,
>                               restore_signals, start_new_session)

../anaconda3/lib/python3.6/subprocess.py:707: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <subprocess.Popen object at 0x7fdd73880588>
args = ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '56525', '--api-ip', ...]
executable = b'configurable-http-proxy', preexec_fn = None, close_fds = True, pass_fds = (), cwd = None
env = {'COLUMNS': '108', 'CONFIGPROXY_AUTH_TOKEN': 'd8210167d69c460bba61b79d6e25350a', 'CVS_RSH': 'ssh', 'HISTCONTROL': 'ignoredups', ...}
startupinfo = None, creationflags = 0, shell = False, p2cread = -1, p2cwrite = -1, c2pread = -1
c2pwrite = -1, errread = -1, errwrite = -1, restore_signals = True, start_new_session = True

    def _execute_child(self, args, executable, preexec_fn, close_fds,
                       pass_fds, cwd, env,
                       startupinfo, creationflags, shell,
                       p2cread, p2cwrite,
                       c2pread, c2pwrite,
                       errread, errwrite,
                       restore_signals, start_new_session):
        """Execute program (POSIX version)"""
    
        if isinstance(args, (str, bytes)):
            args = [args]
        else:
            args = list(args)
    
        if shell:
            args = ["/bin/sh", "-c"] + args
            if executable:
                args[0] = executable
    
        if executable is None:
            executable = args[0]
        orig_executable = executable
    
        # For transferring possible exec failure from child to parent.
        # Data format: "exception name:hex errno:description"
        # Pickle is not used; it is complex and involves memory allocation.
        errpipe_read, errpipe_write = os.pipe()
        # errpipe_write must not be in the standard io 0, 1, or 2 fd range.
        low_fds_to_close = []
        while errpipe_write < 3:
            low_fds_to_close.append(errpipe_write)
            errpipe_write = os.dup(errpipe_write)
        for low_fd in low_fds_to_close:
            os.close(low_fd)
        try:
            try:
                # We must avoid complex work that could involve
                # malloc or free in the child process to avoid
                # potential deadlocks, thus we do all this here.
                # and pass it to fork_exec()
    
                if env is not None:
                    env_list = []
                    for k, v in env.items():
                        k = os.fsencode(k)
                        if b'=' in k:
                            raise ValueError("illegal environment variable name")
                        env_list.append(k + b'=' + os.fsencode(v))
                else:
                    env_list = None  # Use execv instead of execve.
                executable = os.fsencode(executable)
                if os.path.dirname(executable):
                    executable_list = (executable,)
                else:
                    # This matches the behavior of os._execvpe().
                    executable_list = tuple(
                        os.path.join(os.fsencode(dir), executable)
                        for dir in os.get_exec_path(env))
                fds_to_keep = set(pass_fds)
                fds_to_keep.add(errpipe_write)
                self.pid = _posixsubprocess.fork_exec(
                        args, executable_list,
                        close_fds, tuple(sorted(map(int, fds_to_keep))),
                        cwd, env_list,
                        p2cread, p2cwrite, c2pread, c2pwrite,
                        errread, errwrite,
                        errpipe_read, errpipe_write,
                        restore_signals, start_new_session, preexec_fn)
                self._child_created = True
            finally:
                # be sure the FD is closed no matter what
                os.close(errpipe_write)
    
            # self._devnull is not always defined.
            devnull_fd = getattr(self, '_devnull', None)
            if p2cread != -1 and p2cwrite != -1 and p2cread != devnull_fd:
                os.close(p2cread)
            if c2pwrite != -1 and c2pread != -1 and c2pwrite != devnull_fd:
                os.close(c2pwrite)
            if errwrite != -1 and errread != -1 and errwrite != devnull_fd:
                os.close(errwrite)
            if devnull_fd is not None:
                os.close(devnull_fd)
            # Prevent a double close of these fds from __init__ on error.
            self._closed_child_pipe_fds = True
    
            # Wait for exec to fail or succeed; possibly raising an
            # exception (limited in size)
            errpipe_data = bytearray()
            while True:
                part = os.read(errpipe_read, 50000)
                errpipe_data += part
                if not part or len(errpipe_data) > 50000:
                    break
        finally:
            # be sure the FD is closed no matter what
            os.close(errpipe_read)
    
        if errpipe_data:
            try:
                pid, sts = os.waitpid(self.pid, 0)
                if pid == self.pid:
                    self._handle_exitstatus(sts)
                else:
                    self.returncode = sys.maxsize
            except ChildProcessError:
                pass
    
            try:
                exception_name, hex_errno, err_msg = (
                        errpipe_data.split(b':', 2))
            except ValueError:
                exception_name = b'SubprocessError'
                hex_errno = b'0'
                err_msg = (b'Bad exception data from child: ' +
                           repr(errpipe_data))
            child_exception_type = getattr(
                    builtins, exception_name.decode('ascii'),
                    SubprocessError)
            err_msg = err_msg.decode(errors="surrogatepass")
            if issubclass(child_exception_type, OSError) and hex_errno:
                errno_num = int(hex_errno, 16)
                child_exec_never_called = (err_msg == "noexec")
                if child_exec_never_called:
                    err_msg = ""
                if errno_num != 0:
                    err_msg = os.strerror(errno_num)
                    if errno_num == errno.ENOENT:
                        if child_exec_never_called:
                            # The error must be from chdir(cwd).
                            err_msg += ': ' + repr(cwd)
                        else:
                            err_msg += ': ' + repr(orig_executable)
>               raise child_exception_type(errno_num, err_msg)
E               FileNotFoundError: [Errno 2] No such file or directory: 'configurable-http-proxy'

../anaconda3/lib/python3.6/subprocess.py:1333: FileNotFoundError

During handling of the above exception, another exception occurred:

request = <SubRequest 'app' for <Function 'test_handlers'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd735cec88>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:832: in start
    self._run_callback(self._callbacks.popleft())
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:605: in _run_callback
    ret = callback()
../anaconda3/lib/python3.6/site-packages/tornado/stack_context.py:277: in null_wrapper
    return fn(*args, **kwargs)
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:436: in run
    result = func()
../anaconda3/lib/python3.6/site-packages/tornado/gen.py:319: in wrapper
    _futures_to_runners[future] = Runner(result, future, yielded)
../anaconda3/lib/python3.6/site-packages/tornado/gen.py:1003: in __init__
    self.run()
../anaconda3/lib/python3.6/site-packages/tornado/gen.py:1069: in run
    yielded = self.gen.send(value)
jupyterhub/tests/conftest.py:62: in make_app
    yield mocked_app.start()
../anaconda3/lib/python3.6/site-packages/tornado/gen.py:319: in wrapper
    _futures_to_runners[future] = Runner(result, future, yielded)
../anaconda3/lib/python3.6/site-packages/tornado/gen.py:1003: in __init__
    self.run()
../anaconda3/lib/python3.6/site-packages/tornado/gen.py:1063: in run
    yielded = self.gen.throw(*exc_info)
jupyterhub/app.py:1553: in start
    self.exit(1)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <jupyterhub.tests.mocking.MockHub object at 0x7fdd742688d0>, exit_status = 1

    def exit(self, exit_status=0):
        self.log.debug("Exiting application: %s" % self.name)
>       sys.exit(exit_status)
E       SystemExit: 1

../anaconda3/lib/python3.6/site-packages/traitlets/config/application.py:648: SystemExit
------------------------------------------ Captured stderr setup -------------------------------------------
[I 46:01.058 alembic.runtime.migration migration:117] Context impl SQLiteImpl.
[I 46:01.058 alembic.runtime.migration migration:122] Will assume non-transactional DDL.
[I 46:01.064 alembic.runtime.migration migration:327] Running stamp_revision  -> 3ec6993fe20c
[I 46:01.128 MockHub app:1000] Not using whitelist. Any authenticated user will be allowed.
[I 46:01.144 MockHub app:1545] Hub API listening on http://127.0.0.1:8081/@/space%20word/hub/
[W 46:01.145 MockHub proxy:415] 
    Generating CONFIGPROXY_AUTH_TOKEN. Restarting the Hub will require restarting the proxy.
    Set CONFIGPROXY_AUTH_TOKEN env or JupyterHub.proxy_auth_token config to avoid this message.
    
[W 46:01.145 MockHub proxy:456] Running JupyterHub without SSL.  I hope there is SSL termination happening somewhere else...
[I 46:01.145 MockHub proxy:458] Starting proxy @ http://127.0.0.1:56525/@/space%20word/
[E 46:01.148 MockHub proxy:467] Failed to find proxy ['configurable-http-proxy']
    The proxy can be installed with `npm install -g configurable-http-proxy`
[C 46:01.148 MockHub app:1552] Failed to start proxy
    Traceback (most recent call last):
      File "/home/ec2-user/jupyterhub/jupyterhub/app.py", line 1550, in start
        yield self.proxy.start()
      File "/home/ec2-user/jupyterhub/jupyterhub/proxy.py", line 462, in start
        self.proxy_process = Popen(cmd, env=env, start_new_session=True, shell=shell)
      File "/home/ec2-user/anaconda3/lib/python3.6/subprocess.py", line 707, in __init__
        restore_signals, start_new_session)
      File "/home/ec2-user/anaconda3/lib/python3.6/subprocess.py", line 1333, in _execute_child
        raise child_exception_type(errno_num, err_msg)
    FileNotFoundError: [Errno 2] No such file or directory: 'configurable-http-proxy'
    
____________________________________ ERROR at setup of test_auth_state _____________________________________

request = <SubRequest 'app' for <Function 'test_auth_state'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd735cec88>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd735cec88>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
________________________________ ERROR at setup of test_auth_state_disabled ________________________________

request = <SubRequest 'app' for <Function 'test_auth_state'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd735cec88>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd735cec88>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
__________________________________ ERROR at setup of test_default_server ___________________________________

self = <jupyterhub.tests.mocking.MockHub object at 0x7fdd742688d0>

    @gen.coroutine
    def start(self):
        """Start the whole thing"""
        self.io_loop = loop = IOLoop.current()
    
        if self.subapp:
            self.subapp.start()
            loop.stop()
            return
    
        if self.generate_config:
            self.write_config_file()
            loop.stop()
            return
    
        # start the webserver
        self.http_server = tornado.httpserver.HTTPServer(self.tornado_application, xheaders=True)
        try:
            self.http_server.listen(self.hub_port, address=self.hub_ip)
        except Exception:
            self.log.error("Failed to bind hub to %s", self.hub.bind_url)
            raise
        else:
            self.log.info("Hub API listening on %s", self.hub.bind_url)
    
        # start the proxy
        if self.proxy.should_start:
            try:
>               yield self.proxy.start()

/home/ec2-user/jupyterhub/jupyterhub/app.py:1550: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tornado.gen.Runner object at 0x7fdd738c37b8>

    def run(self):
        """Starts or resumes the generator, running until it reaches a
            yield point that is not ready.
            """
        if self.running or self.finished:
            return
        try:
            self.running = True
            while True:
                future = self.future
                if not future.done():
                    return
                self.future = None
                try:
                    orig_stack_contexts = stack_context._state.contexts
                    exc_info = None
    
                    try:
>                       value = future.result()

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1055: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = None, timeout = None

    def result(self, timeout=None):
        """If the operation succeeded, return its result.  If it failed,
            re-raise its exception.
    
            This method takes a ``timeout`` argument for compatibility with
            `concurrent.futures.Future` but it is an error to call it
            before the `Future` is done, so the ``timeout`` is never used.
            """
        self._clear_tb_log()
        if self._result is not None:
            return self._result
        if self._exc_info is not None:
            try:
>               raise_exc_info(self._exc_info)

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/concurrent.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

exc_info = None

>   ???

<string>:4: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<jupyterhub.proxy.ConfigurableHTTPProxy object at 0x7fdd735ec908>,), kwargs = {}, future = None
result = <generator object start at 0x7fdd7379e9e8>, orig_stack_contexts = ((), None), yielded = None

    @functools.wraps(wrapped)
    def wrapper(*args, **kwargs):
        future = TracebackFuture()
    
        if replace_callback and 'callback' in kwargs:
            callback = kwargs.pop('callback')
            IOLoop.current().add_future(
                future, lambda future: callback(future.result()))
    
        try:
            result = func(*args, **kwargs)
        except (Return, StopIteration) as e:
            result = _value_from_stopiteration(e)
        except Exception:
            future.set_exc_info(sys.exc_info())
            return future
        else:
            if isinstance(result, GeneratorType):
                # Inline the first iteration of Runner.run.  This lets us
                # avoid the cost of creating a Runner when the coroutine
                # never actually yields, which in turn allows us to
                # use "optional" coroutines in critical path code without
                # performance penalty for the synchronous case.
                try:
                    orig_stack_contexts = stack_context._state.contexts
>                   yielded = next(result)

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:307: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <jupyterhub.proxy.ConfigurableHTTPProxy object at 0x7fdd735ec908>

    @gen.coroutine
    def start(self):
        public_server = Server.from_url(self.public_url)
        api_server = Server.from_url(self.api_url)
        env = os.environ.copy()
        env['CONFIGPROXY_AUTH_TOKEN'] = self.auth_token
        cmd = self.command + [
            '--ip', public_server.ip,
            '--port', str(public_server.port),
            '--api-ip', api_server.ip,
            '--api-port', str(api_server.port),
            '--error-target', url_path_join(self.hub.url, 'error'),
        ]
        if self.app.subdomain_host:
            cmd.append('--host-routing')
        if self.debug:
            cmd.extend(['--log-level', 'debug'])
        if self.ssl_key:
            cmd.extend(['--ssl-key', self.ssl_key])
        if self.ssl_cert:
            cmd.extend(['--ssl-cert', self.ssl_cert])
        if self.app.statsd_host:
            cmd.extend([
                '--statsd-host', self.app.statsd_host,
                '--statsd-port', str(self.app.statsd_port),
                '--statsd-prefix', self.app.statsd_prefix + '.chp'
            ])
        # Warn if SSL is not used
        if ' --ssl' not in ' '.join(cmd):
            self.log.warning("Running JupyterHub without SSL."
                             "  I hope there is SSL termination happening somewhere else...")
        self.log.info("Starting proxy @ %s", public_server.bind_url)
        self.log.debug("Proxy cmd: %s", cmd)
        shell = os.name == 'nt'
        try:
>           self.proxy_process = Popen(cmd, env=env, start_new_session=True, shell=shell)

/home/ec2-user/jupyterhub/jupyterhub/proxy.py:462: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <subprocess.Popen object at 0x7fdd738c3278>
args = ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '56525', '--api-ip', ...], bufsize = -1
executable = None, stdin = None, stdout = None, stderr = None, preexec_fn = None, close_fds = True
shell = False, cwd = None
env = {'COLUMNS': '108', 'CONFIGPROXY_AUTH_TOKEN': 'd83e4a16abde41758cc185baf8d2a3e2', 'CVS_RSH': 'ssh', 'HISTCONTROL': 'ignoredups', ...}
universal_newlines = False, startupinfo = None, creationflags = 0, restore_signals = True
start_new_session = True, pass_fds = ()

    def __init__(self, args, bufsize=-1, executable=None,
                 stdin=None, stdout=None, stderr=None,
                 preexec_fn=None, close_fds=_PLATFORM_DEFAULT_CLOSE_FDS,
                 shell=False, cwd=None, env=None, universal_newlines=False,
                 startupinfo=None, creationflags=0,
                 restore_signals=True, start_new_session=False,
                 pass_fds=(), *, encoding=None, errors=None):
        """Create new Popen instance."""
        _cleanup()
        # Held while anything is calling waitpid before returncode has been
        # updated to prevent clobbering returncode if wait() or poll() are
        # called from multiple threads at once.  After acquiring the lock,
        # code must re-check self.returncode to see if another thread just
        # finished a waitpid() call.
        self._waitpid_lock = threading.Lock()
    
        self._input = None
        self._communication_started = False
        if bufsize is None:
            bufsize = -1  # Restore default
        if not isinstance(bufsize, int):
            raise TypeError("bufsize must be an integer")
    
        if _mswindows:
            if preexec_fn is not None:
                raise ValueError("preexec_fn is not supported on Windows "
                                 "platforms")
            any_stdio_set = (stdin is not None or stdout is not None or
                             stderr is not None)
            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:
                if any_stdio_set:
                    close_fds = False
                else:
                    close_fds = True
            elif close_fds and any_stdio_set:
                raise ValueError(
                        "close_fds is not supported on Windows platforms"
                        " if you redirect stdin/stdout/stderr")
        else:
            # POSIX
            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:
                close_fds = True
            if pass_fds and not close_fds:
                warnings.warn("pass_fds overriding close_fds.", RuntimeWarning)
                close_fds = True
            if startupinfo is not None:
                raise ValueError("startupinfo is only supported on Windows "
                                 "platforms")
            if creationflags != 0:
                raise ValueError("creationflags is only supported on Windows "
                                 "platforms")
    
        self.args = args
        self.stdin = None
        self.stdout = None
        self.stderr = None
        self.pid = None
        self.returncode = None
        self.universal_newlines = universal_newlines
        self.encoding = encoding
        self.errors = errors
    
        # Input and output objects. The general principle is like
        # this:
        #
        # Parent                   Child
        # ------                   -----
        # p2cwrite   ---stdin--->  p2cread
        # c2pread    <--stdout---  c2pwrite
        # errread    <--stderr---  errwrite
        #
        # On POSIX, the child objects are file descriptors.  On
        # Windows, these are Windows file handles.  The parent objects
        # are file descriptors on both platforms.  The parent objects
        # are -1 when not using PIPEs. The child objects are -1
        # when not redirecting.
    
        (p2cread, p2cwrite,
         c2pread, c2pwrite,
         errread, errwrite) = self._get_handles(stdin, stdout, stderr)
    
        # We wrap OS handles *before* launching the child, otherwise a
        # quickly terminating child could make our fds unwrappable
        # (see #8458).
    
        if _mswindows:
            if p2cwrite != -1:
                p2cwrite = msvcrt.open_osfhandle(p2cwrite.Detach(), 0)
            if c2pread != -1:
                c2pread = msvcrt.open_osfhandle(c2pread.Detach(), 0)
            if errread != -1:
                errread = msvcrt.open_osfhandle(errread.Detach(), 0)
    
        text_mode = encoding or errors or universal_newlines
    
        self._closed_child_pipe_fds = False
    
        try:
            if p2cwrite != -1:
                self.stdin = io.open(p2cwrite, 'wb', bufsize)
                if text_mode:
                    self.stdin = io.TextIOWrapper(self.stdin, write_through=True,
                            line_buffering=(bufsize == 1),
                            encoding=encoding, errors=errors)
            if c2pread != -1:
                self.stdout = io.open(c2pread, 'rb', bufsize)
                if text_mode:
                    self.stdout = io.TextIOWrapper(self.stdout,
                            encoding=encoding, errors=errors)
            if errread != -1:
                self.stderr = io.open(errread, 'rb', bufsize)
                if text_mode:
                    self.stderr = io.TextIOWrapper(self.stderr,
                            encoding=encoding, errors=errors)
    
            self._execute_child(args, executable, preexec_fn, close_fds,
                                pass_fds, cwd, env,
                                startupinfo, creationflags, shell,
                                p2cread, p2cwrite,
                                c2pread, c2pwrite,
                                errread, errwrite,
>                               restore_signals, start_new_session)

/home/ec2-user/anaconda3/lib/python3.6/subprocess.py:707: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <subprocess.Popen object at 0x7fdd738c3278>
args = ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '56525', '--api-ip', ...]
executable = b'configurable-http-proxy', preexec_fn = None, close_fds = True, pass_fds = (), cwd = None
env = {'COLUMNS': '108', 'CONFIGPROXY_AUTH_TOKEN': 'd83e4a16abde41758cc185baf8d2a3e2', 'CVS_RSH': 'ssh', 'HISTCONTROL': 'ignoredups', ...}
startupinfo = None, creationflags = 0, shell = False, p2cread = -1, p2cwrite = -1, c2pread = -1
c2pwrite = -1, errread = -1, errwrite = -1, restore_signals = True, start_new_session = True

    def _execute_child(self, args, executable, preexec_fn, close_fds,
                       pass_fds, cwd, env,
                       startupinfo, creationflags, shell,
                       p2cread, p2cwrite,
                       c2pread, c2pwrite,
                       errread, errwrite,
                       restore_signals, start_new_session):
        """Execute program (POSIX version)"""
    
        if isinstance(args, (str, bytes)):
            args = [args]
        else:
            args = list(args)
    
        if shell:
            args = ["/bin/sh", "-c"] + args
            if executable:
                args[0] = executable
    
        if executable is None:
            executable = args[0]
        orig_executable = executable
    
        # For transferring possible exec failure from child to parent.
        # Data format: "exception name:hex errno:description"
        # Pickle is not used; it is complex and involves memory allocation.
        errpipe_read, errpipe_write = os.pipe()
        # errpipe_write must not be in the standard io 0, 1, or 2 fd range.
        low_fds_to_close = []
        while errpipe_write < 3:
            low_fds_to_close.append(errpipe_write)
            errpipe_write = os.dup(errpipe_write)
        for low_fd in low_fds_to_close:
            os.close(low_fd)
        try:
            try:
                # We must avoid complex work that could involve
                # malloc or free in the child process to avoid
                # potential deadlocks, thus we do all this here.
                # and pass it to fork_exec()
    
                if env is not None:
                    env_list = []
                    for k, v in env.items():
                        k = os.fsencode(k)
                        if b'=' in k:
                            raise ValueError("illegal environment variable name")
                        env_list.append(k + b'=' + os.fsencode(v))
                else:
                    env_list = None  # Use execv instead of execve.
                executable = os.fsencode(executable)
                if os.path.dirname(executable):
                    executable_list = (executable,)
                else:
                    # This matches the behavior of os._execvpe().
                    executable_list = tuple(
                        os.path.join(os.fsencode(dir), executable)
                        for dir in os.get_exec_path(env))
                fds_to_keep = set(pass_fds)
                fds_to_keep.add(errpipe_write)
                self.pid = _posixsubprocess.fork_exec(
                        args, executable_list,
                        close_fds, tuple(sorted(map(int, fds_to_keep))),
                        cwd, env_list,
                        p2cread, p2cwrite, c2pread, c2pwrite,
                        errread, errwrite,
                        errpipe_read, errpipe_write,
                        restore_signals, start_new_session, preexec_fn)
                self._child_created = True
            finally:
                # be sure the FD is closed no matter what
                os.close(errpipe_write)
    
            # self._devnull is not always defined.
            devnull_fd = getattr(self, '_devnull', None)
            if p2cread != -1 and p2cwrite != -1 and p2cread != devnull_fd:
                os.close(p2cread)
            if c2pwrite != -1 and c2pread != -1 and c2pwrite != devnull_fd:
                os.close(c2pwrite)
            if errwrite != -1 and errread != -1 and errwrite != devnull_fd:
                os.close(errwrite)
            if devnull_fd is not None:
                os.close(devnull_fd)
            # Prevent a double close of these fds from __init__ on error.
            self._closed_child_pipe_fds = True
    
            # Wait for exec to fail or succeed; possibly raising an
            # exception (limited in size)
            errpipe_data = bytearray()
            while True:
                part = os.read(errpipe_read, 50000)
                errpipe_data += part
                if not part or len(errpipe_data) > 50000:
                    break
        finally:
            # be sure the FD is closed no matter what
            os.close(errpipe_read)
    
        if errpipe_data:
            try:
                pid, sts = os.waitpid(self.pid, 0)
                if pid == self.pid:
                    self._handle_exitstatus(sts)
                else:
                    self.returncode = sys.maxsize
            except ChildProcessError:
                pass
    
            try:
                exception_name, hex_errno, err_msg = (
                        errpipe_data.split(b':', 2))
            except ValueError:
                exception_name = b'SubprocessError'
                hex_errno = b'0'
                err_msg = (b'Bad exception data from child: ' +
                           repr(errpipe_data))
            child_exception_type = getattr(
                    builtins, exception_name.decode('ascii'),
                    SubprocessError)
            err_msg = err_msg.decode(errors="surrogatepass")
            if issubclass(child_exception_type, OSError) and hex_errno:
                errno_num = int(hex_errno, 16)
                child_exec_never_called = (err_msg == "noexec")
                if child_exec_never_called:
                    err_msg = ""
                if errno_num != 0:
                    err_msg = os.strerror(errno_num)
                    if errno_num == errno.ENOENT:
                        if child_exec_never_called:
                            # The error must be from chdir(cwd).
                            err_msg += ': ' + repr(cwd)
                        else:
                            err_msg += ': ' + repr(orig_executable)
>               raise child_exception_type(errno_num, err_msg)
E               FileNotFoundError: [Errno 2] No such file or directory: 'configurable-http-proxy'

/home/ec2-user/anaconda3/lib/python3.6/subprocess.py:1333: FileNotFoundError

During handling of the above exception, another exception occurred:

request = <SubRequest 'app' for <Function 'test_default_server'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd735ce438>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:832: in start
    self._run_callback(self._callbacks.popleft())
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:605: in _run_callback
    ret = callback()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py:277: in null_wrapper
    return fn(*args, **kwargs)
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:436: in run
    result = func()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:319: in wrapper
    _futures_to_runners[future] = Runner(result, future, yielded)
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1003: in __init__
    self.run()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1069: in run
    yielded = self.gen.send(value)
/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:62: in make_app
    yield mocked_app.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:319: in wrapper
    _futures_to_runners[future] = Runner(result, future, yielded)
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1003: in __init__
    self.run()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1063: in run
    yielded = self.gen.throw(*exc_info)
/home/ec2-user/jupyterhub/jupyterhub/app.py:1553: in start
    self.exit(1)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <jupyterhub.tests.mocking.MockHub object at 0x7fdd742688d0>, exit_status = 1

    def exit(self, exit_status=0):
        self.log.debug("Exiting application: %s" % self.name)
>       sys.exit(exit_status)
E       SystemExit: 1

/home/ec2-user/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py:648: SystemExit
------------------------------------------ Captured stderr setup -------------------------------------------
[I 46:02.225 alembic.runtime.migration migration:117] Context impl SQLiteImpl.
[I 46:02.225 alembic.runtime.migration migration:122] Will assume non-transactional DDL.
[I 46:02.232 alembic.runtime.migration migration:327] Running stamp_revision  -> 3ec6993fe20c
[I 46:02.302 MockHub app:1000] Not using whitelist. Any authenticated user will be allowed.
[I 46:02.320 MockHub app:1545] Hub API listening on http://127.0.0.1:8081/@/space%20word/hub/
[W 46:02.321 MockHub proxy:415] 
    Generating CONFIGPROXY_AUTH_TOKEN. Restarting the Hub will require restarting the proxy.
    Set CONFIGPROXY_AUTH_TOKEN env or JupyterHub.proxy_auth_token config to avoid this message.
    
[W 46:02.321 MockHub proxy:456] Running JupyterHub without SSL.  I hope there is SSL termination happening somewhere else...
[I 46:02.321 MockHub proxy:458] Starting proxy @ http://127.0.0.1:56525/@/space%20word/
[E 46:02.324 MockHub proxy:467] Failed to find proxy ['configurable-http-proxy']
    The proxy can be installed with `npm install -g configurable-http-proxy`
[C 46:02.325 MockHub app:1552] Failed to start proxy
    Traceback (most recent call last):
      File "/home/ec2-user/jupyterhub/jupyterhub/app.py", line 1550, in start
        yield self.proxy.start()
      File "/home/ec2-user/jupyterhub/jupyterhub/proxy.py", line 462, in start
        self.proxy_process = Popen(cmd, env=env, start_new_session=True, shell=shell)
      File "/home/ec2-user/anaconda3/lib/python3.6/subprocess.py", line 707, in __init__
        restore_signals, start_new_session)
      File "/home/ec2-user/anaconda3/lib/python3.6/subprocess.py", line 1333, in _execute_child
        raise child_exception_type(errno_num, err_msg)
    FileNotFoundError: [Errno 2] No such file or directory: 'configurable-http-proxy'
    
________________________________ ERROR at setup of test_create_named_server ________________________________

request = <SubRequest 'app' for <Function 'test_create_named_server'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd735ce438>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd735ce438>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
________________________________ ERROR at setup of test_delete_named_server ________________________________

request = <SubRequest 'app' for <Function 'test_create_named_server'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd735ce438>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd735ce438>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_______________________________ ERROR at setup of test_named_server_disabled _______________________________

request = <SubRequest 'app' for <Function 'test_create_named_server'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd735ce438>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd735ce438>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
___________________________________ ERROR at setup of test_root_no_auth ____________________________________

self = <jupyterhub.tests.mocking.MockHub object at 0x7fdd742688d0>

    @gen.coroutine
    def start(self):
        """Start the whole thing"""
        self.io_loop = loop = IOLoop.current()
    
        if self.subapp:
            self.subapp.start()
            loop.stop()
            return
    
        if self.generate_config:
            self.write_config_file()
            loop.stop()
            return
    
        # start the webserver
        self.http_server = tornado.httpserver.HTTPServer(self.tornado_application, xheaders=True)
        try:
            self.http_server.listen(self.hub_port, address=self.hub_ip)
        except Exception:
            self.log.error("Failed to bind hub to %s", self.hub.bind_url)
            raise
        else:
            self.log.info("Hub API listening on %s", self.hub.bind_url)
    
        # start the proxy
        if self.proxy.should_start:
            try:
>               yield self.proxy.start()

/home/ec2-user/jupyterhub/jupyterhub/app.py:1550: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tornado.gen.Runner object at 0x7fdd73857198>

    def run(self):
        """Starts or resumes the generator, running until it reaches a
            yield point that is not ready.
            """
        if self.running or self.finished:
            return
        try:
            self.running = True
            while True:
                future = self.future
                if not future.done():
                    return
                self.future = None
                try:
                    orig_stack_contexts = stack_context._state.contexts
                    exc_info = None
    
                    try:
>                       value = future.result()

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1055: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = None, timeout = None

    def result(self, timeout=None):
        """If the operation succeeded, return its result.  If it failed,
            re-raise its exception.
    
            This method takes a ``timeout`` argument for compatibility with
            `concurrent.futures.Future` but it is an error to call it
            before the `Future` is done, so the ``timeout`` is never used.
            """
        self._clear_tb_log()
        if self._result is not None:
            return self._result
        if self._exc_info is not None:
            try:
>               raise_exc_info(self._exc_info)

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/concurrent.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

exc_info = None

>   ???

<string>:4: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<jupyterhub.proxy.ConfigurableHTTPProxy object at 0x7fdd7386eb00>,), kwargs = {}, future = None
result = <generator object start at 0x7fdd734aa678>, orig_stack_contexts = ((), None), yielded = None

    @functools.wraps(wrapped)
    def wrapper(*args, **kwargs):
        future = TracebackFuture()
    
        if replace_callback and 'callback' in kwargs:
            callback = kwargs.pop('callback')
            IOLoop.current().add_future(
                future, lambda future: callback(future.result()))
    
        try:
            result = func(*args, **kwargs)
        except (Return, StopIteration) as e:
            result = _value_from_stopiteration(e)
        except Exception:
            future.set_exc_info(sys.exc_info())
            return future
        else:
            if isinstance(result, GeneratorType):
                # Inline the first iteration of Runner.run.  This lets us
                # avoid the cost of creating a Runner when the coroutine
                # never actually yields, which in turn allows us to
                # use "optional" coroutines in critical path code without
                # performance penalty for the synchronous case.
                try:
                    orig_stack_contexts = stack_context._state.contexts
>                   yielded = next(result)

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:307: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <jupyterhub.proxy.ConfigurableHTTPProxy object at 0x7fdd7386eb00>

    @gen.coroutine
    def start(self):
        public_server = Server.from_url(self.public_url)
        api_server = Server.from_url(self.api_url)
        env = os.environ.copy()
        env['CONFIGPROXY_AUTH_TOKEN'] = self.auth_token
        cmd = self.command + [
            '--ip', public_server.ip,
            '--port', str(public_server.port),
            '--api-ip', api_server.ip,
            '--api-port', str(api_server.port),
            '--error-target', url_path_join(self.hub.url, 'error'),
        ]
        if self.app.subdomain_host:
            cmd.append('--host-routing')
        if self.debug:
            cmd.extend(['--log-level', 'debug'])
        if self.ssl_key:
            cmd.extend(['--ssl-key', self.ssl_key])
        if self.ssl_cert:
            cmd.extend(['--ssl-cert', self.ssl_cert])
        if self.app.statsd_host:
            cmd.extend([
                '--statsd-host', self.app.statsd_host,
                '--statsd-port', str(self.app.statsd_port),
                '--statsd-prefix', self.app.statsd_prefix + '.chp'
            ])
        # Warn if SSL is not used
        if ' --ssl' not in ' '.join(cmd):
            self.log.warning("Running JupyterHub without SSL."
                             "  I hope there is SSL termination happening somewhere else...")
        self.log.info("Starting proxy @ %s", public_server.bind_url)
        self.log.debug("Proxy cmd: %s", cmd)
        shell = os.name == 'nt'
        try:
>           self.proxy_process = Popen(cmd, env=env, start_new_session=True, shell=shell)

/home/ec2-user/jupyterhub/jupyterhub/proxy.py:462: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <subprocess.Popen object at 0x7fdd73857860>
args = ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '56525', '--api-ip', ...], bufsize = -1
executable = None, stdin = None, stdout = None, stderr = None, preexec_fn = None, close_fds = True
shell = False, cwd = None
env = {'COLUMNS': '108', 'CONFIGPROXY_AUTH_TOKEN': '1868faa8faac479eb1746f03b714516e', 'CVS_RSH': 'ssh', 'HISTCONTROL': 'ignoredups', ...}
universal_newlines = False, startupinfo = None, creationflags = 0, restore_signals = True
start_new_session = True, pass_fds = ()

    def __init__(self, args, bufsize=-1, executable=None,
                 stdin=None, stdout=None, stderr=None,
                 preexec_fn=None, close_fds=_PLATFORM_DEFAULT_CLOSE_FDS,
                 shell=False, cwd=None, env=None, universal_newlines=False,
                 startupinfo=None, creationflags=0,
                 restore_signals=True, start_new_session=False,
                 pass_fds=(), *, encoding=None, errors=None):
        """Create new Popen instance."""
        _cleanup()
        # Held while anything is calling waitpid before returncode has been
        # updated to prevent clobbering returncode if wait() or poll() are
        # called from multiple threads at once.  After acquiring the lock,
        # code must re-check self.returncode to see if another thread just
        # finished a waitpid() call.
        self._waitpid_lock = threading.Lock()
    
        self._input = None
        self._communication_started = False
        if bufsize is None:
            bufsize = -1  # Restore default
        if not isinstance(bufsize, int):
            raise TypeError("bufsize must be an integer")
    
        if _mswindows:
            if preexec_fn is not None:
                raise ValueError("preexec_fn is not supported on Windows "
                                 "platforms")
            any_stdio_set = (stdin is not None or stdout is not None or
                             stderr is not None)
            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:
                if any_stdio_set:
                    close_fds = False
                else:
                    close_fds = True
            elif close_fds and any_stdio_set:
                raise ValueError(
                        "close_fds is not supported on Windows platforms"
                        " if you redirect stdin/stdout/stderr")
        else:
            # POSIX
            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:
                close_fds = True
            if pass_fds and not close_fds:
                warnings.warn("pass_fds overriding close_fds.", RuntimeWarning)
                close_fds = True
            if startupinfo is not None:
                raise ValueError("startupinfo is only supported on Windows "
                                 "platforms")
            if creationflags != 0:
                raise ValueError("creationflags is only supported on Windows "
                                 "platforms")
    
        self.args = args
        self.stdin = None
        self.stdout = None
        self.stderr = None
        self.pid = None
        self.returncode = None
        self.universal_newlines = universal_newlines
        self.encoding = encoding
        self.errors = errors
    
        # Input and output objects. The general principle is like
        # this:
        #
        # Parent                   Child
        # ------                   -----
        # p2cwrite   ---stdin--->  p2cread
        # c2pread    <--stdout---  c2pwrite
        # errread    <--stderr---  errwrite
        #
        # On POSIX, the child objects are file descriptors.  On
        # Windows, these are Windows file handles.  The parent objects
        # are file descriptors on both platforms.  The parent objects
        # are -1 when not using PIPEs. The child objects are -1
        # when not redirecting.
    
        (p2cread, p2cwrite,
         c2pread, c2pwrite,
         errread, errwrite) = self._get_handles(stdin, stdout, stderr)
    
        # We wrap OS handles *before* launching the child, otherwise a
        # quickly terminating child could make our fds unwrappable
        # (see #8458).
    
        if _mswindows:
            if p2cwrite != -1:
                p2cwrite = msvcrt.open_osfhandle(p2cwrite.Detach(), 0)
            if c2pread != -1:
                c2pread = msvcrt.open_osfhandle(c2pread.Detach(), 0)
            if errread != -1:
                errread = msvcrt.open_osfhandle(errread.Detach(), 0)
    
        text_mode = encoding or errors or universal_newlines
    
        self._closed_child_pipe_fds = False
    
        try:
            if p2cwrite != -1:
                self.stdin = io.open(p2cwrite, 'wb', bufsize)
                if text_mode:
                    self.stdin = io.TextIOWrapper(self.stdin, write_through=True,
                            line_buffering=(bufsize == 1),
                            encoding=encoding, errors=errors)
            if c2pread != -1:
                self.stdout = io.open(c2pread, 'rb', bufsize)
                if text_mode:
                    self.stdout = io.TextIOWrapper(self.stdout,
                            encoding=encoding, errors=errors)
            if errread != -1:
                self.stderr = io.open(errread, 'rb', bufsize)
                if text_mode:
                    self.stderr = io.TextIOWrapper(self.stderr,
                            encoding=encoding, errors=errors)
    
            self._execute_child(args, executable, preexec_fn, close_fds,
                                pass_fds, cwd, env,
                                startupinfo, creationflags, shell,
                                p2cread, p2cwrite,
                                c2pread, c2pwrite,
                                errread, errwrite,
>                               restore_signals, start_new_session)

/home/ec2-user/anaconda3/lib/python3.6/subprocess.py:707: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <subprocess.Popen object at 0x7fdd73857860>
args = ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '56525', '--api-ip', ...]
executable = b'configurable-http-proxy', preexec_fn = None, close_fds = True, pass_fds = (), cwd = None
env = {'COLUMNS': '108', 'CONFIGPROXY_AUTH_TOKEN': '1868faa8faac479eb1746f03b714516e', 'CVS_RSH': 'ssh', 'HISTCONTROL': 'ignoredups', ...}
startupinfo = None, creationflags = 0, shell = False, p2cread = -1, p2cwrite = -1, c2pread = -1
c2pwrite = -1, errread = -1, errwrite = -1, restore_signals = True, start_new_session = True

    def _execute_child(self, args, executable, preexec_fn, close_fds,
                       pass_fds, cwd, env,
                       startupinfo, creationflags, shell,
                       p2cread, p2cwrite,
                       c2pread, c2pwrite,
                       errread, errwrite,
                       restore_signals, start_new_session):
        """Execute program (POSIX version)"""
    
        if isinstance(args, (str, bytes)):
            args = [args]
        else:
            args = list(args)
    
        if shell:
            args = ["/bin/sh", "-c"] + args
            if executable:
                args[0] = executable
    
        if executable is None:
            executable = args[0]
        orig_executable = executable
    
        # For transferring possible exec failure from child to parent.
        # Data format: "exception name:hex errno:description"
        # Pickle is not used; it is complex and involves memory allocation.
        errpipe_read, errpipe_write = os.pipe()
        # errpipe_write must not be in the standard io 0, 1, or 2 fd range.
        low_fds_to_close = []
        while errpipe_write < 3:
            low_fds_to_close.append(errpipe_write)
            errpipe_write = os.dup(errpipe_write)
        for low_fd in low_fds_to_close:
            os.close(low_fd)
        try:
            try:
                # We must avoid complex work that could involve
                # malloc or free in the child process to avoid
                # potential deadlocks, thus we do all this here.
                # and pass it to fork_exec()
    
                if env is not None:
                    env_list = []
                    for k, v in env.items():
                        k = os.fsencode(k)
                        if b'=' in k:
                            raise ValueError("illegal environment variable name")
                        env_list.append(k + b'=' + os.fsencode(v))
                else:
                    env_list = None  # Use execv instead of execve.
                executable = os.fsencode(executable)
                if os.path.dirname(executable):
                    executable_list = (executable,)
                else:
                    # This matches the behavior of os._execvpe().
                    executable_list = tuple(
                        os.path.join(os.fsencode(dir), executable)
                        for dir in os.get_exec_path(env))
                fds_to_keep = set(pass_fds)
                fds_to_keep.add(errpipe_write)
                self.pid = _posixsubprocess.fork_exec(
                        args, executable_list,
                        close_fds, tuple(sorted(map(int, fds_to_keep))),
                        cwd, env_list,
                        p2cread, p2cwrite, c2pread, c2pwrite,
                        errread, errwrite,
                        errpipe_read, errpipe_write,
                        restore_signals, start_new_session, preexec_fn)
                self._child_created = True
            finally:
                # be sure the FD is closed no matter what
                os.close(errpipe_write)
    
            # self._devnull is not always defined.
            devnull_fd = getattr(self, '_devnull', None)
            if p2cread != -1 and p2cwrite != -1 and p2cread != devnull_fd:
                os.close(p2cread)
            if c2pwrite != -1 and c2pread != -1 and c2pwrite != devnull_fd:
                os.close(c2pwrite)
            if errwrite != -1 and errread != -1 and errwrite != devnull_fd:
                os.close(errwrite)
            if devnull_fd is not None:
                os.close(devnull_fd)
            # Prevent a double close of these fds from __init__ on error.
            self._closed_child_pipe_fds = True
    
            # Wait for exec to fail or succeed; possibly raising an
            # exception (limited in size)
            errpipe_data = bytearray()
            while True:
                part = os.read(errpipe_read, 50000)
                errpipe_data += part
                if not part or len(errpipe_data) > 50000:
                    break
        finally:
            # be sure the FD is closed no matter what
            os.close(errpipe_read)
    
        if errpipe_data:
            try:
                pid, sts = os.waitpid(self.pid, 0)
                if pid == self.pid:
                    self._handle_exitstatus(sts)
                else:
                    self.returncode = sys.maxsize
            except ChildProcessError:
                pass
    
            try:
                exception_name, hex_errno, err_msg = (
                        errpipe_data.split(b':', 2))
            except ValueError:
                exception_name = b'SubprocessError'
                hex_errno = b'0'
                err_msg = (b'Bad exception data from child: ' +
                           repr(errpipe_data))
            child_exception_type = getattr(
                    builtins, exception_name.decode('ascii'),
                    SubprocessError)
            err_msg = err_msg.decode(errors="surrogatepass")
            if issubclass(child_exception_type, OSError) and hex_errno:
                errno_num = int(hex_errno, 16)
                child_exec_never_called = (err_msg == "noexec")
                if child_exec_never_called:
                    err_msg = ""
                if errno_num != 0:
                    err_msg = os.strerror(errno_num)
                    if errno_num == errno.ENOENT:
                        if child_exec_never_called:
                            # The error must be from chdir(cwd).
                            err_msg += ': ' + repr(cwd)
                        else:
                            err_msg += ': ' + repr(orig_executable)
>               raise child_exception_type(errno_num, err_msg)
E               FileNotFoundError: [Errno 2] No such file or directory: 'configurable-http-proxy'

/home/ec2-user/anaconda3/lib/python3.6/subprocess.py:1333: FileNotFoundError

During handling of the above exception, another exception occurred:

request = <SubRequest 'app' for <Function 'test_root_no_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:832: in start
    self._run_callback(self._callbacks.popleft())
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:605: in _run_callback
    ret = callback()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py:277: in null_wrapper
    return fn(*args, **kwargs)
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:436: in run
    result = func()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:319: in wrapper
    _futures_to_runners[future] = Runner(result, future, yielded)
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1003: in __init__
    self.run()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1069: in run
    yielded = self.gen.send(value)
/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:62: in make_app
    yield mocked_app.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:319: in wrapper
    _futures_to_runners[future] = Runner(result, future, yielded)
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1003: in __init__
    self.run()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1063: in run
    yielded = self.gen.throw(*exc_info)
/home/ec2-user/jupyterhub/jupyterhub/app.py:1553: in start
    self.exit(1)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <jupyterhub.tests.mocking.MockHub object at 0x7fdd742688d0>, exit_status = 1

    def exit(self, exit_status=0):
        self.log.debug("Exiting application: %s" % self.name)
>       sys.exit(exit_status)
E       SystemExit: 1

/home/ec2-user/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py:648: SystemExit
------------------------------------------ Captured stderr setup -------------------------------------------
[I 46:02.775 alembic.runtime.migration migration:117] Context impl SQLiteImpl.
[I 46:02.775 alembic.runtime.migration migration:122] Will assume non-transactional DDL.
[I 46:02.782 alembic.runtime.migration migration:327] Running stamp_revision  -> 3ec6993fe20c
[I 46:02.846 MockHub app:1000] Not using whitelist. Any authenticated user will be allowed.
[I 46:02.863 MockHub app:1545] Hub API listening on http://127.0.0.1:8081/@/space%20word/hub/
[W 46:02.864 MockHub proxy:415] 
    Generating CONFIGPROXY_AUTH_TOKEN. Restarting the Hub will require restarting the proxy.
    Set CONFIGPROXY_AUTH_TOKEN env or JupyterHub.proxy_auth_token config to avoid this message.
    
[W 46:02.864 MockHub proxy:456] Running JupyterHub without SSL.  I hope there is SSL termination happening somewhere else...
[I 46:02.864 MockHub proxy:458] Starting proxy @ http://127.0.0.1:56525/@/space%20word/
[E 46:02.868 MockHub proxy:467] Failed to find proxy ['configurable-http-proxy']
    The proxy can be installed with `npm install -g configurable-http-proxy`
[C 46:02.868 MockHub app:1552] Failed to start proxy
    Traceback (most recent call last):
      File "/home/ec2-user/jupyterhub/jupyterhub/app.py", line 1550, in start
        yield self.proxy.start()
      File "/home/ec2-user/jupyterhub/jupyterhub/proxy.py", line 462, in start
        self.proxy_process = Popen(cmd, env=env, start_new_session=True, shell=shell)
      File "/home/ec2-user/anaconda3/lib/python3.6/subprocess.py", line 707, in __init__
        restore_signals, start_new_session)
      File "/home/ec2-user/anaconda3/lib/python3.6/subprocess.py", line 1333, in _execute_child
        raise child_exception_type(errno_num, err_msg)
    FileNotFoundError: [Errno 2] No such file or directory: 'configurable-http-proxy'
    
_____________________________________ ERROR at setup of test_root_auth _____________________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
___________________________________ ERROR at setup of test_root_redirect ___________________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
___________________________________ ERROR at setup of test_home_no_auth ____________________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_____________________________________ ERROR at setup of test_home_auth _____________________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
___________________________________ ERROR at setup of test_admin_no_auth ___________________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
__________________________________ ERROR at setup of test_admin_not_admin __________________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_______________________________________ ERROR at setup of test_admin _______________________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
________________________________ ERROR at setup of test_admin_sort[running] ________________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_____________________________ ERROR at setup of test_admin_sort[last_activity] _____________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_________________________________ ERROR at setup of test_admin_sort[admin] _________________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_________________________________ ERROR at setup of test_admin_sort[name] __________________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
__________________________________ ERROR at setup of test_spawn_redirect ___________________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
____________________________________ ERROR at setup of test_spawn_page _____________________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
____________________________________ ERROR at setup of test_spawn_form _____________________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_______________________________ ERROR at setup of test_spawn_form_with_file ________________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
___________________________________ ERROR at setup of test_user_redirect ___________________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_____________________________ ERROR at setup of test_user_redirect_deprecated ______________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
____________________________________ ERROR at setup of test_login_fail _____________________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
____________________________________ ERROR at setup of test_login_strip ____________________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
__________________________________ ERROR at setup of test_login_redirect ___________________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
____________________________________ ERROR at setup of test_auto_login _____________________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_________________________________ ERROR at setup of test_auto_login_logout _________________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
______________________________________ ERROR at setup of test_logout _______________________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
___________________________ ERROR at setup of test_login_no_whitelist_adds_user ____________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
___________________________________ ERROR at setup of test_static_files ____________________________________

request = <SubRequest 'app' for <Function 'test_root_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd7352f8d0>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_________________________________ ERROR at teardown of test_external_proxy _________________________________

    def fin():
        MockHub.clear_instance()
>       app.http_server.stop()

/home/ec2-user/jupyterhub/jupyterhub/tests/test_proxy.py:46: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tornado.httpserver.HTTPServer object at 0x7fdd735cecf8>

    def stop(self):
        """Stops listening for new connections.
    
            Requests currently in progress may still continue after the
            server is stopped.
            """
        if self._stopped:
            return
        self._stopped = True
        for fd, sock in self._sockets.items():
>           assert sock.fileno() == fd
E           AssertionError

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/tcpserver.py:236: AssertionError
_________________________________ ERROR at setup of test_check_routes[zoe] _________________________________

self = <jupyterhub.tests.mocking.MockHub object at 0x7fdd735223c8>

    @gen.coroutine
    def start(self):
        """Start the whole thing"""
        self.io_loop = loop = IOLoop.current()
    
        if self.subapp:
            self.subapp.start()
            loop.stop()
            return
    
        if self.generate_config:
            self.write_config_file()
            loop.stop()
            return
    
        # start the webserver
        self.http_server = tornado.httpserver.HTTPServer(self.tornado_application, xheaders=True)
        try:
            self.http_server.listen(self.hub_port, address=self.hub_ip)
        except Exception:
            self.log.error("Failed to bind hub to %s", self.hub.bind_url)
            raise
        else:
            self.log.info("Hub API listening on %s", self.hub.bind_url)
    
        # start the proxy
        if self.proxy.should_start:
            try:
>               yield self.proxy.start()

/home/ec2-user/jupyterhub/jupyterhub/app.py:1550: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tornado.gen.Runner object at 0x7fdd73491f28>

    def run(self):
        """Starts or resumes the generator, running until it reaches a
            yield point that is not ready.
            """
        if self.running or self.finished:
            return
        try:
            self.running = True
            while True:
                future = self.future
                if not future.done():
                    return
                self.future = None
                try:
                    orig_stack_contexts = stack_context._state.contexts
                    exc_info = None
    
                    try:
>                       value = future.result()

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1055: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = None, timeout = None

    def result(self, timeout=None):
        """If the operation succeeded, return its result.  If it failed,
            re-raise its exception.
    
            This method takes a ``timeout`` argument for compatibility with
            `concurrent.futures.Future` but it is an error to call it
            before the `Future` is done, so the ``timeout`` is never used.
            """
        self._clear_tb_log()
        if self._result is not None:
            return self._result
        if self._exc_info is not None:
            try:
>               raise_exc_info(self._exc_info)

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/concurrent.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

exc_info = None

>   ???

<string>:4: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<jupyterhub.proxy.ConfigurableHTTPProxy object at 0x7fdd73b01ba8>,), kwargs = {}, future = None
result = <generator object start at 0x7fdd732dce60>, orig_stack_contexts = ((), None), yielded = None

    @functools.wraps(wrapped)
    def wrapper(*args, **kwargs):
        future = TracebackFuture()
    
        if replace_callback and 'callback' in kwargs:
            callback = kwargs.pop('callback')
            IOLoop.current().add_future(
                future, lambda future: callback(future.result()))
    
        try:
            result = func(*args, **kwargs)
        except (Return, StopIteration) as e:
            result = _value_from_stopiteration(e)
        except Exception:
            future.set_exc_info(sys.exc_info())
            return future
        else:
            if isinstance(result, GeneratorType):
                # Inline the first iteration of Runner.run.  This lets us
                # avoid the cost of creating a Runner when the coroutine
                # never actually yields, which in turn allows us to
                # use "optional" coroutines in critical path code without
                # performance penalty for the synchronous case.
                try:
                    orig_stack_contexts = stack_context._state.contexts
>                   yielded = next(result)

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:307: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <jupyterhub.proxy.ConfigurableHTTPProxy object at 0x7fdd73b01ba8>

    @gen.coroutine
    def start(self):
        public_server = Server.from_url(self.public_url)
        api_server = Server.from_url(self.api_url)
        env = os.environ.copy()
        env['CONFIGPROXY_AUTH_TOKEN'] = self.auth_token
        cmd = self.command + [
            '--ip', public_server.ip,
            '--port', str(public_server.port),
            '--api-ip', api_server.ip,
            '--api-port', str(api_server.port),
            '--error-target', url_path_join(self.hub.url, 'error'),
        ]
        if self.app.subdomain_host:
            cmd.append('--host-routing')
        if self.debug:
            cmd.extend(['--log-level', 'debug'])
        if self.ssl_key:
            cmd.extend(['--ssl-key', self.ssl_key])
        if self.ssl_cert:
            cmd.extend(['--ssl-cert', self.ssl_cert])
        if self.app.statsd_host:
            cmd.extend([
                '--statsd-host', self.app.statsd_host,
                '--statsd-port', str(self.app.statsd_port),
                '--statsd-prefix', self.app.statsd_prefix + '.chp'
            ])
        # Warn if SSL is not used
        if ' --ssl' not in ' '.join(cmd):
            self.log.warning("Running JupyterHub without SSL."
                             "  I hope there is SSL termination happening somewhere else...")
        self.log.info("Starting proxy @ %s", public_server.bind_url)
        self.log.debug("Proxy cmd: %s", cmd)
        shell = os.name == 'nt'
        try:
>           self.proxy_process = Popen(cmd, env=env, start_new_session=True, shell=shell)

/home/ec2-user/jupyterhub/jupyterhub/proxy.py:462: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <subprocess.Popen object at 0x7fdd73491b38>
args = ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '35321', '--api-ip', ...], bufsize = -1
executable = None, stdin = None, stdout = None, stderr = None, preexec_fn = None, close_fds = True
shell = False, cwd = None
env = {'COLUMNS': '108', 'CONFIGPROXY_AUTH_TOKEN': '28b24210c103499c8b62c7adc98c46e4', 'CVS_RSH': 'ssh', 'HISTCONTROL': 'ignoredups', ...}
universal_newlines = False, startupinfo = None, creationflags = 0, restore_signals = True
start_new_session = True, pass_fds = ()

    def __init__(self, args, bufsize=-1, executable=None,
                 stdin=None, stdout=None, stderr=None,
                 preexec_fn=None, close_fds=_PLATFORM_DEFAULT_CLOSE_FDS,
                 shell=False, cwd=None, env=None, universal_newlines=False,
                 startupinfo=None, creationflags=0,
                 restore_signals=True, start_new_session=False,
                 pass_fds=(), *, encoding=None, errors=None):
        """Create new Popen instance."""
        _cleanup()
        # Held while anything is calling waitpid before returncode has been
        # updated to prevent clobbering returncode if wait() or poll() are
        # called from multiple threads at once.  After acquiring the lock,
        # code must re-check self.returncode to see if another thread just
        # finished a waitpid() call.
        self._waitpid_lock = threading.Lock()
    
        self._input = None
        self._communication_started = False
        if bufsize is None:
            bufsize = -1  # Restore default
        if not isinstance(bufsize, int):
            raise TypeError("bufsize must be an integer")
    
        if _mswindows:
            if preexec_fn is not None:
                raise ValueError("preexec_fn is not supported on Windows "
                                 "platforms")
            any_stdio_set = (stdin is not None or stdout is not None or
                             stderr is not None)
            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:
                if any_stdio_set:
                    close_fds = False
                else:
                    close_fds = True
            elif close_fds and any_stdio_set:
                raise ValueError(
                        "close_fds is not supported on Windows platforms"
                        " if you redirect stdin/stdout/stderr")
        else:
            # POSIX
            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:
                close_fds = True
            if pass_fds and not close_fds:
                warnings.warn("pass_fds overriding close_fds.", RuntimeWarning)
                close_fds = True
            if startupinfo is not None:
                raise ValueError("startupinfo is only supported on Windows "
                                 "platforms")
            if creationflags != 0:
                raise ValueError("creationflags is only supported on Windows "
                                 "platforms")
    
        self.args = args
        self.stdin = None
        self.stdout = None
        self.stderr = None
        self.pid = None
        self.returncode = None
        self.universal_newlines = universal_newlines
        self.encoding = encoding
        self.errors = errors
    
        # Input and output objects. The general principle is like
        # this:
        #
        # Parent                   Child
        # ------                   -----
        # p2cwrite   ---stdin--->  p2cread
        # c2pread    <--stdout---  c2pwrite
        # errread    <--stderr---  errwrite
        #
        # On POSIX, the child objects are file descriptors.  On
        # Windows, these are Windows file handles.  The parent objects
        # are file descriptors on both platforms.  The parent objects
        # are -1 when not using PIPEs. The child objects are -1
        # when not redirecting.
    
        (p2cread, p2cwrite,
         c2pread, c2pwrite,
         errread, errwrite) = self._get_handles(stdin, stdout, stderr)
    
        # We wrap OS handles *before* launching the child, otherwise a
        # quickly terminating child could make our fds unwrappable
        # (see #8458).
    
        if _mswindows:
            if p2cwrite != -1:
                p2cwrite = msvcrt.open_osfhandle(p2cwrite.Detach(), 0)
            if c2pread != -1:
                c2pread = msvcrt.open_osfhandle(c2pread.Detach(), 0)
            if errread != -1:
                errread = msvcrt.open_osfhandle(errread.Detach(), 0)
    
        text_mode = encoding or errors or universal_newlines
    
        self._closed_child_pipe_fds = False
    
        try:
            if p2cwrite != -1:
                self.stdin = io.open(p2cwrite, 'wb', bufsize)
                if text_mode:
                    self.stdin = io.TextIOWrapper(self.stdin, write_through=True,
                            line_buffering=(bufsize == 1),
                            encoding=encoding, errors=errors)
            if c2pread != -1:
                self.stdout = io.open(c2pread, 'rb', bufsize)
                if text_mode:
                    self.stdout = io.TextIOWrapper(self.stdout,
                            encoding=encoding, errors=errors)
            if errread != -1:
                self.stderr = io.open(errread, 'rb', bufsize)
                if text_mode:
                    self.stderr = io.TextIOWrapper(self.stderr,
                            encoding=encoding, errors=errors)
    
            self._execute_child(args, executable, preexec_fn, close_fds,
                                pass_fds, cwd, env,
                                startupinfo, creationflags, shell,
                                p2cread, p2cwrite,
                                c2pread, c2pwrite,
                                errread, errwrite,
>                               restore_signals, start_new_session)

/home/ec2-user/anaconda3/lib/python3.6/subprocess.py:707: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <subprocess.Popen object at 0x7fdd73491b38>
args = ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '35321', '--api-ip', ...]
executable = b'configurable-http-proxy', preexec_fn = None, close_fds = True, pass_fds = (), cwd = None
env = {'COLUMNS': '108', 'CONFIGPROXY_AUTH_TOKEN': '28b24210c103499c8b62c7adc98c46e4', 'CVS_RSH': 'ssh', 'HISTCONTROL': 'ignoredups', ...}
startupinfo = None, creationflags = 0, shell = False, p2cread = -1, p2cwrite = -1, c2pread = -1
c2pwrite = -1, errread = -1, errwrite = -1, restore_signals = True, start_new_session = True

    def _execute_child(self, args, executable, preexec_fn, close_fds,
                       pass_fds, cwd, env,
                       startupinfo, creationflags, shell,
                       p2cread, p2cwrite,
                       c2pread, c2pwrite,
                       errread, errwrite,
                       restore_signals, start_new_session):
        """Execute program (POSIX version)"""
    
        if isinstance(args, (str, bytes)):
            args = [args]
        else:
            args = list(args)
    
        if shell:
            args = ["/bin/sh", "-c"] + args
            if executable:
                args[0] = executable
    
        if executable is None:
            executable = args[0]
        orig_executable = executable
    
        # For transferring possible exec failure from child to parent.
        # Data format: "exception name:hex errno:description"
        # Pickle is not used; it is complex and involves memory allocation.
        errpipe_read, errpipe_write = os.pipe()
        # errpipe_write must not be in the standard io 0, 1, or 2 fd range.
        low_fds_to_close = []
        while errpipe_write < 3:
            low_fds_to_close.append(errpipe_write)
            errpipe_write = os.dup(errpipe_write)
        for low_fd in low_fds_to_close:
            os.close(low_fd)
        try:
            try:
                # We must avoid complex work that could involve
                # malloc or free in the child process to avoid
                # potential deadlocks, thus we do all this here.
                # and pass it to fork_exec()
    
                if env is not None:
                    env_list = []
                    for k, v in env.items():
                        k = os.fsencode(k)
                        if b'=' in k:
                            raise ValueError("illegal environment variable name")
                        env_list.append(k + b'=' + os.fsencode(v))
                else:
                    env_list = None  # Use execv instead of execve.
                executable = os.fsencode(executable)
                if os.path.dirname(executable):
                    executable_list = (executable,)
                else:
                    # This matches the behavior of os._execvpe().
                    executable_list = tuple(
                        os.path.join(os.fsencode(dir), executable)
                        for dir in os.get_exec_path(env))
                fds_to_keep = set(pass_fds)
                fds_to_keep.add(errpipe_write)
                self.pid = _posixsubprocess.fork_exec(
                        args, executable_list,
                        close_fds, tuple(sorted(map(int, fds_to_keep))),
                        cwd, env_list,
                        p2cread, p2cwrite, c2pread, c2pwrite,
                        errread, errwrite,
                        errpipe_read, errpipe_write,
                        restore_signals, start_new_session, preexec_fn)
                self._child_created = True
            finally:
                # be sure the FD is closed no matter what
                os.close(errpipe_write)
    
            # self._devnull is not always defined.
            devnull_fd = getattr(self, '_devnull', None)
            if p2cread != -1 and p2cwrite != -1 and p2cread != devnull_fd:
                os.close(p2cread)
            if c2pwrite != -1 and c2pread != -1 and c2pwrite != devnull_fd:
                os.close(c2pwrite)
            if errwrite != -1 and errread != -1 and errwrite != devnull_fd:
                os.close(errwrite)
            if devnull_fd is not None:
                os.close(devnull_fd)
            # Prevent a double close of these fds from __init__ on error.
            self._closed_child_pipe_fds = True
    
            # Wait for exec to fail or succeed; possibly raising an
            # exception (limited in size)
            errpipe_data = bytearray()
            while True:
                part = os.read(errpipe_read, 50000)
                errpipe_data += part
                if not part or len(errpipe_data) > 50000:
                    break
        finally:
            # be sure the FD is closed no matter what
            os.close(errpipe_read)
    
        if errpipe_data:
            try:
                pid, sts = os.waitpid(self.pid, 0)
                if pid == self.pid:
                    self._handle_exitstatus(sts)
                else:
                    self.returncode = sys.maxsize
            except ChildProcessError:
                pass
    
            try:
                exception_name, hex_errno, err_msg = (
                        errpipe_data.split(b':', 2))
            except ValueError:
                exception_name = b'SubprocessError'
                hex_errno = b'0'
                err_msg = (b'Bad exception data from child: ' +
                           repr(errpipe_data))
            child_exception_type = getattr(
                    builtins, exception_name.decode('ascii'),
                    SubprocessError)
            err_msg = err_msg.decode(errors="surrogatepass")
            if issubclass(child_exception_type, OSError) and hex_errno:
                errno_num = int(hex_errno, 16)
                child_exec_never_called = (err_msg == "noexec")
                if child_exec_never_called:
                    err_msg = ""
                if errno_num != 0:
                    err_msg = os.strerror(errno_num)
                    if errno_num == errno.ENOENT:
                        if child_exec_never_called:
                            # The error must be from chdir(cwd).
                            err_msg += ': ' + repr(cwd)
                        else:
                            err_msg += ': ' + repr(orig_executable)
>               raise child_exception_type(errno_num, err_msg)
E               FileNotFoundError: [Errno 2] No such file or directory: 'configurable-http-proxy'

/home/ec2-user/anaconda3/lib/python3.6/subprocess.py:1333: FileNotFoundError

During handling of the above exception, another exception occurred:

request = <SubRequest 'app' for <Function 'test_check_routes[zoe]'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:832: in start
    self._run_callback(self._callbacks.popleft())
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:605: in _run_callback
    ret = callback()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py:277: in null_wrapper
    return fn(*args, **kwargs)
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:436: in run
    result = func()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:319: in wrapper
    _futures_to_runners[future] = Runner(result, future, yielded)
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1003: in __init__
    self.run()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1069: in run
    yielded = self.gen.send(value)
/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:62: in make_app
    yield mocked_app.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:319: in wrapper
    _futures_to_runners[future] = Runner(result, future, yielded)
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1003: in __init__
    self.run()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1063: in run
    yielded = self.gen.throw(*exc_info)
/home/ec2-user/jupyterhub/jupyterhub/app.py:1553: in start
    self.exit(1)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <jupyterhub.tests.mocking.MockHub object at 0x7fdd735223c8>, exit_status = 1

    def exit(self, exit_status=0):
        self.log.debug("Exiting application: %s" % self.name)
>       sys.exit(exit_status)
E       SystemExit: 1

/home/ec2-user/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py:648: SystemExit
------------------------------------------ Captured stderr setup -------------------------------------------
[D 46:03.914 MockHub app:1365] Writing PID 27865 to /tmp/tmp7nusojnn
[D 46:03.915 MockHub app:883] Generating new cookie_secret
[I 46:03.915 MockHub app:888] Writing cookie_secret to /tmp/pytest-of-ec2-user/pytest-2/test_upgrade_entrypoint0/jupyterhub_cookie_secret
[D 46:03.915 MockHub app:903] Connecting to db: sqlite:////tmp/tmpqxu83ge3
[D 46:03.919 MockHub orm:475] Stamping empty database with alembic revision 3ec6993fe20c
[I 46:03.921 alembic.runtime.migration migration:117] Context impl SQLiteImpl.
[I 46:03.921 alembic.runtime.migration migration:122] Will assume non-transactional DDL.
[I 46:03.928 alembic.runtime.migration migration:327] Running stamp_revision  -> 3ec6993fe20c
[D 46:03.928 alembic.runtime.migration migration:516] new branch insert 3ec6993fe20c
[I 46:03.994 MockHub app:1000] Not using whitelist. Any authenticated user will be allowed.
[D 46:04.004 MockHub app:1228] Loading state for admin from db
[D 46:04.005 MockHub app:1258] Loaded users: 
       admin admin
[I 46:04.011 MockHub app:1545] Hub API listening on http://127.0.0.1:8081/@/space%20word/hub/
[W 46:04.012 MockHub proxy:415] 
    Generating CONFIGPROXY_AUTH_TOKEN. Restarting the Hub will require restarting the proxy.
    Set CONFIGPROXY_AUTH_TOKEN env or JupyterHub.proxy_auth_token config to avoid this message.
    
[W 46:04.012 MockHub proxy:456] Running JupyterHub without SSL.  I hope there is SSL termination happening somewhere else...
[I 46:04.012 MockHub proxy:458] Starting proxy @ http://127.0.0.1:35321/@/space%20word/
[D 46:04.012 MockHub proxy:459] Proxy cmd: ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '35321', '--api-ip', '127.0.0.1', '--api-port', '8001', '--error-target', 'http://127.0.0.1:8081/@/space%20word/hub/error']
[E 46:04.016 MockHub proxy:467] Failed to find proxy ['configurable-http-proxy']
    The proxy can be installed with `npm install -g configurable-http-proxy`
[C 46:04.016 MockHub app:1552] Failed to start proxy
    Traceback (most recent call last):
      File "/home/ec2-user/jupyterhub/jupyterhub/app.py", line 1550, in start
        yield self.proxy.start()
      File "/home/ec2-user/jupyterhub/jupyterhub/proxy.py", line 462, in start
        self.proxy_process = Popen(cmd, env=env, start_new_session=True, shell=shell)
      File "/home/ec2-user/anaconda3/lib/python3.6/subprocess.py", line 707, in __init__
        restore_signals, start_new_session)
      File "/home/ec2-user/anaconda3/lib/python3.6/subprocess.py", line 1333, in _execute_child
        raise child_exception_type(errno_num, err_msg)
    FileNotFoundError: [Errno 2] No such file or directory: 'configurable-http-proxy'
    
[D 46:04.016 MockHub application:647] Exiting application: jupyterhub
________________________________ ERROR at setup of test_check_routes[50fia] ________________________________

request = <SubRequest 'app' for <Function 'test_check_routes[50fia]'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
____________________________ ERROR at setup of test_check_routes[\u79c0\u6a39] _____________________________

request = <SubRequest 'app' for <Function 'test_check_routes[50fia]'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_________________________ ERROR at setup of test_add_get_delete[/has%20space/foo/] _________________________

request = <SubRequest 'app' for <Function 'test_check_routes[50fia]'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
______________________ ERROR at setup of test_add_get_delete[/missing-trailing/slash] ______________________

request = <SubRequest 'app' for <Function 'test_check_routes[50fia]'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
______________________________ ERROR at setup of test_add_get_delete[/has/@/] ______________________________

request = <SubRequest 'app' for <Function 'test_check_routes[50fia]'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
________ ERROR at setup of test_add_get_delete[/has/%C3%BC%C3%B1%C3%AE%C3%A7%C3%B8%E2%88%82%C3%A9] _________

request = <SubRequest 'app' for <Function 'test_check_routes[50fia]'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
__________________________ ERROR at setup of test_add_get_delete[host.name/path/] __________________________

request = <SubRequest 'app' for <Function 'test_check_routes[50fia]'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_____________________ ERROR at setup of test_add_get_delete[other.host/path/no/slash] ______________________

request = <SubRequest 'app' for <Function 'test_check_routes[50fia]'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
________________________ ERROR at setup of test_proxy_patch_bad_request_data[None] _________________________

request = <SubRequest 'app' for <Function 'test_check_routes[50fia]'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_______________________ ERROR at setup of test_proxy_patch_bad_request_data[notjson] _______________________

request = <SubRequest 'app' for <Function 'test_check_routes[50fia]'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_________________________ ERROR at setup of test_proxy_patch_bad_request_data[[]] __________________________

request = <SubRequest 'app' for <Function 'test_check_routes[50fia]'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd732fdf28>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
__________________________________ ERROR at setup of test_managed_service __________________________________

self = <jupyterhub.tests.mocking.MockHub object at 0x7fdd735223c8>

    @gen.coroutine
    def start(self):
        """Start the whole thing"""
        self.io_loop = loop = IOLoop.current()
    
        if self.subapp:
            self.subapp.start()
            loop.stop()
            return
    
        if self.generate_config:
            self.write_config_file()
            loop.stop()
            return
    
        # start the webserver
        self.http_server = tornado.httpserver.HTTPServer(self.tornado_application, xheaders=True)
        try:
            self.http_server.listen(self.hub_port, address=self.hub_ip)
        except Exception:
            self.log.error("Failed to bind hub to %s", self.hub.bind_url)
            raise
        else:
            self.log.info("Hub API listening on %s", self.hub.bind_url)
    
        # start the proxy
        if self.proxy.should_start:
            try:
>               yield self.proxy.start()

/home/ec2-user/jupyterhub/jupyterhub/app.py:1550: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tornado.gen.Runner object at 0x7fdd73750748>

    def run(self):
        """Starts or resumes the generator, running until it reaches a
            yield point that is not ready.
            """
        if self.running or self.finished:
            return
        try:
            self.running = True
            while True:
                future = self.future
                if not future.done():
                    return
                self.future = None
                try:
                    orig_stack_contexts = stack_context._state.contexts
                    exc_info = None
    
                    try:
>                       value = future.result()

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1055: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = None, timeout = None

    def result(self, timeout=None):
        """If the operation succeeded, return its result.  If it failed,
            re-raise its exception.
    
            This method takes a ``timeout`` argument for compatibility with
            `concurrent.futures.Future` but it is an error to call it
            before the `Future` is done, so the ``timeout`` is never used.
            """
        self._clear_tb_log()
        if self._result is not None:
            return self._result
        if self._exc_info is not None:
            try:
>               raise_exc_info(self._exc_info)

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/concurrent.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

exc_info = None

>   ???

<string>:4: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<jupyterhub.proxy.ConfigurableHTTPProxy object at 0x7fdd73308d68>,), kwargs = {}, future = None
result = <generator object start at 0x7fdd732b4200>, orig_stack_contexts = ((), None), yielded = None

    @functools.wraps(wrapped)
    def wrapper(*args, **kwargs):
        future = TracebackFuture()
    
        if replace_callback and 'callback' in kwargs:
            callback = kwargs.pop('callback')
            IOLoop.current().add_future(
                future, lambda future: callback(future.result()))
    
        try:
            result = func(*args, **kwargs)
        except (Return, StopIteration) as e:
            result = _value_from_stopiteration(e)
        except Exception:
            future.set_exc_info(sys.exc_info())
            return future
        else:
            if isinstance(result, GeneratorType):
                # Inline the first iteration of Runner.run.  This lets us
                # avoid the cost of creating a Runner when the coroutine
                # never actually yields, which in turn allows us to
                # use "optional" coroutines in critical path code without
                # performance penalty for the synchronous case.
                try:
                    orig_stack_contexts = stack_context._state.contexts
>                   yielded = next(result)

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:307: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <jupyterhub.proxy.ConfigurableHTTPProxy object at 0x7fdd73308d68>

    @gen.coroutine
    def start(self):
        public_server = Server.from_url(self.public_url)
        api_server = Server.from_url(self.api_url)
        env = os.environ.copy()
        env['CONFIGPROXY_AUTH_TOKEN'] = self.auth_token
        cmd = self.command + [
            '--ip', public_server.ip,
            '--port', str(public_server.port),
            '--api-ip', api_server.ip,
            '--api-port', str(api_server.port),
            '--error-target', url_path_join(self.hub.url, 'error'),
        ]
        if self.app.subdomain_host:
            cmd.append('--host-routing')
        if self.debug:
            cmd.extend(['--log-level', 'debug'])
        if self.ssl_key:
            cmd.extend(['--ssl-key', self.ssl_key])
        if self.ssl_cert:
            cmd.extend(['--ssl-cert', self.ssl_cert])
        if self.app.statsd_host:
            cmd.extend([
                '--statsd-host', self.app.statsd_host,
                '--statsd-port', str(self.app.statsd_port),
                '--statsd-prefix', self.app.statsd_prefix + '.chp'
            ])
        # Warn if SSL is not used
        if ' --ssl' not in ' '.join(cmd):
            self.log.warning("Running JupyterHub without SSL."
                             "  I hope there is SSL termination happening somewhere else...")
        self.log.info("Starting proxy @ %s", public_server.bind_url)
        self.log.debug("Proxy cmd: %s", cmd)
        shell = os.name == 'nt'
        try:
>           self.proxy_process = Popen(cmd, env=env, start_new_session=True, shell=shell)

/home/ec2-user/jupyterhub/jupyterhub/proxy.py:462: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <subprocess.Popen object at 0x7fdd735409e8>
args = ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '35321', '--api-ip', ...], bufsize = -1
executable = None, stdin = None, stdout = None, stderr = None, preexec_fn = None, close_fds = True
shell = False, cwd = None
env = {'COLUMNS': '108', 'CONFIGPROXY_AUTH_TOKEN': 'a051cf59f0a04f92b2bd065848dc4ed0', 'CVS_RSH': 'ssh', 'HISTCONTROL': 'ignoredups', ...}
universal_newlines = False, startupinfo = None, creationflags = 0, restore_signals = True
start_new_session = True, pass_fds = ()

    def __init__(self, args, bufsize=-1, executable=None,
                 stdin=None, stdout=None, stderr=None,
                 preexec_fn=None, close_fds=_PLATFORM_DEFAULT_CLOSE_FDS,
                 shell=False, cwd=None, env=None, universal_newlines=False,
                 startupinfo=None, creationflags=0,
                 restore_signals=True, start_new_session=False,
                 pass_fds=(), *, encoding=None, errors=None):
        """Create new Popen instance."""
        _cleanup()
        # Held while anything is calling waitpid before returncode has been
        # updated to prevent clobbering returncode if wait() or poll() are
        # called from multiple threads at once.  After acquiring the lock,
        # code must re-check self.returncode to see if another thread just
        # finished a waitpid() call.
        self._waitpid_lock = threading.Lock()
    
        self._input = None
        self._communication_started = False
        if bufsize is None:
            bufsize = -1  # Restore default
        if not isinstance(bufsize, int):
            raise TypeError("bufsize must be an integer")
    
        if _mswindows:
            if preexec_fn is not None:
                raise ValueError("preexec_fn is not supported on Windows "
                                 "platforms")
            any_stdio_set = (stdin is not None or stdout is not None or
                             stderr is not None)
            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:
                if any_stdio_set:
                    close_fds = False
                else:
                    close_fds = True
            elif close_fds and any_stdio_set:
                raise ValueError(
                        "close_fds is not supported on Windows platforms"
                        " if you redirect stdin/stdout/stderr")
        else:
            # POSIX
            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:
                close_fds = True
            if pass_fds and not close_fds:
                warnings.warn("pass_fds overriding close_fds.", RuntimeWarning)
                close_fds = True
            if startupinfo is not None:
                raise ValueError("startupinfo is only supported on Windows "
                                 "platforms")
            if creationflags != 0:
                raise ValueError("creationflags is only supported on Windows "
                                 "platforms")
    
        self.args = args
        self.stdin = None
        self.stdout = None
        self.stderr = None
        self.pid = None
        self.returncode = None
        self.universal_newlines = universal_newlines
        self.encoding = encoding
        self.errors = errors
    
        # Input and output objects. The general principle is like
        # this:
        #
        # Parent                   Child
        # ------                   -----
        # p2cwrite   ---stdin--->  p2cread
        # c2pread    <--stdout---  c2pwrite
        # errread    <--stderr---  errwrite
        #
        # On POSIX, the child objects are file descriptors.  On
        # Windows, these are Windows file handles.  The parent objects
        # are file descriptors on both platforms.  The parent objects
        # are -1 when not using PIPEs. The child objects are -1
        # when not redirecting.
    
        (p2cread, p2cwrite,
         c2pread, c2pwrite,
         errread, errwrite) = self._get_handles(stdin, stdout, stderr)
    
        # We wrap OS handles *before* launching the child, otherwise a
        # quickly terminating child could make our fds unwrappable
        # (see #8458).
    
        if _mswindows:
            if p2cwrite != -1:
                p2cwrite = msvcrt.open_osfhandle(p2cwrite.Detach(), 0)
            if c2pread != -1:
                c2pread = msvcrt.open_osfhandle(c2pread.Detach(), 0)
            if errread != -1:
                errread = msvcrt.open_osfhandle(errread.Detach(), 0)
    
        text_mode = encoding or errors or universal_newlines
    
        self._closed_child_pipe_fds = False
    
        try:
            if p2cwrite != -1:
                self.stdin = io.open(p2cwrite, 'wb', bufsize)
                if text_mode:
                    self.stdin = io.TextIOWrapper(self.stdin, write_through=True,
                            line_buffering=(bufsize == 1),
                            encoding=encoding, errors=errors)
            if c2pread != -1:
                self.stdout = io.open(c2pread, 'rb', bufsize)
                if text_mode:
                    self.stdout = io.TextIOWrapper(self.stdout,
                            encoding=encoding, errors=errors)
            if errread != -1:
                self.stderr = io.open(errread, 'rb', bufsize)
                if text_mode:
                    self.stderr = io.TextIOWrapper(self.stderr,
                            encoding=encoding, errors=errors)
    
            self._execute_child(args, executable, preexec_fn, close_fds,
                                pass_fds, cwd, env,
                                startupinfo, creationflags, shell,
                                p2cread, p2cwrite,
                                c2pread, c2pwrite,
                                errread, errwrite,
>                               restore_signals, start_new_session)

/home/ec2-user/anaconda3/lib/python3.6/subprocess.py:707: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <subprocess.Popen object at 0x7fdd735409e8>
args = ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '35321', '--api-ip', ...]
executable = b'configurable-http-proxy', preexec_fn = None, close_fds = True, pass_fds = (), cwd = None
env = {'COLUMNS': '108', 'CONFIGPROXY_AUTH_TOKEN': 'a051cf59f0a04f92b2bd065848dc4ed0', 'CVS_RSH': 'ssh', 'HISTCONTROL': 'ignoredups', ...}
startupinfo = None, creationflags = 0, shell = False, p2cread = -1, p2cwrite = -1, c2pread = -1
c2pwrite = -1, errread = -1, errwrite = -1, restore_signals = True, start_new_session = True

    def _execute_child(self, args, executable, preexec_fn, close_fds,
                       pass_fds, cwd, env,
                       startupinfo, creationflags, shell,
                       p2cread, p2cwrite,
                       c2pread, c2pwrite,
                       errread, errwrite,
                       restore_signals, start_new_session):
        """Execute program (POSIX version)"""
    
        if isinstance(args, (str, bytes)):
            args = [args]
        else:
            args = list(args)
    
        if shell:
            args = ["/bin/sh", "-c"] + args
            if executable:
                args[0] = executable
    
        if executable is None:
            executable = args[0]
        orig_executable = executable
    
        # For transferring possible exec failure from child to parent.
        # Data format: "exception name:hex errno:description"
        # Pickle is not used; it is complex and involves memory allocation.
        errpipe_read, errpipe_write = os.pipe()
        # errpipe_write must not be in the standard io 0, 1, or 2 fd range.
        low_fds_to_close = []
        while errpipe_write < 3:
            low_fds_to_close.append(errpipe_write)
            errpipe_write = os.dup(errpipe_write)
        for low_fd in low_fds_to_close:
            os.close(low_fd)
        try:
            try:
                # We must avoid complex work that could involve
                # malloc or free in the child process to avoid
                # potential deadlocks, thus we do all this here.
                # and pass it to fork_exec()
    
                if env is not None:
                    env_list = []
                    for k, v in env.items():
                        k = os.fsencode(k)
                        if b'=' in k:
                            raise ValueError("illegal environment variable name")
                        env_list.append(k + b'=' + os.fsencode(v))
                else:
                    env_list = None  # Use execv instead of execve.
                executable = os.fsencode(executable)
                if os.path.dirname(executable):
                    executable_list = (executable,)
                else:
                    # This matches the behavior of os._execvpe().
                    executable_list = tuple(
                        os.path.join(os.fsencode(dir), executable)
                        for dir in os.get_exec_path(env))
                fds_to_keep = set(pass_fds)
                fds_to_keep.add(errpipe_write)
                self.pid = _posixsubprocess.fork_exec(
                        args, executable_list,
                        close_fds, tuple(sorted(map(int, fds_to_keep))),
                        cwd, env_list,
                        p2cread, p2cwrite, c2pread, c2pwrite,
                        errread, errwrite,
                        errpipe_read, errpipe_write,
                        restore_signals, start_new_session, preexec_fn)
                self._child_created = True
            finally:
                # be sure the FD is closed no matter what
                os.close(errpipe_write)
    
            # self._devnull is not always defined.
            devnull_fd = getattr(self, '_devnull', None)
            if p2cread != -1 and p2cwrite != -1 and p2cread != devnull_fd:
                os.close(p2cread)
            if c2pwrite != -1 and c2pread != -1 and c2pwrite != devnull_fd:
                os.close(c2pwrite)
            if errwrite != -1 and errread != -1 and errwrite != devnull_fd:
                os.close(errwrite)
            if devnull_fd is not None:
                os.close(devnull_fd)
            # Prevent a double close of these fds from __init__ on error.
            self._closed_child_pipe_fds = True
    
            # Wait for exec to fail or succeed; possibly raising an
            # exception (limited in size)
            errpipe_data = bytearray()
            while True:
                part = os.read(errpipe_read, 50000)
                errpipe_data += part
                if not part or len(errpipe_data) > 50000:
                    break
        finally:
            # be sure the FD is closed no matter what
            os.close(errpipe_read)
    
        if errpipe_data:
            try:
                pid, sts = os.waitpid(self.pid, 0)
                if pid == self.pid:
                    self._handle_exitstatus(sts)
                else:
                    self.returncode = sys.maxsize
            except ChildProcessError:
                pass
    
            try:
                exception_name, hex_errno, err_msg = (
                        errpipe_data.split(b':', 2))
            except ValueError:
                exception_name = b'SubprocessError'
                hex_errno = b'0'
                err_msg = (b'Bad exception data from child: ' +
                           repr(errpipe_data))
            child_exception_type = getattr(
                    builtins, exception_name.decode('ascii'),
                    SubprocessError)
            err_msg = err_msg.decode(errors="surrogatepass")
            if issubclass(child_exception_type, OSError) and hex_errno:
                errno_num = int(hex_errno, 16)
                child_exec_never_called = (err_msg == "noexec")
                if child_exec_never_called:
                    err_msg = ""
                if errno_num != 0:
                    err_msg = os.strerror(errno_num)
                    if errno_num == errno.ENOENT:
                        if child_exec_never_called:
                            # The error must be from chdir(cwd).
                            err_msg += ': ' + repr(cwd)
                        else:
                            err_msg += ': ' + repr(orig_executable)
>               raise child_exception_type(errno_num, err_msg)
E               FileNotFoundError: [Errno 2] No such file or directory: 'configurable-http-proxy'

/home/ec2-user/anaconda3/lib/python3.6/subprocess.py:1333: FileNotFoundError

During handling of the above exception, another exception occurred:

request = <SubRequest 'app' for <Function 'test_managed_service'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd73748278>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:832: in start
    self._run_callback(self._callbacks.popleft())
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:605: in _run_callback
    ret = callback()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py:277: in null_wrapper
    return fn(*args, **kwargs)
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:436: in run
    result = func()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:319: in wrapper
    _futures_to_runners[future] = Runner(result, future, yielded)
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1003: in __init__
    self.run()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1069: in run
    yielded = self.gen.send(value)
/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:62: in make_app
    yield mocked_app.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:319: in wrapper
    _futures_to_runners[future] = Runner(result, future, yielded)
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1003: in __init__
    self.run()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1063: in run
    yielded = self.gen.throw(*exc_info)
/home/ec2-user/jupyterhub/jupyterhub/app.py:1553: in start
    self.exit(1)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <jupyterhub.tests.mocking.MockHub object at 0x7fdd735223c8>, exit_status = 1

    def exit(self, exit_status=0):
        self.log.debug("Exiting application: %s" % self.name)
>       sys.exit(exit_status)
E       SystemExit: 1

/home/ec2-user/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py:648: SystemExit
------------------------------------------ Captured stderr setup -------------------------------------------
[D 46:04.618 MockHub app:1365] Writing PID 27865 to /tmp/tmpmnlio8zx
[D 46:04.619 MockHub app:903] Connecting to db: sqlite:////tmp/tmpryr2_9ur
[D 46:04.623 MockHub orm:475] Stamping empty database with alembic revision 3ec6993fe20c
[I 46:04.625 alembic.runtime.migration migration:117] Context impl SQLiteImpl.
[I 46:04.625 alembic.runtime.migration migration:122] Will assume non-transactional DDL.
[I 46:04.631 alembic.runtime.migration migration:327] Running stamp_revision  -> 3ec6993fe20c
[D 46:04.631 alembic.runtime.migration migration:516] new branch insert 3ec6993fe20c
[I 46:04.698 MockHub app:1000] Not using whitelist. Any authenticated user will be allowed.
[D 46:04.707 MockHub app:1228] Loading state for admin from db
[D 46:04.708 MockHub app:1258] Loaded users: 
       admin admin
[I 46:04.714 MockHub app:1545] Hub API listening on http://127.0.0.1:8081/@/space%20word/hub/
[W 46:04.715 MockHub proxy:415] 
    Generating CONFIGPROXY_AUTH_TOKEN. Restarting the Hub will require restarting the proxy.
    Set CONFIGPROXY_AUTH_TOKEN env or JupyterHub.proxy_auth_token config to avoid this message.
    
[W 46:04.715 MockHub proxy:456] Running JupyterHub without SSL.  I hope there is SSL termination happening somewhere else...
[I 46:04.715 MockHub proxy:458] Starting proxy @ http://127.0.0.1:35321/@/space%20word/
[D 46:04.715 MockHub proxy:459] Proxy cmd: ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '35321', '--api-ip', '127.0.0.1', '--api-port', '8001', '--error-target', 'http://127.0.0.1:8081/@/space%20word/hub/error']
[E 46:04.719 MockHub proxy:467] Failed to find proxy ['configurable-http-proxy']
    The proxy can be installed with `npm install -g configurable-http-proxy`
[C 46:04.719 MockHub app:1552] Failed to start proxy
    Traceback (most recent call last):
      File "/home/ec2-user/jupyterhub/jupyterhub/app.py", line 1550, in start
        yield self.proxy.start()
      File "/home/ec2-user/jupyterhub/jupyterhub/proxy.py", line 462, in start
        self.proxy_process = Popen(cmd, env=env, start_new_session=True, shell=shell)
      File "/home/ec2-user/anaconda3/lib/python3.6/subprocess.py", line 707, in __init__
        restore_signals, start_new_session)
      File "/home/ec2-user/anaconda3/lib/python3.6/subprocess.py", line 1333, in _execute_child
        raise child_exception_type(errno_num, err_msg)
    FileNotFoundError: [Errno 2] No such file or directory: 'configurable-http-proxy'
    
[D 46:04.719 MockHub application:647] Exiting application: jupyterhub
___________________________________ ERROR at setup of test_proxy_service ___________________________________

request = <SubRequest 'app' for <Function 'test_proxy_service'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd73748278>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd73748278>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_________________________________ ERROR at setup of test_external_service __________________________________

request = <SubRequest 'app' for <Function 'test_proxy_service'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd73748278>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd73748278>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
__________________________________ ERROR at setup of test_hubauth_cookie ___________________________________

self = <jupyterhub.tests.mocking.MockHub object at 0x7fdd735223c8>

    @gen.coroutine
    def start(self):
        """Start the whole thing"""
        self.io_loop = loop = IOLoop.current()
    
        if self.subapp:
            self.subapp.start()
            loop.stop()
            return
    
        if self.generate_config:
            self.write_config_file()
            loop.stop()
            return
    
        # start the webserver
        self.http_server = tornado.httpserver.HTTPServer(self.tornado_application, xheaders=True)
        try:
            self.http_server.listen(self.hub_port, address=self.hub_ip)
        except Exception:
            self.log.error("Failed to bind hub to %s", self.hub.bind_url)
            raise
        else:
            self.log.info("Hub API listening on %s", self.hub.bind_url)
    
        # start the proxy
        if self.proxy.should_start:
            try:
>               yield self.proxy.start()

/home/ec2-user/jupyterhub/jupyterhub/app.py:1550: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tornado.gen.Runner object at 0x7fdd7217cb70>

    def run(self):
        """Starts or resumes the generator, running until it reaches a
            yield point that is not ready.
            """
        if self.running or self.finished:
            return
        try:
            self.running = True
            while True:
                future = self.future
                if not future.done():
                    return
                self.future = None
                try:
                    orig_stack_contexts = stack_context._state.contexts
                    exc_info = None
    
                    try:
>                       value = future.result()

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1055: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = None, timeout = None

    def result(self, timeout=None):
        """If the operation succeeded, return its result.  If it failed,
            re-raise its exception.
    
            This method takes a ``timeout`` argument for compatibility with
            `concurrent.futures.Future` but it is an error to call it
            before the `Future` is done, so the ``timeout`` is never used.
            """
        self._clear_tb_log()
        if self._result is not None:
            return self._result
        if self._exc_info is not None:
            try:
>               raise_exc_info(self._exc_info)

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/concurrent.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

exc_info = None

>   ???

<string>:4: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<jupyterhub.proxy.ConfigurableHTTPProxy object at 0x7fdd738d5cc0>,), kwargs = {}, future = None
result = <generator object start at 0x7fdd7375ae08>, orig_stack_contexts = ((), None), yielded = None

    @functools.wraps(wrapped)
    def wrapper(*args, **kwargs):
        future = TracebackFuture()
    
        if replace_callback and 'callback' in kwargs:
            callback = kwargs.pop('callback')
            IOLoop.current().add_future(
                future, lambda future: callback(future.result()))
    
        try:
            result = func(*args, **kwargs)
        except (Return, StopIteration) as e:
            result = _value_from_stopiteration(e)
        except Exception:
            future.set_exc_info(sys.exc_info())
            return future
        else:
            if isinstance(result, GeneratorType):
                # Inline the first iteration of Runner.run.  This lets us
                # avoid the cost of creating a Runner when the coroutine
                # never actually yields, which in turn allows us to
                # use "optional" coroutines in critical path code without
                # performance penalty for the synchronous case.
                try:
                    orig_stack_contexts = stack_context._state.contexts
>                   yielded = next(result)

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:307: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <jupyterhub.proxy.ConfigurableHTTPProxy object at 0x7fdd738d5cc0>

    @gen.coroutine
    def start(self):
        public_server = Server.from_url(self.public_url)
        api_server = Server.from_url(self.api_url)
        env = os.environ.copy()
        env['CONFIGPROXY_AUTH_TOKEN'] = self.auth_token
        cmd = self.command + [
            '--ip', public_server.ip,
            '--port', str(public_server.port),
            '--api-ip', api_server.ip,
            '--api-port', str(api_server.port),
            '--error-target', url_path_join(self.hub.url, 'error'),
        ]
        if self.app.subdomain_host:
            cmd.append('--host-routing')
        if self.debug:
            cmd.extend(['--log-level', 'debug'])
        if self.ssl_key:
            cmd.extend(['--ssl-key', self.ssl_key])
        if self.ssl_cert:
            cmd.extend(['--ssl-cert', self.ssl_cert])
        if self.app.statsd_host:
            cmd.extend([
                '--statsd-host', self.app.statsd_host,
                '--statsd-port', str(self.app.statsd_port),
                '--statsd-prefix', self.app.statsd_prefix + '.chp'
            ])
        # Warn if SSL is not used
        if ' --ssl' not in ' '.join(cmd):
            self.log.warning("Running JupyterHub without SSL."
                             "  I hope there is SSL termination happening somewhere else...")
        self.log.info("Starting proxy @ %s", public_server.bind_url)
        self.log.debug("Proxy cmd: %s", cmd)
        shell = os.name == 'nt'
        try:
>           self.proxy_process = Popen(cmd, env=env, start_new_session=True, shell=shell)

/home/ec2-user/jupyterhub/jupyterhub/proxy.py:462: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <subprocess.Popen object at 0x7fdd7217c358>
args = ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '35321', '--api-ip', ...], bufsize = -1
executable = None, stdin = None, stdout = None, stderr = None, preexec_fn = None, close_fds = True
shell = False, cwd = None
env = {'COLUMNS': '108', 'CONFIGPROXY_AUTH_TOKEN': '70dd5e0e6cb749e28d48ead33b09847a', 'CVS_RSH': 'ssh', 'HISTCONTROL': 'ignoredups', ...}
universal_newlines = False, startupinfo = None, creationflags = 0, restore_signals = True
start_new_session = True, pass_fds = ()

    def __init__(self, args, bufsize=-1, executable=None,
                 stdin=None, stdout=None, stderr=None,
                 preexec_fn=None, close_fds=_PLATFORM_DEFAULT_CLOSE_FDS,
                 shell=False, cwd=None, env=None, universal_newlines=False,
                 startupinfo=None, creationflags=0,
                 restore_signals=True, start_new_session=False,
                 pass_fds=(), *, encoding=None, errors=None):
        """Create new Popen instance."""
        _cleanup()
        # Held while anything is calling waitpid before returncode has been
        # updated to prevent clobbering returncode if wait() or poll() are
        # called from multiple threads at once.  After acquiring the lock,
        # code must re-check self.returncode to see if another thread just
        # finished a waitpid() call.
        self._waitpid_lock = threading.Lock()
    
        self._input = None
        self._communication_started = False
        if bufsize is None:
            bufsize = -1  # Restore default
        if not isinstance(bufsize, int):
            raise TypeError("bufsize must be an integer")
    
        if _mswindows:
            if preexec_fn is not None:
                raise ValueError("preexec_fn is not supported on Windows "
                                 "platforms")
            any_stdio_set = (stdin is not None or stdout is not None or
                             stderr is not None)
            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:
                if any_stdio_set:
                    close_fds = False
                else:
                    close_fds = True
            elif close_fds and any_stdio_set:
                raise ValueError(
                        "close_fds is not supported on Windows platforms"
                        " if you redirect stdin/stdout/stderr")
        else:
            # POSIX
            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:
                close_fds = True
            if pass_fds and not close_fds:
                warnings.warn("pass_fds overriding close_fds.", RuntimeWarning)
                close_fds = True
            if startupinfo is not None:
                raise ValueError("startupinfo is only supported on Windows "
                                 "platforms")
            if creationflags != 0:
                raise ValueError("creationflags is only supported on Windows "
                                 "platforms")
    
        self.args = args
        self.stdin = None
        self.stdout = None
        self.stderr = None
        self.pid = None
        self.returncode = None
        self.universal_newlines = universal_newlines
        self.encoding = encoding
        self.errors = errors
    
        # Input and output objects. The general principle is like
        # this:
        #
        # Parent                   Child
        # ------                   -----
        # p2cwrite   ---stdin--->  p2cread
        # c2pread    <--stdout---  c2pwrite
        # errread    <--stderr---  errwrite
        #
        # On POSIX, the child objects are file descriptors.  On
        # Windows, these are Windows file handles.  The parent objects
        # are file descriptors on both platforms.  The parent objects
        # are -1 when not using PIPEs. The child objects are -1
        # when not redirecting.
    
        (p2cread, p2cwrite,
         c2pread, c2pwrite,
         errread, errwrite) = self._get_handles(stdin, stdout, stderr)
    
        # We wrap OS handles *before* launching the child, otherwise a
        # quickly terminating child could make our fds unwrappable
        # (see #8458).
    
        if _mswindows:
            if p2cwrite != -1:
                p2cwrite = msvcrt.open_osfhandle(p2cwrite.Detach(), 0)
            if c2pread != -1:
                c2pread = msvcrt.open_osfhandle(c2pread.Detach(), 0)
            if errread != -1:
                errread = msvcrt.open_osfhandle(errread.Detach(), 0)
    
        text_mode = encoding or errors or universal_newlines
    
        self._closed_child_pipe_fds = False
    
        try:
            if p2cwrite != -1:
                self.stdin = io.open(p2cwrite, 'wb', bufsize)
                if text_mode:
                    self.stdin = io.TextIOWrapper(self.stdin, write_through=True,
                            line_buffering=(bufsize == 1),
                            encoding=encoding, errors=errors)
            if c2pread != -1:
                self.stdout = io.open(c2pread, 'rb', bufsize)
                if text_mode:
                    self.stdout = io.TextIOWrapper(self.stdout,
                            encoding=encoding, errors=errors)
            if errread != -1:
                self.stderr = io.open(errread, 'rb', bufsize)
                if text_mode:
                    self.stderr = io.TextIOWrapper(self.stderr,
                            encoding=encoding, errors=errors)
    
            self._execute_child(args, executable, preexec_fn, close_fds,
                                pass_fds, cwd, env,
                                startupinfo, creationflags, shell,
                                p2cread, p2cwrite,
                                c2pread, c2pwrite,
                                errread, errwrite,
>                               restore_signals, start_new_session)

/home/ec2-user/anaconda3/lib/python3.6/subprocess.py:707: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <subprocess.Popen object at 0x7fdd7217c358>
args = ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '35321', '--api-ip', ...]
executable = b'configurable-http-proxy', preexec_fn = None, close_fds = True, pass_fds = (), cwd = None
env = {'COLUMNS': '108', 'CONFIGPROXY_AUTH_TOKEN': '70dd5e0e6cb749e28d48ead33b09847a', 'CVS_RSH': 'ssh', 'HISTCONTROL': 'ignoredups', ...}
startupinfo = None, creationflags = 0, shell = False, p2cread = -1, p2cwrite = -1, c2pread = -1
c2pwrite = -1, errread = -1, errwrite = -1, restore_signals = True, start_new_session = True

    def _execute_child(self, args, executable, preexec_fn, close_fds,
                       pass_fds, cwd, env,
                       startupinfo, creationflags, shell,
                       p2cread, p2cwrite,
                       c2pread, c2pwrite,
                       errread, errwrite,
                       restore_signals, start_new_session):
        """Execute program (POSIX version)"""
    
        if isinstance(args, (str, bytes)):
            args = [args]
        else:
            args = list(args)
    
        if shell:
            args = ["/bin/sh", "-c"] + args
            if executable:
                args[0] = executable
    
        if executable is None:
            executable = args[0]
        orig_executable = executable
    
        # For transferring possible exec failure from child to parent.
        # Data format: "exception name:hex errno:description"
        # Pickle is not used; it is complex and involves memory allocation.
        errpipe_read, errpipe_write = os.pipe()
        # errpipe_write must not be in the standard io 0, 1, or 2 fd range.
        low_fds_to_close = []
        while errpipe_write < 3:
            low_fds_to_close.append(errpipe_write)
            errpipe_write = os.dup(errpipe_write)
        for low_fd in low_fds_to_close:
            os.close(low_fd)
        try:
            try:
                # We must avoid complex work that could involve
                # malloc or free in the child process to avoid
                # potential deadlocks, thus we do all this here.
                # and pass it to fork_exec()
    
                if env is not None:
                    env_list = []
                    for k, v in env.items():
                        k = os.fsencode(k)
                        if b'=' in k:
                            raise ValueError("illegal environment variable name")
                        env_list.append(k + b'=' + os.fsencode(v))
                else:
                    env_list = None  # Use execv instead of execve.
                executable = os.fsencode(executable)
                if os.path.dirname(executable):
                    executable_list = (executable,)
                else:
                    # This matches the behavior of os._execvpe().
                    executable_list = tuple(
                        os.path.join(os.fsencode(dir), executable)
                        for dir in os.get_exec_path(env))
                fds_to_keep = set(pass_fds)
                fds_to_keep.add(errpipe_write)
                self.pid = _posixsubprocess.fork_exec(
                        args, executable_list,
                        close_fds, tuple(sorted(map(int, fds_to_keep))),
                        cwd, env_list,
                        p2cread, p2cwrite, c2pread, c2pwrite,
                        errread, errwrite,
                        errpipe_read, errpipe_write,
                        restore_signals, start_new_session, preexec_fn)
                self._child_created = True
            finally:
                # be sure the FD is closed no matter what
                os.close(errpipe_write)
    
            # self._devnull is not always defined.
            devnull_fd = getattr(self, '_devnull', None)
            if p2cread != -1 and p2cwrite != -1 and p2cread != devnull_fd:
                os.close(p2cread)
            if c2pwrite != -1 and c2pread != -1 and c2pwrite != devnull_fd:
                os.close(c2pwrite)
            if errwrite != -1 and errread != -1 and errwrite != devnull_fd:
                os.close(errwrite)
            if devnull_fd is not None:
                os.close(devnull_fd)
            # Prevent a double close of these fds from __init__ on error.
            self._closed_child_pipe_fds = True
    
            # Wait for exec to fail or succeed; possibly raising an
            # exception (limited in size)
            errpipe_data = bytearray()
            while True:
                part = os.read(errpipe_read, 50000)
                errpipe_data += part
                if not part or len(errpipe_data) > 50000:
                    break
        finally:
            # be sure the FD is closed no matter what
            os.close(errpipe_read)
    
        if errpipe_data:
            try:
                pid, sts = os.waitpid(self.pid, 0)
                if pid == self.pid:
                    self._handle_exitstatus(sts)
                else:
                    self.returncode = sys.maxsize
            except ChildProcessError:
                pass
    
            try:
                exception_name, hex_errno, err_msg = (
                        errpipe_data.split(b':', 2))
            except ValueError:
                exception_name = b'SubprocessError'
                hex_errno = b'0'
                err_msg = (b'Bad exception data from child: ' +
                           repr(errpipe_data))
            child_exception_type = getattr(
                    builtins, exception_name.decode('ascii'),
                    SubprocessError)
            err_msg = err_msg.decode(errors="surrogatepass")
            if issubclass(child_exception_type, OSError) and hex_errno:
                errno_num = int(hex_errno, 16)
                child_exec_never_called = (err_msg == "noexec")
                if child_exec_never_called:
                    err_msg = ""
                if errno_num != 0:
                    err_msg = os.strerror(errno_num)
                    if errno_num == errno.ENOENT:
                        if child_exec_never_called:
                            # The error must be from chdir(cwd).
                            err_msg += ': ' + repr(cwd)
                        else:
                            err_msg += ': ' + repr(orig_executable)
>               raise child_exception_type(errno_num, err_msg)
E               FileNotFoundError: [Errno 2] No such file or directory: 'configurable-http-proxy'

/home/ec2-user/anaconda3/lib/python3.6/subprocess.py:1333: FileNotFoundError

During handling of the above exception, another exception occurred:

request = <SubRequest 'app' for <Function 'test_hubauth_cookie'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd742b4f28>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:832: in start
    self._run_callback(self._callbacks.popleft())
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:605: in _run_callback
    ret = callback()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py:277: in null_wrapper
    return fn(*args, **kwargs)
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:436: in run
    result = func()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:319: in wrapper
    _futures_to_runners[future] = Runner(result, future, yielded)
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1003: in __init__
    self.run()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1069: in run
    yielded = self.gen.send(value)
/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:62: in make_app
    yield mocked_app.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:319: in wrapper
    _futures_to_runners[future] = Runner(result, future, yielded)
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1003: in __init__
    self.run()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1063: in run
    yielded = self.gen.throw(*exc_info)
/home/ec2-user/jupyterhub/jupyterhub/app.py:1553: in start
    self.exit(1)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <jupyterhub.tests.mocking.MockHub object at 0x7fdd735223c8>, exit_status = 1

    def exit(self, exit_status=0):
        self.log.debug("Exiting application: %s" % self.name)
>       sys.exit(exit_status)
E       SystemExit: 1

/home/ec2-user/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py:648: SystemExit
------------------------------------------ Captured stderr setup -------------------------------------------
[D 46:05.063 MockHub app:1365] Writing PID 27865 to /tmp/tmpa63uc9gs
[D 46:05.063 MockHub app:903] Connecting to db: sqlite:////tmp/tmppptjktm7
[D 46:05.067 MockHub orm:475] Stamping empty database with alembic revision 3ec6993fe20c
[I 46:05.070 alembic.runtime.migration migration:117] Context impl SQLiteImpl.
[I 46:05.070 alembic.runtime.migration migration:122] Will assume non-transactional DDL.
[I 46:05.076 alembic.runtime.migration migration:327] Running stamp_revision  -> 3ec6993fe20c
[D 46:05.076 alembic.runtime.migration migration:516] new branch insert 3ec6993fe20c
[I 46:05.140 MockHub app:1000] Not using whitelist. Any authenticated user will be allowed.
[D 46:05.149 MockHub app:1228] Loading state for admin from db
[D 46:05.150 MockHub app:1258] Loaded users: 
       admin admin
[I 46:05.157 MockHub app:1545] Hub API listening on http://127.0.0.1:8081/@/space%20word/hub/
[W 46:05.157 MockHub proxy:415] 
    Generating CONFIGPROXY_AUTH_TOKEN. Restarting the Hub will require restarting the proxy.
    Set CONFIGPROXY_AUTH_TOKEN env or JupyterHub.proxy_auth_token config to avoid this message.
    
[W 46:05.157 MockHub proxy:456] Running JupyterHub without SSL.  I hope there is SSL termination happening somewhere else...
[I 46:05.158 MockHub proxy:458] Starting proxy @ http://127.0.0.1:35321/@/space%20word/
[D 46:05.158 MockHub proxy:459] Proxy cmd: ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '35321', '--api-ip', '127.0.0.1', '--api-port', '8001', '--error-target', 'http://127.0.0.1:8081/@/space%20word/hub/error']
[E 46:05.161 MockHub proxy:467] Failed to find proxy ['configurable-http-proxy']
    The proxy can be installed with `npm install -g configurable-http-proxy`
[C 46:05.161 MockHub app:1552] Failed to start proxy
    Traceback (most recent call last):
      File "/home/ec2-user/jupyterhub/jupyterhub/app.py", line 1550, in start
        yield self.proxy.start()
      File "/home/ec2-user/jupyterhub/jupyterhub/proxy.py", line 462, in start
        self.proxy_process = Popen(cmd, env=env, start_new_session=True, shell=shell)
      File "/home/ec2-user/anaconda3/lib/python3.6/subprocess.py", line 707, in __init__
        restore_signals, start_new_session)
      File "/home/ec2-user/anaconda3/lib/python3.6/subprocess.py", line 1333, in _execute_child
        raise child_exception_type(errno_num, err_msg)
    FileNotFoundError: [Errno 2] No such file or directory: 'configurable-http-proxy'
    
[D 46:05.162 MockHub application:647] Exiting application: jupyterhub
___________________________________ ERROR at setup of test_hubauth_token ___________________________________

request = <SubRequest 'app' for <Function 'test_hubauth_token'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd742b4f28>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd742b4f28>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_______________________________ ERROR at setup of test_hubauth_service_token _______________________________

request = <SubRequest 'app' for <Function 'test_hubauth_token'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd742b4f28>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd742b4f28>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
___________________________________ ERROR at setup of test_oauth_service ___________________________________

request = <SubRequest 'app' for <Function 'test_hubauth_token'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd742b4f28>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd742b4f28>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
______________________________ ERROR at setup of test_oauth_cookie_collision _______________________________

request = <SubRequest 'app' for <Function 'test_hubauth_token'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd742b4f28>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd742b4f28>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
__________________________________ ERROR at setup of test_singleuser_auth __________________________________

self = <jupyterhub.tests.mocking.MockHub object at 0x7fdd735223c8>

    @gen.coroutine
    def start(self):
        """Start the whole thing"""
        self.io_loop = loop = IOLoop.current()
    
        if self.subapp:
            self.subapp.start()
            loop.stop()
            return
    
        if self.generate_config:
            self.write_config_file()
            loop.stop()
            return
    
        # start the webserver
        self.http_server = tornado.httpserver.HTTPServer(self.tornado_application, xheaders=True)
        try:
            self.http_server.listen(self.hub_port, address=self.hub_ip)
        except Exception:
            self.log.error("Failed to bind hub to %s", self.hub.bind_url)
            raise
        else:
            self.log.info("Hub API listening on %s", self.hub.bind_url)
    
        # start the proxy
        if self.proxy.should_start:
            try:
>               yield self.proxy.start()

/home/ec2-user/jupyterhub/jupyterhub/app.py:1550: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tornado.gen.Runner object at 0x7fdd72218780>

    def run(self):
        """Starts or resumes the generator, running until it reaches a
            yield point that is not ready.
            """
        if self.running or self.finished:
            return
        try:
            self.running = True
            while True:
                future = self.future
                if not future.done():
                    return
                self.future = None
                try:
                    orig_stack_contexts = stack_context._state.contexts
                    exc_info = None
    
                    try:
>                       value = future.result()

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1055: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = None, timeout = None

    def result(self, timeout=None):
        """If the operation succeeded, return its result.  If it failed,
            re-raise its exception.
    
            This method takes a ``timeout`` argument for compatibility with
            `concurrent.futures.Future` but it is an error to call it
            before the `Future` is done, so the ``timeout`` is never used.
            """
        self._clear_tb_log()
        if self._result is not None:
            return self._result
        if self._exc_info is not None:
            try:
>               raise_exc_info(self._exc_info)

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/concurrent.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

exc_info = None

>   ???

<string>:4: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<jupyterhub.proxy.ConfigurableHTTPProxy object at 0x7fdd733f9128>,), kwargs = {}, future = None
result = <generator object start at 0x7fdd721a0678>, orig_stack_contexts = ((), None), yielded = None

    @functools.wraps(wrapped)
    def wrapper(*args, **kwargs):
        future = TracebackFuture()
    
        if replace_callback and 'callback' in kwargs:
            callback = kwargs.pop('callback')
            IOLoop.current().add_future(
                future, lambda future: callback(future.result()))
    
        try:
            result = func(*args, **kwargs)
        except (Return, StopIteration) as e:
            result = _value_from_stopiteration(e)
        except Exception:
            future.set_exc_info(sys.exc_info())
            return future
        else:
            if isinstance(result, GeneratorType):
                # Inline the first iteration of Runner.run.  This lets us
                # avoid the cost of creating a Runner when the coroutine
                # never actually yields, which in turn allows us to
                # use "optional" coroutines in critical path code without
                # performance penalty for the synchronous case.
                try:
                    orig_stack_contexts = stack_context._state.contexts
>                   yielded = next(result)

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:307: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <jupyterhub.proxy.ConfigurableHTTPProxy object at 0x7fdd733f9128>

    @gen.coroutine
    def start(self):
        public_server = Server.from_url(self.public_url)
        api_server = Server.from_url(self.api_url)
        env = os.environ.copy()
        env['CONFIGPROXY_AUTH_TOKEN'] = self.auth_token
        cmd = self.command + [
            '--ip', public_server.ip,
            '--port', str(public_server.port),
            '--api-ip', api_server.ip,
            '--api-port', str(api_server.port),
            '--error-target', url_path_join(self.hub.url, 'error'),
        ]
        if self.app.subdomain_host:
            cmd.append('--host-routing')
        if self.debug:
            cmd.extend(['--log-level', 'debug'])
        if self.ssl_key:
            cmd.extend(['--ssl-key', self.ssl_key])
        if self.ssl_cert:
            cmd.extend(['--ssl-cert', self.ssl_cert])
        if self.app.statsd_host:
            cmd.extend([
                '--statsd-host', self.app.statsd_host,
                '--statsd-port', str(self.app.statsd_port),
                '--statsd-prefix', self.app.statsd_prefix + '.chp'
            ])
        # Warn if SSL is not used
        if ' --ssl' not in ' '.join(cmd):
            self.log.warning("Running JupyterHub without SSL."
                             "  I hope there is SSL termination happening somewhere else...")
        self.log.info("Starting proxy @ %s", public_server.bind_url)
        self.log.debug("Proxy cmd: %s", cmd)
        shell = os.name == 'nt'
        try:
>           self.proxy_process = Popen(cmd, env=env, start_new_session=True, shell=shell)

/home/ec2-user/jupyterhub/jupyterhub/proxy.py:462: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <subprocess.Popen object at 0x7fdd72218c50>
args = ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '35321', '--api-ip', ...], bufsize = -1
executable = None, stdin = None, stdout = None, stderr = None, preexec_fn = None, close_fds = True
shell = False, cwd = None
env = {'COLUMNS': '108', 'CONFIGPROXY_AUTH_TOKEN': '63594fd4fcac41988f4570902081576c', 'CVS_RSH': 'ssh', 'HISTCONTROL': 'ignoredups', ...}
universal_newlines = False, startupinfo = None, creationflags = 0, restore_signals = True
start_new_session = True, pass_fds = ()

    def __init__(self, args, bufsize=-1, executable=None,
                 stdin=None, stdout=None, stderr=None,
                 preexec_fn=None, close_fds=_PLATFORM_DEFAULT_CLOSE_FDS,
                 shell=False, cwd=None, env=None, universal_newlines=False,
                 startupinfo=None, creationflags=0,
                 restore_signals=True, start_new_session=False,
                 pass_fds=(), *, encoding=None, errors=None):
        """Create new Popen instance."""
        _cleanup()
        # Held while anything is calling waitpid before returncode has been
        # updated to prevent clobbering returncode if wait() or poll() are
        # called from multiple threads at once.  After acquiring the lock,
        # code must re-check self.returncode to see if another thread just
        # finished a waitpid() call.
        self._waitpid_lock = threading.Lock()
    
        self._input = None
        self._communication_started = False
        if bufsize is None:
            bufsize = -1  # Restore default
        if not isinstance(bufsize, int):
            raise TypeError("bufsize must be an integer")
    
        if _mswindows:
            if preexec_fn is not None:
                raise ValueError("preexec_fn is not supported on Windows "
                                 "platforms")
            any_stdio_set = (stdin is not None or stdout is not None or
                             stderr is not None)
            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:
                if any_stdio_set:
                    close_fds = False
                else:
                    close_fds = True
            elif close_fds and any_stdio_set:
                raise ValueError(
                        "close_fds is not supported on Windows platforms"
                        " if you redirect stdin/stdout/stderr")
        else:
            # POSIX
            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:
                close_fds = True
            if pass_fds and not close_fds:
                warnings.warn("pass_fds overriding close_fds.", RuntimeWarning)
                close_fds = True
            if startupinfo is not None:
                raise ValueError("startupinfo is only supported on Windows "
                                 "platforms")
            if creationflags != 0:
                raise ValueError("creationflags is only supported on Windows "
                                 "platforms")
    
        self.args = args
        self.stdin = None
        self.stdout = None
        self.stderr = None
        self.pid = None
        self.returncode = None
        self.universal_newlines = universal_newlines
        self.encoding = encoding
        self.errors = errors
    
        # Input and output objects. The general principle is like
        # this:
        #
        # Parent                   Child
        # ------                   -----
        # p2cwrite   ---stdin--->  p2cread
        # c2pread    <--stdout---  c2pwrite
        # errread    <--stderr---  errwrite
        #
        # On POSIX, the child objects are file descriptors.  On
        # Windows, these are Windows file handles.  The parent objects
        # are file descriptors on both platforms.  The parent objects
        # are -1 when not using PIPEs. The child objects are -1
        # when not redirecting.
    
        (p2cread, p2cwrite,
         c2pread, c2pwrite,
         errread, errwrite) = self._get_handles(stdin, stdout, stderr)
    
        # We wrap OS handles *before* launching the child, otherwise a
        # quickly terminating child could make our fds unwrappable
        # (see #8458).
    
        if _mswindows:
            if p2cwrite != -1:
                p2cwrite = msvcrt.open_osfhandle(p2cwrite.Detach(), 0)
            if c2pread != -1:
                c2pread = msvcrt.open_osfhandle(c2pread.Detach(), 0)
            if errread != -1:
                errread = msvcrt.open_osfhandle(errread.Detach(), 0)
    
        text_mode = encoding or errors or universal_newlines
    
        self._closed_child_pipe_fds = False
    
        try:
            if p2cwrite != -1:
                self.stdin = io.open(p2cwrite, 'wb', bufsize)
                if text_mode:
                    self.stdin = io.TextIOWrapper(self.stdin, write_through=True,
                            line_buffering=(bufsize == 1),
                            encoding=encoding, errors=errors)
            if c2pread != -1:
                self.stdout = io.open(c2pread, 'rb', bufsize)
                if text_mode:
                    self.stdout = io.TextIOWrapper(self.stdout,
                            encoding=encoding, errors=errors)
            if errread != -1:
                self.stderr = io.open(errread, 'rb', bufsize)
                if text_mode:
                    self.stderr = io.TextIOWrapper(self.stderr,
                            encoding=encoding, errors=errors)
    
            self._execute_child(args, executable, preexec_fn, close_fds,
                                pass_fds, cwd, env,
                                startupinfo, creationflags, shell,
                                p2cread, p2cwrite,
                                c2pread, c2pwrite,
                                errread, errwrite,
>                               restore_signals, start_new_session)

/home/ec2-user/anaconda3/lib/python3.6/subprocess.py:707: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <subprocess.Popen object at 0x7fdd72218c50>
args = ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '35321', '--api-ip', ...]
executable = b'configurable-http-proxy', preexec_fn = None, close_fds = True, pass_fds = (), cwd = None
env = {'COLUMNS': '108', 'CONFIGPROXY_AUTH_TOKEN': '63594fd4fcac41988f4570902081576c', 'CVS_RSH': 'ssh', 'HISTCONTROL': 'ignoredups', ...}
startupinfo = None, creationflags = 0, shell = False, p2cread = -1, p2cwrite = -1, c2pread = -1
c2pwrite = -1, errread = -1, errwrite = -1, restore_signals = True, start_new_session = True

    def _execute_child(self, args, executable, preexec_fn, close_fds,
                       pass_fds, cwd, env,
                       startupinfo, creationflags, shell,
                       p2cread, p2cwrite,
                       c2pread, c2pwrite,
                       errread, errwrite,
                       restore_signals, start_new_session):
        """Execute program (POSIX version)"""
    
        if isinstance(args, (str, bytes)):
            args = [args]
        else:
            args = list(args)
    
        if shell:
            args = ["/bin/sh", "-c"] + args
            if executable:
                args[0] = executable
    
        if executable is None:
            executable = args[0]
        orig_executable = executable
    
        # For transferring possible exec failure from child to parent.
        # Data format: "exception name:hex errno:description"
        # Pickle is not used; it is complex and involves memory allocation.
        errpipe_read, errpipe_write = os.pipe()
        # errpipe_write must not be in the standard io 0, 1, or 2 fd range.
        low_fds_to_close = []
        while errpipe_write < 3:
            low_fds_to_close.append(errpipe_write)
            errpipe_write = os.dup(errpipe_write)
        for low_fd in low_fds_to_close:
            os.close(low_fd)
        try:
            try:
                # We must avoid complex work that could involve
                # malloc or free in the child process to avoid
                # potential deadlocks, thus we do all this here.
                # and pass it to fork_exec()
    
                if env is not None:
                    env_list = []
                    for k, v in env.items():
                        k = os.fsencode(k)
                        if b'=' in k:
                            raise ValueError("illegal environment variable name")
                        env_list.append(k + b'=' + os.fsencode(v))
                else:
                    env_list = None  # Use execv instead of execve.
                executable = os.fsencode(executable)
                if os.path.dirname(executable):
                    executable_list = (executable,)
                else:
                    # This matches the behavior of os._execvpe().
                    executable_list = tuple(
                        os.path.join(os.fsencode(dir), executable)
                        for dir in os.get_exec_path(env))
                fds_to_keep = set(pass_fds)
                fds_to_keep.add(errpipe_write)
                self.pid = _posixsubprocess.fork_exec(
                        args, executable_list,
                        close_fds, tuple(sorted(map(int, fds_to_keep))),
                        cwd, env_list,
                        p2cread, p2cwrite, c2pread, c2pwrite,
                        errread, errwrite,
                        errpipe_read, errpipe_write,
                        restore_signals, start_new_session, preexec_fn)
                self._child_created = True
            finally:
                # be sure the FD is closed no matter what
                os.close(errpipe_write)
    
            # self._devnull is not always defined.
            devnull_fd = getattr(self, '_devnull', None)
            if p2cread != -1 and p2cwrite != -1 and p2cread != devnull_fd:
                os.close(p2cread)
            if c2pwrite != -1 and c2pread != -1 and c2pwrite != devnull_fd:
                os.close(c2pwrite)
            if errwrite != -1 and errread != -1 and errwrite != devnull_fd:
                os.close(errwrite)
            if devnull_fd is not None:
                os.close(devnull_fd)
            # Prevent a double close of these fds from __init__ on error.
            self._closed_child_pipe_fds = True
    
            # Wait for exec to fail or succeed; possibly raising an
            # exception (limited in size)
            errpipe_data = bytearray()
            while True:
                part = os.read(errpipe_read, 50000)
                errpipe_data += part
                if not part or len(errpipe_data) > 50000:
                    break
        finally:
            # be sure the FD is closed no matter what
            os.close(errpipe_read)
    
        if errpipe_data:
            try:
                pid, sts = os.waitpid(self.pid, 0)
                if pid == self.pid:
                    self._handle_exitstatus(sts)
                else:
                    self.returncode = sys.maxsize
            except ChildProcessError:
                pass
    
            try:
                exception_name, hex_errno, err_msg = (
                        errpipe_data.split(b':', 2))
            except ValueError:
                exception_name = b'SubprocessError'
                hex_errno = b'0'
                err_msg = (b'Bad exception data from child: ' +
                           repr(errpipe_data))
            child_exception_type = getattr(
                    builtins, exception_name.decode('ascii'),
                    SubprocessError)
            err_msg = err_msg.decode(errors="surrogatepass")
            if issubclass(child_exception_type, OSError) and hex_errno:
                errno_num = int(hex_errno, 16)
                child_exec_never_called = (err_msg == "noexec")
                if child_exec_never_called:
                    err_msg = ""
                if errno_num != 0:
                    err_msg = os.strerror(errno_num)
                    if errno_num == errno.ENOENT:
                        if child_exec_never_called:
                            # The error must be from chdir(cwd).
                            err_msg += ': ' + repr(cwd)
                        else:
                            err_msg += ': ' + repr(orig_executable)
>               raise child_exception_type(errno_num, err_msg)
E               FileNotFoundError: [Errno 2] No such file or directory: 'configurable-http-proxy'

/home/ec2-user/anaconda3/lib/python3.6/subprocess.py:1333: FileNotFoundError

During handling of the above exception, another exception occurred:

request = <SubRequest 'app' for <Function 'test_singleuser_auth'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd733f9b00>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:832: in start
    self._run_callback(self._callbacks.popleft())
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:605: in _run_callback
    ret = callback()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py:277: in null_wrapper
    return fn(*args, **kwargs)
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:436: in run
    result = func()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:319: in wrapper
    _futures_to_runners[future] = Runner(result, future, yielded)
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1003: in __init__
    self.run()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1069: in run
    yielded = self.gen.send(value)
/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:62: in make_app
    yield mocked_app.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:319: in wrapper
    _futures_to_runners[future] = Runner(result, future, yielded)
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1003: in __init__
    self.run()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1063: in run
    yielded = self.gen.throw(*exc_info)
/home/ec2-user/jupyterhub/jupyterhub/app.py:1553: in start
    self.exit(1)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <jupyterhub.tests.mocking.MockHub object at 0x7fdd735223c8>, exit_status = 1

    def exit(self, exit_status=0):
        self.log.debug("Exiting application: %s" % self.name)
>       sys.exit(exit_status)
E       SystemExit: 1

/home/ec2-user/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py:648: SystemExit
------------------------------------------ Captured stderr setup -------------------------------------------
[D 46:05.546 MockHub app:1365] Writing PID 27865 to /tmp/tmpeqlwx7s_
[D 46:05.547 MockHub app:903] Connecting to db: sqlite:////tmp/tmpuo2sduvv
[D 46:05.551 MockHub orm:475] Stamping empty database with alembic revision 3ec6993fe20c
[I 46:05.553 alembic.runtime.migration migration:117] Context impl SQLiteImpl.
[I 46:05.553 alembic.runtime.migration migration:122] Will assume non-transactional DDL.
[I 46:05.559 alembic.runtime.migration migration:327] Running stamp_revision  -> 3ec6993fe20c
[D 46:05.559 alembic.runtime.migration migration:516] new branch insert 3ec6993fe20c
[I 46:05.624 MockHub app:1000] Not using whitelist. Any authenticated user will be allowed.
[D 46:05.633 MockHub app:1228] Loading state for admin from db
[D 46:05.634 MockHub app:1258] Loaded users: 
       admin admin
[I 46:05.641 MockHub app:1545] Hub API listening on http://127.0.0.1:8081/@/space%20word/hub/
[W 46:05.642 MockHub proxy:415] 
    Generating CONFIGPROXY_AUTH_TOKEN. Restarting the Hub will require restarting the proxy.
    Set CONFIGPROXY_AUTH_TOKEN env or JupyterHub.proxy_auth_token config to avoid this message.
    
[W 46:05.642 MockHub proxy:456] Running JupyterHub without SSL.  I hope there is SSL termination happening somewhere else...
[I 46:05.642 MockHub proxy:458] Starting proxy @ http://127.0.0.1:35321/@/space%20word/
[D 46:05.642 MockHub proxy:459] Proxy cmd: ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '35321', '--api-ip', '127.0.0.1', '--api-port', '8001', '--error-target', 'http://127.0.0.1:8081/@/space%20word/hub/error']
[E 46:05.645 MockHub proxy:467] Failed to find proxy ['configurable-http-proxy']
    The proxy can be installed with `npm install -g configurable-http-proxy`
[C 46:05.646 MockHub app:1552] Failed to start proxy
    Traceback (most recent call last):
      File "/home/ec2-user/jupyterhub/jupyterhub/app.py", line 1550, in start
        yield self.proxy.start()
      File "/home/ec2-user/jupyterhub/jupyterhub/proxy.py", line 462, in start
        self.proxy_process = Popen(cmd, env=env, start_new_session=True, shell=shell)
      File "/home/ec2-user/anaconda3/lib/python3.6/subprocess.py", line 707, in __init__
        restore_signals, start_new_session)
      File "/home/ec2-user/anaconda3/lib/python3.6/subprocess.py", line 1333, in _execute_child
        raise child_exception_type(errno_num, err_msg)
    FileNotFoundError: [Errno 2] No such file or directory: 'configurable-http-proxy'
    
[D 46:05.646 MockHub application:647] Exiting application: jupyterhub
________________________________ ERROR at setup of test_disable_user_config ________________________________

request = <SubRequest 'app' for <Function 'test_disable_user_config'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd733f9b00>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd733f9b00>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
________________________________ ERROR at setup of test_single_user_spawner ________________________________

self = <jupyterhub.tests.mocking.MockHub object at 0x7fdd735223c8>

    @gen.coroutine
    def start(self):
        """Start the whole thing"""
        self.io_loop = loop = IOLoop.current()
    
        if self.subapp:
            self.subapp.start()
            loop.stop()
            return
    
        if self.generate_config:
            self.write_config_file()
            loop.stop()
            return
    
        # start the webserver
        self.http_server = tornado.httpserver.HTTPServer(self.tornado_application, xheaders=True)
        try:
            self.http_server.listen(self.hub_port, address=self.hub_ip)
        except Exception:
            self.log.error("Failed to bind hub to %s", self.hub.bind_url)
            raise
        else:
            self.log.info("Hub API listening on %s", self.hub.bind_url)
    
        # start the proxy
        if self.proxy.should_start:
            try:
>               yield self.proxy.start()

/home/ec2-user/jupyterhub/jupyterhub/app.py:1550: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tornado.gen.Runner object at 0x7fdd733fcac8>

    def run(self):
        """Starts or resumes the generator, running until it reaches a
            yield point that is not ready.
            """
        if self.running or self.finished:
            return
        try:
            self.running = True
            while True:
                future = self.future
                if not future.done():
                    return
                self.future = None
                try:
                    orig_stack_contexts = stack_context._state.contexts
                    exc_info = None
    
                    try:
>                       value = future.result()

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1055: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = None, timeout = None

    def result(self, timeout=None):
        """If the operation succeeded, return its result.  If it failed,
            re-raise its exception.
    
            This method takes a ``timeout`` argument for compatibility with
            `concurrent.futures.Future` but it is an error to call it
            before the `Future` is done, so the ``timeout`` is never used.
            """
        self._clear_tb_log()
        if self._result is not None:
            return self._result
        if self._exc_info is not None:
            try:
>               raise_exc_info(self._exc_info)

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/concurrent.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

exc_info = None

>   ???

<string>:4: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<jupyterhub.proxy.ConfigurableHTTPProxy object at 0x7fdd73491550>,), kwargs = {}, future = None
result = <generator object start at 0x7fdd732dc4c0>, orig_stack_contexts = ((), None), yielded = None

    @functools.wraps(wrapped)
    def wrapper(*args, **kwargs):
        future = TracebackFuture()
    
        if replace_callback and 'callback' in kwargs:
            callback = kwargs.pop('callback')
            IOLoop.current().add_future(
                future, lambda future: callback(future.result()))
    
        try:
            result = func(*args, **kwargs)
        except (Return, StopIteration) as e:
            result = _value_from_stopiteration(e)
        except Exception:
            future.set_exc_info(sys.exc_info())
            return future
        else:
            if isinstance(result, GeneratorType):
                # Inline the first iteration of Runner.run.  This lets us
                # avoid the cost of creating a Runner when the coroutine
                # never actually yields, which in turn allows us to
                # use "optional" coroutines in critical path code without
                # performance penalty for the synchronous case.
                try:
                    orig_stack_contexts = stack_context._state.contexts
>                   yielded = next(result)

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:307: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <jupyterhub.proxy.ConfigurableHTTPProxy object at 0x7fdd73491550>

    @gen.coroutine
    def start(self):
        public_server = Server.from_url(self.public_url)
        api_server = Server.from_url(self.api_url)
        env = os.environ.copy()
        env['CONFIGPROXY_AUTH_TOKEN'] = self.auth_token
        cmd = self.command + [
            '--ip', public_server.ip,
            '--port', str(public_server.port),
            '--api-ip', api_server.ip,
            '--api-port', str(api_server.port),
            '--error-target', url_path_join(self.hub.url, 'error'),
        ]
        if self.app.subdomain_host:
            cmd.append('--host-routing')
        if self.debug:
            cmd.extend(['--log-level', 'debug'])
        if self.ssl_key:
            cmd.extend(['--ssl-key', self.ssl_key])
        if self.ssl_cert:
            cmd.extend(['--ssl-cert', self.ssl_cert])
        if self.app.statsd_host:
            cmd.extend([
                '--statsd-host', self.app.statsd_host,
                '--statsd-port', str(self.app.statsd_port),
                '--statsd-prefix', self.app.statsd_prefix + '.chp'
            ])
        # Warn if SSL is not used
        if ' --ssl' not in ' '.join(cmd):
            self.log.warning("Running JupyterHub without SSL."
                             "  I hope there is SSL termination happening somewhere else...")
        self.log.info("Starting proxy @ %s", public_server.bind_url)
        self.log.debug("Proxy cmd: %s", cmd)
        shell = os.name == 'nt'
        try:
>           self.proxy_process = Popen(cmd, env=env, start_new_session=True, shell=shell)

/home/ec2-user/jupyterhub/jupyterhub/proxy.py:462: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <subprocess.Popen object at 0x7fdd733fcef0>
args = ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '35321', '--api-ip', ...], bufsize = -1
executable = None, stdin = None, stdout = None, stderr = None, preexec_fn = None, close_fds = True
shell = False, cwd = None
env = {'COLUMNS': '108', 'CONFIGPROXY_AUTH_TOKEN': 'fee3064c9cc544b3b9eaf5cc7765be88', 'CVS_RSH': 'ssh', 'HISTCONTROL': 'ignoredups', ...}
universal_newlines = False, startupinfo = None, creationflags = 0, restore_signals = True
start_new_session = True, pass_fds = ()

    def __init__(self, args, bufsize=-1, executable=None,
                 stdin=None, stdout=None, stderr=None,
                 preexec_fn=None, close_fds=_PLATFORM_DEFAULT_CLOSE_FDS,
                 shell=False, cwd=None, env=None, universal_newlines=False,
                 startupinfo=None, creationflags=0,
                 restore_signals=True, start_new_session=False,
                 pass_fds=(), *, encoding=None, errors=None):
        """Create new Popen instance."""
        _cleanup()
        # Held while anything is calling waitpid before returncode has been
        # updated to prevent clobbering returncode if wait() or poll() are
        # called from multiple threads at once.  After acquiring the lock,
        # code must re-check self.returncode to see if another thread just
        # finished a waitpid() call.
        self._waitpid_lock = threading.Lock()
    
        self._input = None
        self._communication_started = False
        if bufsize is None:
            bufsize = -1  # Restore default
        if not isinstance(bufsize, int):
            raise TypeError("bufsize must be an integer")
    
        if _mswindows:
            if preexec_fn is not None:
                raise ValueError("preexec_fn is not supported on Windows "
                                 "platforms")
            any_stdio_set = (stdin is not None or stdout is not None or
                             stderr is not None)
            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:
                if any_stdio_set:
                    close_fds = False
                else:
                    close_fds = True
            elif close_fds and any_stdio_set:
                raise ValueError(
                        "close_fds is not supported on Windows platforms"
                        " if you redirect stdin/stdout/stderr")
        else:
            # POSIX
            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:
                close_fds = True
            if pass_fds and not close_fds:
                warnings.warn("pass_fds overriding close_fds.", RuntimeWarning)
                close_fds = True
            if startupinfo is not None:
                raise ValueError("startupinfo is only supported on Windows "
                                 "platforms")
            if creationflags != 0:
                raise ValueError("creationflags is only supported on Windows "
                                 "platforms")
    
        self.args = args
        self.stdin = None
        self.stdout = None
        self.stderr = None
        self.pid = None
        self.returncode = None
        self.universal_newlines = universal_newlines
        self.encoding = encoding
        self.errors = errors
    
        # Input and output objects. The general principle is like
        # this:
        #
        # Parent                   Child
        # ------                   -----
        # p2cwrite   ---stdin--->  p2cread
        # c2pread    <--stdout---  c2pwrite
        # errread    <--stderr---  errwrite
        #
        # On POSIX, the child objects are file descriptors.  On
        # Windows, these are Windows file handles.  The parent objects
        # are file descriptors on both platforms.  The parent objects
        # are -1 when not using PIPEs. The child objects are -1
        # when not redirecting.
    
        (p2cread, p2cwrite,
         c2pread, c2pwrite,
         errread, errwrite) = self._get_handles(stdin, stdout, stderr)
    
        # We wrap OS handles *before* launching the child, otherwise a
        # quickly terminating child could make our fds unwrappable
        # (see #8458).
    
        if _mswindows:
            if p2cwrite != -1:
                p2cwrite = msvcrt.open_osfhandle(p2cwrite.Detach(), 0)
            if c2pread != -1:
                c2pread = msvcrt.open_osfhandle(c2pread.Detach(), 0)
            if errread != -1:
                errread = msvcrt.open_osfhandle(errread.Detach(), 0)
    
        text_mode = encoding or errors or universal_newlines
    
        self._closed_child_pipe_fds = False
    
        try:
            if p2cwrite != -1:
                self.stdin = io.open(p2cwrite, 'wb', bufsize)
                if text_mode:
                    self.stdin = io.TextIOWrapper(self.stdin, write_through=True,
                            line_buffering=(bufsize == 1),
                            encoding=encoding, errors=errors)
            if c2pread != -1:
                self.stdout = io.open(c2pread, 'rb', bufsize)
                if text_mode:
                    self.stdout = io.TextIOWrapper(self.stdout,
                            encoding=encoding, errors=errors)
            if errread != -1:
                self.stderr = io.open(errread, 'rb', bufsize)
                if text_mode:
                    self.stderr = io.TextIOWrapper(self.stderr,
                            encoding=encoding, errors=errors)
    
            self._execute_child(args, executable, preexec_fn, close_fds,
                                pass_fds, cwd, env,
                                startupinfo, creationflags, shell,
                                p2cread, p2cwrite,
                                c2pread, c2pwrite,
                                errread, errwrite,
>                               restore_signals, start_new_session)

/home/ec2-user/anaconda3/lib/python3.6/subprocess.py:707: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <subprocess.Popen object at 0x7fdd733fcef0>
args = ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '35321', '--api-ip', ...]
executable = b'configurable-http-proxy', preexec_fn = None, close_fds = True, pass_fds = (), cwd = None
env = {'COLUMNS': '108', 'CONFIGPROXY_AUTH_TOKEN': 'fee3064c9cc544b3b9eaf5cc7765be88', 'CVS_RSH': 'ssh', 'HISTCONTROL': 'ignoredups', ...}
startupinfo = None, creationflags = 0, shell = False, p2cread = -1, p2cwrite = -1, c2pread = -1
c2pwrite = -1, errread = -1, errwrite = -1, restore_signals = True, start_new_session = True

    def _execute_child(self, args, executable, preexec_fn, close_fds,
                       pass_fds, cwd, env,
                       startupinfo, creationflags, shell,
                       p2cread, p2cwrite,
                       c2pread, c2pwrite,
                       errread, errwrite,
                       restore_signals, start_new_session):
        """Execute program (POSIX version)"""
    
        if isinstance(args, (str, bytes)):
            args = [args]
        else:
            args = list(args)
    
        if shell:
            args = ["/bin/sh", "-c"] + args
            if executable:
                args[0] = executable
    
        if executable is None:
            executable = args[0]
        orig_executable = executable
    
        # For transferring possible exec failure from child to parent.
        # Data format: "exception name:hex errno:description"
        # Pickle is not used; it is complex and involves memory allocation.
        errpipe_read, errpipe_write = os.pipe()
        # errpipe_write must not be in the standard io 0, 1, or 2 fd range.
        low_fds_to_close = []
        while errpipe_write < 3:
            low_fds_to_close.append(errpipe_write)
            errpipe_write = os.dup(errpipe_write)
        for low_fd in low_fds_to_close:
            os.close(low_fd)
        try:
            try:
                # We must avoid complex work that could involve
                # malloc or free in the child process to avoid
                # potential deadlocks, thus we do all this here.
                # and pass it to fork_exec()
    
                if env is not None:
                    env_list = []
                    for k, v in env.items():
                        k = os.fsencode(k)
                        if b'=' in k:
                            raise ValueError("illegal environment variable name")
                        env_list.append(k + b'=' + os.fsencode(v))
                else:
                    env_list = None  # Use execv instead of execve.
                executable = os.fsencode(executable)
                if os.path.dirname(executable):
                    executable_list = (executable,)
                else:
                    # This matches the behavior of os._execvpe().
                    executable_list = tuple(
                        os.path.join(os.fsencode(dir), executable)
                        for dir in os.get_exec_path(env))
                fds_to_keep = set(pass_fds)
                fds_to_keep.add(errpipe_write)
                self.pid = _posixsubprocess.fork_exec(
                        args, executable_list,
                        close_fds, tuple(sorted(map(int, fds_to_keep))),
                        cwd, env_list,
                        p2cread, p2cwrite, c2pread, c2pwrite,
                        errread, errwrite,
                        errpipe_read, errpipe_write,
                        restore_signals, start_new_session, preexec_fn)
                self._child_created = True
            finally:
                # be sure the FD is closed no matter what
                os.close(errpipe_write)
    
            # self._devnull is not always defined.
            devnull_fd = getattr(self, '_devnull', None)
            if p2cread != -1 and p2cwrite != -1 and p2cread != devnull_fd:
                os.close(p2cread)
            if c2pwrite != -1 and c2pread != -1 and c2pwrite != devnull_fd:
                os.close(c2pwrite)
            if errwrite != -1 and errread != -1 and errwrite != devnull_fd:
                os.close(errwrite)
            if devnull_fd is not None:
                os.close(devnull_fd)
            # Prevent a double close of these fds from __init__ on error.
            self._closed_child_pipe_fds = True
    
            # Wait for exec to fail or succeed; possibly raising an
            # exception (limited in size)
            errpipe_data = bytearray()
            while True:
                part = os.read(errpipe_read, 50000)
                errpipe_data += part
                if not part or len(errpipe_data) > 50000:
                    break
        finally:
            # be sure the FD is closed no matter what
            os.close(errpipe_read)
    
        if errpipe_data:
            try:
                pid, sts = os.waitpid(self.pid, 0)
                if pid == self.pid:
                    self._handle_exitstatus(sts)
                else:
                    self.returncode = sys.maxsize
            except ChildProcessError:
                pass
    
            try:
                exception_name, hex_errno, err_msg = (
                        errpipe_data.split(b':', 2))
            except ValueError:
                exception_name = b'SubprocessError'
                hex_errno = b'0'
                err_msg = (b'Bad exception data from child: ' +
                           repr(errpipe_data))
            child_exception_type = getattr(
                    builtins, exception_name.decode('ascii'),
                    SubprocessError)
            err_msg = err_msg.decode(errors="surrogatepass")
            if issubclass(child_exception_type, OSError) and hex_errno:
                errno_num = int(hex_errno, 16)
                child_exec_never_called = (err_msg == "noexec")
                if child_exec_never_called:
                    err_msg = ""
                if errno_num != 0:
                    err_msg = os.strerror(errno_num)
                    if errno_num == errno.ENOENT:
                        if child_exec_never_called:
                            # The error must be from chdir(cwd).
                            err_msg += ': ' + repr(cwd)
                        else:
                            err_msg += ': ' + repr(orig_executable)
>               raise child_exception_type(errno_num, err_msg)
E               FileNotFoundError: [Errno 2] No such file or directory: 'configurable-http-proxy'

/home/ec2-user/anaconda3/lib/python3.6/subprocess.py:1333: FileNotFoundError

During handling of the above exception, another exception occurred:

request = <SubRequest 'app' for <Function 'test_single_user_spawner'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd73308ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:832: in start
    self._run_callback(self._callbacks.popleft())
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:605: in _run_callback
    ret = callback()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py:277: in null_wrapper
    return fn(*args, **kwargs)
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:436: in run
    result = func()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:319: in wrapper
    _futures_to_runners[future] = Runner(result, future, yielded)
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1003: in __init__
    self.run()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1069: in run
    yielded = self.gen.send(value)
/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:62: in make_app
    yield mocked_app.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:319: in wrapper
    _futures_to_runners[future] = Runner(result, future, yielded)
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1003: in __init__
    self.run()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/gen.py:1063: in run
    yielded = self.gen.throw(*exc_info)
/home/ec2-user/jupyterhub/jupyterhub/app.py:1553: in start
    self.exit(1)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <jupyterhub.tests.mocking.MockHub object at 0x7fdd735223c8>, exit_status = 1

    def exit(self, exit_status=0):
        self.log.debug("Exiting application: %s" % self.name)
>       sys.exit(exit_status)
E       SystemExit: 1

/home/ec2-user/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py:648: SystemExit
------------------------------------------ Captured stderr setup -------------------------------------------
[D 46:07.209 MockHub app:1365] Writing PID 27865 to /tmp/tmpf16n59g4
[D 46:07.209 MockHub app:903] Connecting to db: sqlite:////tmp/tmpp920_nyr
[D 46:07.213 MockHub orm:475] Stamping empty database with alembic revision 3ec6993fe20c
[I 46:07.215 alembic.runtime.migration migration:117] Context impl SQLiteImpl.
[I 46:07.215 alembic.runtime.migration migration:122] Will assume non-transactional DDL.
[I 46:07.222 alembic.runtime.migration migration:327] Running stamp_revision  -> 3ec6993fe20c
[D 46:07.222 alembic.runtime.migration migration:516] new branch insert 3ec6993fe20c
[I 46:07.288 MockHub app:1000] Not using whitelist. Any authenticated user will be allowed.
[D 46:07.298 MockHub app:1228] Loading state for admin from db
[D 46:07.299 MockHub app:1258] Loaded users: 
       admin admin
[I 46:07.305 MockHub app:1545] Hub API listening on http://127.0.0.1:8081/@/space%20word/hub/
[W 46:07.306 MockHub proxy:415] 
    Generating CONFIGPROXY_AUTH_TOKEN. Restarting the Hub will require restarting the proxy.
    Set CONFIGPROXY_AUTH_TOKEN env or JupyterHub.proxy_auth_token config to avoid this message.
    
[W 46:07.306 MockHub proxy:456] Running JupyterHub without SSL.  I hope there is SSL termination happening somewhere else...
[I 46:07.306 MockHub proxy:458] Starting proxy @ http://127.0.0.1:35321/@/space%20word/
[D 46:07.306 MockHub proxy:459] Proxy cmd: ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '35321', '--api-ip', '127.0.0.1', '--api-port', '8001', '--error-target', 'http://127.0.0.1:8081/@/space%20word/hub/error']
[E 46:07.310 MockHub proxy:467] Failed to find proxy ['configurable-http-proxy']
    The proxy can be installed with `npm install -g configurable-http-proxy`
[C 46:07.310 MockHub app:1552] Failed to start proxy
    Traceback (most recent call last):
      File "/home/ec2-user/jupyterhub/jupyterhub/app.py", line 1550, in start
        yield self.proxy.start()
      File "/home/ec2-user/jupyterhub/jupyterhub/proxy.py", line 462, in start
        self.proxy_process = Popen(cmd, env=env, start_new_session=True, shell=shell)
      File "/home/ec2-user/anaconda3/lib/python3.6/subprocess.py", line 707, in __init__
        restore_signals, start_new_session)
      File "/home/ec2-user/anaconda3/lib/python3.6/subprocess.py", line 1333, in _execute_child
        raise child_exception_type(errno_num, err_msg)
    FileNotFoundError: [Errno 2] No such file or directory: 'configurable-http-proxy'
    
[D 46:07.310 MockHub application:647] Exiting application: jupyterhub
______________________________ ERROR at setup of test_spawner_reuse_api_token ______________________________

request = <SubRequest 'app' for <Function 'test_spawner_reuse_api_token'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd73308ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd73308ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_____________________________ ERROR at setup of test_spawner_insert_api_token ______________________________

request = <SubRequest 'app' for <Function 'test_spawner_reuse_api_token'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd73308ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd73308ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_______________________________ ERROR at setup of test_spawner_bad_api_token _______________________________

request = <SubRequest 'app' for <Function 'test_spawner_reuse_api_token'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd73308ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd73308ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_______________________________ ERROR at setup of test_spawner_delete_server _______________________________

request = <SubRequest 'app' for <Function 'test_spawner_reuse_api_token'>>
io_loop = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd73308ac8>

    @fixture(scope='module')
    def app(request, io_loop):
        """Mock a jupyterhub app for testing"""
        mocked_app = MockHub.instance(log_level=logging.DEBUG)
        @gen.coroutine
        def make_app():
            yield mocked_app.initialize([])
            yield mocked_app.start()
>       io_loop.run_sync(make_app)

/home/ec2-user/jupyterhub/jupyterhub/tests/conftest.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd73308ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
================================================= FAILURES =================================================
______________________________________________ test_token_app ______________________________________________

    def test_token_app():
        cmd = [sys.executable, '-m', 'jupyterhub', 'token']
        out = check_output(cmd + ['--help-all']).decode('utf8', 'replace')
        with TemporaryDirectory() as td:
            with open(os.path.join(td, 'jupyterhub_config.py'), 'w') as f:
                f.write("c.Authenticator.admin_users={'user'}")
>           out = check_output(cmd + ['user'], cwd=td).decode('utf8', 'replace').strip()

jupyterhub/tests/test_app.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/subprocess.py:336: in check_output
    **kwargs).stdout
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = None, timeout = None, check = True
popenargs = (['/home/ec2-user/anaconda3/bin/python', '-m', 'jupyterhub', 'token', 'user'],)
kwargs = {'cwd': '/tmp/tmpuoj6yaxo', 'stdout': -1}, process = <subprocess.Popen object at 0x7fdd738d5e48>
stdout = b'', stderr = None, retcode = 1

    def run(*popenargs, input=None, timeout=None, check=False, **kwargs):
        """Run command with arguments and return a CompletedProcess instance.
    
        The returned instance will have attributes args, returncode, stdout and
        stderr. By default, stdout and stderr are not captured, and those attributes
        will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them.
    
        If check is True and the exit code was non-zero, it raises a
        CalledProcessError. The CalledProcessError object will have the return code
        in the returncode attribute, and output & stderr attributes if those streams
        were captured.
    
        If timeout is given, and the process takes too long, a TimeoutExpired
        exception will be raised.
    
        There is an optional argument "input", allowing you to
        pass a string to the subprocess's stdin.  If you use this argument
        you may not also use the Popen constructor's "stdin" argument, as
        it will be used internally.
    
        The other arguments are the same as for the Popen constructor.
    
        If universal_newlines=True is passed, the "input" argument must be a
        string and stdout/stderr in the returned object will be strings rather than
        bytes.
        """
        if input is not None:
            if 'stdin' in kwargs:
                raise ValueError('stdin and input arguments may not both be used.')
            kwargs['stdin'] = PIPE
    
        with Popen(*popenargs, **kwargs) as process:
            try:
                stdout, stderr = process.communicate(input, timeout=timeout)
            except TimeoutExpired:
                process.kill()
                stdout, stderr = process.communicate()
                raise TimeoutExpired(process.args, timeout, output=stdout,
                                     stderr=stderr)
            except:
                process.kill()
                process.wait()
                raise
            retcode = process.poll()
            if check and retcode:
                raise CalledProcessError(retcode, process.args,
>                                        output=stdout, stderr=stderr)
E               subprocess.CalledProcessError: Command '['/home/ec2-user/anaconda3/bin/python', '-m', 'jupyterhub', 'token', 'user']' returned non-zero exit status 1.

../anaconda3/lib/python3.6/subprocess.py:418: CalledProcessError
------------------------------------------- Captured stderr call -------------------------------------------
/home/ec2-user/anaconda3/bin/python: No module named jupyterhub.__main__; 'jupyterhub' is a package and cannot be directly executed
___________________________________________ test_normalize_names ___________________________________________

pyfuncitem = <Function 'test_normalize_names'>

    @pytest.mark.tryfirst
    def pytest_pyfunc_call(pyfuncitem):
        gen_test_mark = pyfuncitem.keywords.get('gen_test')
        if gen_test_mark:
            io_loop = pyfuncitem.funcargs.get('io_loop')
            run_sync = gen_test_mark.kwargs.get('run_sync', True)
    
            funcargs = dict((arg, pyfuncitem.funcargs[arg])
                            for arg in _argnames(pyfuncitem.obj))
            if iscoroutinefunction(pyfuncitem.obj):
                coroutine = pyfuncitem.obj
                future = tornado.gen.convert_yielded(coroutine(**funcargs))
            else:
                coroutine = tornado.gen.coroutine(pyfuncitem.obj)
                future = coroutine(**funcargs)
            if run_sync:
>               io_loop.run_sync(lambda: future, timeout=_timeout(pyfuncitem))

../anaconda3/lib/python3.6/site-packages/pytest_tornado/plugin.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd735cec88>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
____________________________________________ test_username_map _____________________________________________

pyfuncitem = <Function 'test_username_map'>

    @pytest.mark.tryfirst
    def pytest_pyfunc_call(pyfuncitem):
        gen_test_mark = pyfuncitem.keywords.get('gen_test')
        if gen_test_mark:
            io_loop = pyfuncitem.funcargs.get('io_loop')
            run_sync = gen_test_mark.kwargs.get('run_sync', True)
    
            funcargs = dict((arg, pyfuncitem.funcargs[arg])
                            for arg in _argnames(pyfuncitem.obj))
            if iscoroutinefunction(pyfuncitem.obj):
                coroutine = pyfuncitem.obj
                future = tornado.gen.convert_yielded(coroutine(**funcargs))
            else:
                coroutine = tornado.gen.coroutine(pyfuncitem.obj)
                future = coroutine(**funcargs)
            if run_sync:
>               io_loop.run_sync(lambda: future, timeout=_timeout(pyfuncitem))

../anaconda3/lib/python3.6/site-packages/pytest_tornado/plugin.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
../anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd735cec88>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

../anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
_______________________________________________ test_upgrade _______________________________________________

tmpdir = local('/tmp/pytest-of-ec2-user/pytest-2/test_upgrade0')

    def test_upgrade(tmpdir):
        print(tmpdir)
        db_url = generate_old_db(str(tmpdir))
>       upgrade(db_url)

jupyterhub/tests/test_db.py:25: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
jupyterhub/dbutil.py:89: in upgrade
    ['alembic', '-c', alembic_ini, 'upgrade', revision]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

popenargs = (['alembic', '-c', '/tmp/tmpdxftyz5z/alembic.ini', 'upgrade', 'head'],), kwargs = {}
retcode = 1, cmd = ['alembic', '-c', '/tmp/tmpdxftyz5z/alembic.ini', 'upgrade', 'head']

    def check_call(*popenargs, **kwargs):
        """Run command with arguments.  Wait for command to complete.  If
        the exit code was zero then return, otherwise raise
        CalledProcessError.  The CalledProcessError object will have the
        return code in the returncode attribute.
    
        The arguments are the same as for the call function.  Example:
    
        check_call(["ls", "-l"])
        """
        retcode = call(*popenargs, **kwargs)
        if retcode:
            cmd = kwargs.get("args")
            if cmd is None:
                cmd = popenargs[0]
>           raise CalledProcessError(retcode, cmd)
E           subprocess.CalledProcessError: Command '['alembic', '-c', '/tmp/tmpdxftyz5z/alembic.ini', 'upgrade', 'head']' returned non-zero exit status 1.

../anaconda3/lib/python3.6/subprocess.py:291: CalledProcessError
------------------------------------------- Captured stdout call -------------------------------------------
/tmp/pytest-of-ec2-user/pytest-2/test_upgrade0
/home/ec2-user/jupyterhub/jupyterhub/tests/old-jupyterhub.sqlite /tmp/pytest-of-ec2-user/pytest-2/test_upgrade0/jupyterhub.sqlite
------------------------------------------- Captured stderr call -------------------------------------------
Traceback (most recent call last):
  File "/home/ec2-user/anaconda3/lib/python3.6/logging/config.py", line 98, in _resolve
    found = getattr(found, n)
AttributeError: module 'jupyterhub' has no attribute 'log'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ec2-user/anaconda3/bin/alembic", line 11, in <module>
    sys.exit(main())
  File "/home/ec2-user/anaconda3/lib/python3.6/site-packages/alembic/config.py", line 479, in main
    CommandLine(prog=prog).main(argv=argv)
  File "/home/ec2-user/anaconda3/lib/python3.6/site-packages/alembic/config.py", line 473, in main
    self.run_cmd(cfg, options)
  File "/home/ec2-user/anaconda3/lib/python3.6/site-packages/alembic/config.py", line 456, in run_cmd
    **dict((k, getattr(options, k, None)) for k in kwarg)
  File "/home/ec2-user/anaconda3/lib/python3.6/site-packages/alembic/command.py", line 254, in upgrade
    script.run_env()
  File "/home/ec2-user/anaconda3/lib/python3.6/site-packages/alembic/script/base.py", line 425, in run_env
    util.load_python_file(self.dir, 'env.py')
  File "/home/ec2-user/anaconda3/lib/python3.6/site-packages/alembic/util/pyfiles.py", line 81, in load_python_file
    module = load_module_py(module_id, path)
  File "/home/ec2-user/anaconda3/lib/python3.6/site-packages/alembic/util/compat.py", line 83, in load_module_py
    spec.loader.exec_module(module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 205, in _call_with_frames_removed
  File "/home/ec2-user/jupyterhub/jupyterhub/alembic/env.py", line 31, in <module>
    fileConfig(config.config_file_name)
  File "/home/ec2-user/anaconda3/lib/python3.6/logging/config.py", line 76, in fileConfig
    formatters = _create_formatters(cp)
  File "/home/ec2-user/anaconda3/lib/python3.6/logging/config.py", line 123, in _create_formatters
    c = _resolve(class_name)
  File "/home/ec2-user/anaconda3/lib/python3.6/logging/config.py", line 100, in _resolve
    __import__(used)
ModuleNotFoundError: No module named 'jupyterhub.log'
_________________________________________ test_upgrade_entrypoint __________________________________________

tmpdir = local('/tmp/pytest-of-ec2-user/pytest-2/test_upgrade_entrypoint0')

    @pytest.mark.gen_test
    def test_upgrade_entrypoint(tmpdir):
        db_url = os.getenv('JUPYTERHUB_TEST_UPGRADE_DB_URL')
        if not db_url:
            # default: sqlite
            db_url = generate_old_db(str(tmpdir))
        cfg = Config()
        cfg.JupyterHub.db_url = db_url
    
        tmpdir.chdir()
        tokenapp = NewToken(config=cfg)
        tokenapp.initialize(['kaylee'])
        with raises(SystemExit):
            tokenapp.start()
    
        if 'sqlite' in db_url:
            sqlite_files = glob(os.path.join(str(tmpdir), 'jupyterhub.sqlite*'))
            assert len(sqlite_files) == 1
    
        upgradeapp = UpgradeDB(config=cfg)
        yield upgradeapp.initialize([])
>       upgradeapp.start()

/home/ec2-user/jupyterhub/jupyterhub/tests/test_db.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/jupyterhub/jupyterhub/app.py:179: in start
    dbutil.upgrade_if_needed(hub.db_url, log=self.log)
/home/ec2-user/jupyterhub/jupyterhub/dbutil.py:130: in upgrade_if_needed
    upgrade(db_url)
/home/ec2-user/jupyterhub/jupyterhub/dbutil.py:89: in upgrade
    ['alembic', '-c', alembic_ini, 'upgrade', revision]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

popenargs = (['alembic', '-c', '/tmp/tmphvck0g6v/alembic.ini', 'upgrade', 'head'],), kwargs = {}
retcode = 1, cmd = ['alembic', '-c', '/tmp/tmphvck0g6v/alembic.ini', 'upgrade', 'head']

    def check_call(*popenargs, **kwargs):
        """Run command with arguments.  Wait for command to complete.  If
        the exit code was zero then return, otherwise raise
        CalledProcessError.  The CalledProcessError object will have the
        return code in the returncode attribute.
    
        The arguments are the same as for the call function.  Example:
    
        check_call(["ls", "-l"])
        """
        retcode = call(*popenargs, **kwargs)
        if retcode:
            cmd = kwargs.get("args")
            if cmd is None:
                cmd = popenargs[0]
>           raise CalledProcessError(retcode, cmd)
E           subprocess.CalledProcessError: Command '['alembic', '-c', '/tmp/tmphvck0g6v/alembic.ini', 'upgrade', 'head']' returned non-zero exit status 1.

/home/ec2-user/anaconda3/lib/python3.6/subprocess.py:291: CalledProcessError
------------------------------------------- Captured stdout call -------------------------------------------
/home/ec2-user/jupyterhub/jupyterhub/tests/old-jupyterhub.sqlite /tmp/pytest-of-ec2-user/pytest-2/test_upgrade_entrypoint0/jupyterhub.sqlite
------------------------------------------- Captured stderr call -------------------------------------------
[W 46:01.855 MockHub orm:495] Database schema version not found, guessing that JupyterHub 0.6 or earlier created this database.
[I 46:01.857 alembic.runtime.migration migration:117] Context impl SQLiteImpl.
[I 46:01.857 alembic.runtime.migration migration:122] Will assume non-transactional DDL.
[I 46:01.864 alembic.runtime.migration migration:327] Running stamp_revision  -> 19c0846f6344
[I 2017-11-27 14:46:01.878 JupyterHub dbutil:125] Upgrading sqlite:////tmp/pytest-of-ec2-user/pytest-2/test_upgrade_entrypoint0/jupyterhub.sqlite
[I 2017-11-27 14:46:01.878 JupyterHub dbutil:105] Backing up /tmp/pytest-of-ec2-user/pytest-2/test_upgrade_entrypoint0/jupyterhub.sqlite => /tmp/pytest-of-ec2-user/pytest-2/test_upgrade_entrypoint0/jupyterhub.sqlite.2017-11-27-144601
Traceback (most recent call last):
  File "/home/ec2-user/anaconda3/lib/python3.6/logging/config.py", line 98, in _resolve
    found = getattr(found, n)
AttributeError: module 'jupyterhub' has no attribute 'log'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ec2-user/anaconda3/bin/alembic", line 11, in <module>
    sys.exit(main())
  File "/home/ec2-user/anaconda3/lib/python3.6/site-packages/alembic/config.py", line 479, in main
    CommandLine(prog=prog).main(argv=argv)
  File "/home/ec2-user/anaconda3/lib/python3.6/site-packages/alembic/config.py", line 473, in main
    self.run_cmd(cfg, options)
  File "/home/ec2-user/anaconda3/lib/python3.6/site-packages/alembic/config.py", line 456, in run_cmd
    **dict((k, getattr(options, k, None)) for k in kwarg)
  File "/home/ec2-user/anaconda3/lib/python3.6/site-packages/alembic/command.py", line 254, in upgrade
    script.run_env()
  File "/home/ec2-user/anaconda3/lib/python3.6/site-packages/alembic/script/base.py", line 425, in run_env
    util.load_python_file(self.dir, 'env.py')
  File "/home/ec2-user/anaconda3/lib/python3.6/site-packages/alembic/util/pyfiles.py", line 81, in load_python_file
    module = load_module_py(module_id, path)
  File "/home/ec2-user/anaconda3/lib/python3.6/site-packages/alembic/util/compat.py", line 83, in load_module_py
    spec.loader.exec_module(module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 205, in _call_with_frames_removed
  File "/home/ec2-user/jupyterhub/jupyterhub/alembic/env.py", line 31, in <module>
    fileConfig(config.config_file_name)
  File "/home/ec2-user/anaconda3/lib/python3.6/logging/config.py", line 76, in fileConfig
    formatters = _create_formatters(cp)
  File "/home/ec2-user/anaconda3/lib/python3.6/logging/config.py", line 123, in _create_formatters
    c = _resolve(class_name)
  File "/home/ec2-user/anaconda3/lib/python3.6/logging/config.py", line 100, in _resolve
    __import__(used)
ModuleNotFoundError: No module named 'jupyterhub.log'
___________________________________________ test_external_proxy ____________________________________________

request = <FixtureRequest for <Function 'test_external_proxy'>>

    @pytest.mark.gen_test
    def test_external_proxy(request):
    
        auth_token = 'secret!'
        proxy_ip = '127.0.0.1'
        proxy_port = 54321
        cfg = Config()
        cfg.ConfigurableHTTPProxy.auth_token = auth_token
        cfg.ConfigurableHTTPProxy.api_url = 'http://%s:%i' % (proxy_ip, proxy_port)
        cfg.ConfigurableHTTPProxy.should_start = False
    
        app = MockHub.instance(config=cfg)
        # disable last_activity polling to avoid check_routes being called during the test,
        # which races with some of our test conditions
        app.last_activity_interval = 0
    
        def fin():
            MockHub.clear_instance()
            app.http_server.stop()
    
        request.addfinalizer(fin)
    
        # configures and starts proxy process
        env = os.environ.copy()
        env['CONFIGPROXY_AUTH_TOKEN'] = auth_token
        cmd = [
            'configurable-http-proxy',
            '--ip', app.ip,
            '--port', str(app.port),
            '--api-ip', proxy_ip,
            '--api-port', str(proxy_port),
            '--log-level=debug',
        ]
        if app.subdomain_host:
            cmd.append('--host-routing')
>       proxy = Popen(cmd, env=env)

/home/ec2-user/jupyterhub/jupyterhub/tests/test_proxy.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/subprocess.py:707: in __init__
    restore_signals, start_new_session)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <subprocess.Popen object at 0x7fdd738a75f8>
args = ['configurable-http-proxy', '--ip', '127.0.0.1', '--port', '56525', '--api-ip', ...]
executable = b'configurable-http-proxy', preexec_fn = None, close_fds = True, pass_fds = (), cwd = None
env = {'COLUMNS': '108', 'CONFIGPROXY_AUTH_TOKEN': 'secret!', 'CVS_RSH': 'ssh', 'HISTCONTROL': 'ignoredups', ...}
startupinfo = None, creationflags = 0, shell = False, p2cread = -1, p2cwrite = -1, c2pread = -1
c2pwrite = -1, errread = -1, errwrite = -1, restore_signals = True, start_new_session = False

    def _execute_child(self, args, executable, preexec_fn, close_fds,
                       pass_fds, cwd, env,
                       startupinfo, creationflags, shell,
                       p2cread, p2cwrite,
                       c2pread, c2pwrite,
                       errread, errwrite,
                       restore_signals, start_new_session):
        """Execute program (POSIX version)"""
    
        if isinstance(args, (str, bytes)):
            args = [args]
        else:
            args = list(args)
    
        if shell:
            args = ["/bin/sh", "-c"] + args
            if executable:
                args[0] = executable
    
        if executable is None:
            executable = args[0]
        orig_executable = executable
    
        # For transferring possible exec failure from child to parent.
        # Data format: "exception name:hex errno:description"
        # Pickle is not used; it is complex and involves memory allocation.
        errpipe_read, errpipe_write = os.pipe()
        # errpipe_write must not be in the standard io 0, 1, or 2 fd range.
        low_fds_to_close = []
        while errpipe_write < 3:
            low_fds_to_close.append(errpipe_write)
            errpipe_write = os.dup(errpipe_write)
        for low_fd in low_fds_to_close:
            os.close(low_fd)
        try:
            try:
                # We must avoid complex work that could involve
                # malloc or free in the child process to avoid
                # potential deadlocks, thus we do all this here.
                # and pass it to fork_exec()
    
                if env is not None:
                    env_list = []
                    for k, v in env.items():
                        k = os.fsencode(k)
                        if b'=' in k:
                            raise ValueError("illegal environment variable name")
                        env_list.append(k + b'=' + os.fsencode(v))
                else:
                    env_list = None  # Use execv instead of execve.
                executable = os.fsencode(executable)
                if os.path.dirname(executable):
                    executable_list = (executable,)
                else:
                    # This matches the behavior of os._execvpe().
                    executable_list = tuple(
                        os.path.join(os.fsencode(dir), executable)
                        for dir in os.get_exec_path(env))
                fds_to_keep = set(pass_fds)
                fds_to_keep.add(errpipe_write)
                self.pid = _posixsubprocess.fork_exec(
                        args, executable_list,
                        close_fds, tuple(sorted(map(int, fds_to_keep))),
                        cwd, env_list,
                        p2cread, p2cwrite, c2pread, c2pwrite,
                        errread, errwrite,
                        errpipe_read, errpipe_write,
                        restore_signals, start_new_session, preexec_fn)
                self._child_created = True
            finally:
                # be sure the FD is closed no matter what
                os.close(errpipe_write)
    
            # self._devnull is not always defined.
            devnull_fd = getattr(self, '_devnull', None)
            if p2cread != -1 and p2cwrite != -1 and p2cread != devnull_fd:
                os.close(p2cread)
            if c2pwrite != -1 and c2pread != -1 and c2pwrite != devnull_fd:
                os.close(c2pwrite)
            if errwrite != -1 and errread != -1 and errwrite != devnull_fd:
                os.close(errwrite)
            if devnull_fd is not None:
                os.close(devnull_fd)
            # Prevent a double close of these fds from __init__ on error.
            self._closed_child_pipe_fds = True
    
            # Wait for exec to fail or succeed; possibly raising an
            # exception (limited in size)
            errpipe_data = bytearray()
            while True:
                part = os.read(errpipe_read, 50000)
                errpipe_data += part
                if not part or len(errpipe_data) > 50000:
                    break
        finally:
            # be sure the FD is closed no matter what
            os.close(errpipe_read)
    
        if errpipe_data:
            try:
                pid, sts = os.waitpid(self.pid, 0)
                if pid == self.pid:
                    self._handle_exitstatus(sts)
                else:
                    self.returncode = sys.maxsize
            except ChildProcessError:
                pass
    
            try:
                exception_name, hex_errno, err_msg = (
                        errpipe_data.split(b':', 2))
            except ValueError:
                exception_name = b'SubprocessError'
                hex_errno = b'0'
                err_msg = (b'Bad exception data from child: ' +
                           repr(errpipe_data))
            child_exception_type = getattr(
                    builtins, exception_name.decode('ascii'),
                    SubprocessError)
            err_msg = err_msg.decode(errors="surrogatepass")
            if issubclass(child_exception_type, OSError) and hex_errno:
                errno_num = int(hex_errno, 16)
                child_exec_never_called = (err_msg == "noexec")
                if child_exec_never_called:
                    err_msg = ""
                if errno_num != 0:
                    err_msg = os.strerror(errno_num)
                    if errno_num == errno.ENOENT:
                        if child_exec_never_called:
                            # The error must be from chdir(cwd).
                            err_msg += ': ' + repr(cwd)
                        else:
                            err_msg += ': ' + repr(orig_executable)
>               raise child_exception_type(errno_num, err_msg)
E               FileNotFoundError: [Errno 2] No such file or directory: 'configurable-http-proxy'

/home/ec2-user/anaconda3/lib/python3.6/subprocess.py:1333: FileNotFoundError
_____________________________________________ test_help_output _____________________________________________

    def test_help_output():
>       out = check_output([sys.executable, '-m', 'jupyterhub.singleuser', '--help-all']).decode('utf8', 'replace')

/home/ec2-user/jupyterhub/jupyterhub/tests/test_singleuser.py:78: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/subprocess.py:336: in check_output
    **kwargs).stdout
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = None, timeout = None, check = True
popenargs = (['/home/ec2-user/anaconda3/bin/python', '-m', 'jupyterhub.singleuser', '--help-all'],)
kwargs = {'stdout': -1}, process = <subprocess.Popen object at 0x7fdd73759390>, stdout = b'', stderr = None
retcode = 1

    def run(*popenargs, input=None, timeout=None, check=False, **kwargs):
        """Run command with arguments and return a CompletedProcess instance.
    
        The returned instance will have attributes args, returncode, stdout and
        stderr. By default, stdout and stderr are not captured, and those attributes
        will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them.
    
        If check is True and the exit code was non-zero, it raises a
        CalledProcessError. The CalledProcessError object will have the return code
        in the returncode attribute, and output & stderr attributes if those streams
        were captured.
    
        If timeout is given, and the process takes too long, a TimeoutExpired
        exception will be raised.
    
        There is an optional argument "input", allowing you to
        pass a string to the subprocess's stdin.  If you use this argument
        you may not also use the Popen constructor's "stdin" argument, as
        it will be used internally.
    
        The other arguments are the same as for the Popen constructor.
    
        If universal_newlines=True is passed, the "input" argument must be a
        string and stdout/stderr in the returned object will be strings rather than
        bytes.
        """
        if input is not None:
            if 'stdin' in kwargs:
                raise ValueError('stdin and input arguments may not both be used.')
            kwargs['stdin'] = PIPE
    
        with Popen(*popenargs, **kwargs) as process:
            try:
                stdout, stderr = process.communicate(input, timeout=timeout)
            except TimeoutExpired:
                process.kill()
                stdout, stderr = process.communicate()
                raise TimeoutExpired(process.args, timeout, output=stdout,
                                     stderr=stderr)
            except:
                process.kill()
                process.wait()
                raise
            retcode = process.poll()
            if check and retcode:
                raise CalledProcessError(retcode, process.args,
>                                        output=stdout, stderr=stderr)
E               subprocess.CalledProcessError: Command '['/home/ec2-user/anaconda3/bin/python', '-m', 'jupyterhub.singleuser', '--help-all']' returned non-zero exit status 1.

/home/ec2-user/anaconda3/lib/python3.6/subprocess.py:418: CalledProcessError
------------------------------------------- Captured stderr call -------------------------------------------
/home/ec2-user/anaconda3/bin/python: No module named jupyterhub.singleuser
_______________________________________________ test_version _______________________________________________

    def test_version():
>       out = check_output([sys.executable, '-m', 'jupyterhub.singleuser', '--version']).decode('utf8', 'replace')

/home/ec2-user/jupyterhub/jupyterhub/tests/test_singleuser.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/subprocess.py:336: in check_output
    **kwargs).stdout
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = None, timeout = None, check = True
popenargs = (['/home/ec2-user/anaconda3/bin/python', '-m', 'jupyterhub.singleuser', '--version'],)
kwargs = {'stdout': -1}, process = <subprocess.Popen object at 0x7fdd735ea438>, stdout = b'', stderr = None
retcode = 1

    def run(*popenargs, input=None, timeout=None, check=False, **kwargs):
        """Run command with arguments and return a CompletedProcess instance.
    
        The returned instance will have attributes args, returncode, stdout and
        stderr. By default, stdout and stderr are not captured, and those attributes
        will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them.
    
        If check is True and the exit code was non-zero, it raises a
        CalledProcessError. The CalledProcessError object will have the return code
        in the returncode attribute, and output & stderr attributes if those streams
        were captured.
    
        If timeout is given, and the process takes too long, a TimeoutExpired
        exception will be raised.
    
        There is an optional argument "input", allowing you to
        pass a string to the subprocess's stdin.  If you use this argument
        you may not also use the Popen constructor's "stdin" argument, as
        it will be used internally.
    
        The other arguments are the same as for the Popen constructor.
    
        If universal_newlines=True is passed, the "input" argument must be a
        string and stdout/stderr in the returned object will be strings rather than
        bytes.
        """
        if input is not None:
            if 'stdin' in kwargs:
                raise ValueError('stdin and input arguments may not both be used.')
            kwargs['stdin'] = PIPE
    
        with Popen(*popenargs, **kwargs) as process:
            try:
                stdout, stderr = process.communicate(input, timeout=timeout)
            except TimeoutExpired:
                process.kill()
                stdout, stderr = process.communicate()
                raise TimeoutExpired(process.args, timeout, output=stdout,
                                     stderr=stderr)
            except:
                process.kill()
                process.wait()
                raise
            retcode = process.poll()
            if check and retcode:
                raise CalledProcessError(retcode, process.args,
>                                        output=stdout, stderr=stderr)
E               subprocess.CalledProcessError: Command '['/home/ec2-user/anaconda3/bin/python', '-m', 'jupyterhub.singleuser', '--version']' returned non-zero exit status 1.

/home/ec2-user/anaconda3/lib/python3.6/subprocess.py:418: CalledProcessError
------------------------------------------- Captured stderr call -------------------------------------------
/home/ec2-user/anaconda3/bin/python: No module named jupyterhub.singleuser
______________________________________ test_stop_spawner_sigint_fails ______________________________________

pyfuncitem = <Function 'test_stop_spawner_sigint_fails'>

    @pytest.mark.tryfirst
    def pytest_pyfunc_call(pyfuncitem):
        gen_test_mark = pyfuncitem.keywords.get('gen_test')
        if gen_test_mark:
            io_loop = pyfuncitem.funcargs.get('io_loop')
            run_sync = gen_test_mark.kwargs.get('run_sync', True)
    
            funcargs = dict((arg, pyfuncitem.funcargs[arg])
                            for arg in _argnames(pyfuncitem.obj))
            if iscoroutinefunction(pyfuncitem.obj):
                coroutine = pyfuncitem.obj
                future = tornado.gen.convert_yielded(coroutine(**funcargs))
            else:
                coroutine = tornado.gen.coroutine(pyfuncitem.obj)
                future = coroutine(**funcargs)
            if run_sync:
>               io_loop.run_sync(lambda: future, timeout=_timeout(pyfuncitem))

/home/ec2-user/anaconda3/lib/python3.6/site-packages/pytest_tornado/plugin.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd73308ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
------------------------------------------- Captured stderr call -------------------------------------------
[D 46:07.599 MockHub user:184] Creating <class 'jupyterhub.spawner.LocalProcessSpawner'> for ec2-user:
[D 46:07.601 MockHub user:184] Creating <class 'jupyterhub.spawner.LocalProcessSpawner'> for ec2-user:
[I 46:07.602 MockHub spawner:978] Spawning /home/ec2-user/anaconda3/bin/python -c '
    import time
    while True:
        try:
            time.sleep(10)
        except KeyboardInterrupt:
            print("interrupted")
    ' --port=46171 '--notebook-dir="/tmp/pytest-of-ec2-user/pytest-2/test_upgrade_entrypoint0"' '--NotebookApp.default_url="/user/ec2-user/lab"'
Failed to set groups [Errno 1] Operation not permitted
________________________________________ test_stop_spawner_stop_now ________________________________________

pyfuncitem = <Function 'test_stop_spawner_stop_now'>

    @pytest.mark.tryfirst
    def pytest_pyfunc_call(pyfuncitem):
        gen_test_mark = pyfuncitem.keywords.get('gen_test')
        if gen_test_mark:
            io_loop = pyfuncitem.funcargs.get('io_loop')
            run_sync = gen_test_mark.kwargs.get('run_sync', True)
    
            funcargs = dict((arg, pyfuncitem.funcargs[arg])
                            for arg in _argnames(pyfuncitem.obj))
            if iscoroutinefunction(pyfuncitem.obj):
                coroutine = pyfuncitem.obj
                future = tornado.gen.convert_yielded(coroutine(**funcargs))
            else:
                coroutine = tornado.gen.coroutine(pyfuncitem.obj)
                future = coroutine(**funcargs)
            if run_sync:
>               io_loop.run_sync(lambda: future, timeout=_timeout(pyfuncitem))

/home/ec2-user/anaconda3/lib/python3.6/site-packages/pytest_tornado/plugin.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd73308ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
------------------------------------------- Captured stderr call -------------------------------------------
[D 46:07.654 MockHub user:184] Creating <class 'jupyterhub.spawner.LocalProcessSpawner'> for ec2-user:
[D 46:07.655 MockHub user:184] Creating <class 'jupyterhub.spawner.LocalProcessSpawner'> for ec2-user:
[I 46:07.657 MockHub spawner:978] Spawning /home/ec2-user/anaconda3/bin/python -c '
    import sys, time
    print(sys.argv)
    time.sleep(30)
    ' --port=42587 '--notebook-dir="/tmp/pytest-of-ec2-user/pytest-2/test_upgrade_entrypoint0"' '--NotebookApp.default_url="/user/ec2-user/lab"'
Failed to set groups [Errno 1] Operation not permitted
____________________________________________ test_spawner_poll _____________________________________________

pyfuncitem = <Function 'test_spawner_poll'>

    @pytest.mark.tryfirst
    def pytest_pyfunc_call(pyfuncitem):
        gen_test_mark = pyfuncitem.keywords.get('gen_test')
        if gen_test_mark:
            io_loop = pyfuncitem.funcargs.get('io_loop')
            run_sync = gen_test_mark.kwargs.get('run_sync', True)
    
            funcargs = dict((arg, pyfuncitem.funcargs[arg])
                            for arg in _argnames(pyfuncitem.obj))
            if iscoroutinefunction(pyfuncitem.obj):
                coroutine = pyfuncitem.obj
                future = tornado.gen.convert_yielded(coroutine(**funcargs))
            else:
                coroutine = tornado.gen.coroutine(pyfuncitem.obj)
                future = coroutine(**funcargs)
            if run_sync:
>               io_loop.run_sync(lambda: future, timeout=_timeout(pyfuncitem))

/home/ec2-user/anaconda3/lib/python3.6/site-packages/pytest_tornado/plugin.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd73308ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
------------------------------------------- Captured stderr call -------------------------------------------
[D 46:07.708 MockHub user:184] Creating <class 'jupyterhub.spawner.LocalProcessSpawner'> for ec2-user:
[D 46:07.709 MockHub user:184] Creating <class 'jupyterhub.spawner.LocalProcessSpawner'> for ec2-user:
[I 46:07.711 MockHub spawner:978] Spawning /home/ec2-user/anaconda3/bin/python -c '
    import sys, time
    print(sys.argv)
    time.sleep(30)
    ' --port=48503 '--notebook-dir="/tmp/pytest-of-ec2-user/pytest-2/test_upgrade_entrypoint0"' '--NotebookApp.default_url="/user/ec2-user/lab"'
Failed to set groups [Errno 1] Operation not permitted
[D 46:07.719 MockHub user:184] Creating <class 'jupyterhub.spawner.LocalProcessSpawner'> for ec2-user:
[D 46:07.722 MockHub user:184] Creating <class 'jupyterhub.spawner.LocalProcessSpawner'> for ec2-user:
[D 46:07.724 MockHub spawner:727] Polling subprocess every 1s
____________________________________________ test_popen_kwargs _____________________________________________

pyfuncitem = <Function 'test_popen_kwargs'>

    @pytest.mark.tryfirst
    def pytest_pyfunc_call(pyfuncitem):
        gen_test_mark = pyfuncitem.keywords.get('gen_test')
        if gen_test_mark:
            io_loop = pyfuncitem.funcargs.get('io_loop')
            run_sync = gen_test_mark.kwargs.get('run_sync', True)
    
            funcargs = dict((arg, pyfuncitem.funcargs[arg])
                            for arg in _argnames(pyfuncitem.obj))
            if iscoroutinefunction(pyfuncitem.obj):
                coroutine = pyfuncitem.obj
                future = tornado.gen.convert_yielded(coroutine(**funcargs))
            else:
                coroutine = tornado.gen.coroutine(pyfuncitem.obj)
                future = coroutine(**funcargs)
            if run_sync:
>               io_loop.run_sync(lambda: future, timeout=_timeout(pyfuncitem))

/home/ec2-user/anaconda3/lib/python3.6/site-packages/pytest_tornado/plugin.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd73308ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
------------------------------------------- Captured stderr call -------------------------------------------
[D 46:07.772 MockHub user:184] Creating <class 'jupyterhub.spawner.LocalProcessSpawner'> for ec2-user:
[D 46:07.773 MockHub user:184] Creating <class 'jupyterhub.spawner.LocalProcessSpawner'> for ec2-user:
[I 46:07.775 MockHub spawner:978] Spawning jupyterhub-singleuser --port=39317 '--notebook-dir="/tmp/pytest-of-ec2-user/pytest-2/test_upgrade_entrypoint0"' '--NotebookApp.default_url="/user/ec2-user/lab"'
______________________________________________ test_shell_cmd ______________________________________________

pyfuncitem = <Function 'test_shell_cmd'>

    @pytest.mark.tryfirst
    def pytest_pyfunc_call(pyfuncitem):
        gen_test_mark = pyfuncitem.keywords.get('gen_test')
        if gen_test_mark:
            io_loop = pyfuncitem.funcargs.get('io_loop')
            run_sync = gen_test_mark.kwargs.get('run_sync', True)
    
            funcargs = dict((arg, pyfuncitem.funcargs[arg])
                            for arg in _argnames(pyfuncitem.obj))
            if iscoroutinefunction(pyfuncitem.obj):
                coroutine = pyfuncitem.obj
                future = tornado.gen.convert_yielded(coroutine(**funcargs))
            else:
                coroutine = tornado.gen.coroutine(pyfuncitem.obj)
                future = coroutine(**funcargs)
            if run_sync:
>               io_loop.run_sync(lambda: future, timeout=_timeout(pyfuncitem))

/home/ec2-user/anaconda3/lib/python3.6/site-packages/pytest_tornado/plugin.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:453: in run_sync
    self.start()
/home/ec2-user/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py:177: in start
    super(ZMQIOLoop, self).start()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7fdd73308ac8>

    def start(self):
        if self._running:
>           raise RuntimeError("IOLoop is already running")
E           RuntimeError: IOLoop is already running

/home/ec2-user/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py:755: RuntimeError
------------------------------------------- Captured stderr call -------------------------------------------
[D 46:07.804 MockHub user:184] Creating <class 'jupyterhub.spawner.LocalProcessSpawner'> for ec2-user:
[D 46:07.805 MockHub user:184] Creating <class 'jupyterhub.spawner.LocalProcessSpawner'> for ec2-user:
[I 46:07.811 MockHub spawner:978] Spawning bash --rcfile /tmp/pytest-of-ec2-user/pytest-2/test_shell_cmd0/bashrc -i -c '/home/ec2-user/anaconda3/bin/python -m jupyterhub.tests.mocksu --port=44653 '"'"'--notebook-dir="/tmp/pytest-of-ec2-user/pytest-2/test_upgrade_entrypoint0"'"'"' '"'"'--NotebookApp.default_url="/user/ec2-user/lab"'"'"''
Failed to set groups [Errno 1] Operation not permitted
bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
----------------------------------------- Captured stderr teardown -----------------------------------------
/home/ec2-user/anaconda3/bin/python: Error while finding module specification for 'jupyterhub.tests.mocksu' (ModuleNotFoundError: No module named 'jupyterhub.tests')
============================= 13 failed, 51 passed, 104 error in 12.26 seconds =============================
